<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="A Unified Library for Inference and Fine-Tuning Tabular Foundation Models" name="description"/>
<meta content="Lexsi Labs" name="author"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<title>Installation - TabTune Documentation</title>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/all.css" rel="stylesheet"/>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css" rel="stylesheet"/>
<link href="//rsms.me/inter/inter.css" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&amp;subset=latin-ext,latin" rel="stylesheet" type="text/css"/>
<link href="../../css/bootstrap-custom.min.css" rel="stylesheet"/>
<link href="../../css/base.min.css" rel="stylesheet"/>
<link href="../../css/cinder.min.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css" rel="stylesheet"/>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../assets/overrides.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->
</head>
<body>
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
<div class="container">
<!-- Collapsed navigation -->
<div class="navbar-header">
<!-- Expander button -->
<button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse" type="button">
<span class="sr-only">Toggle navigation</span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
</button>
<!-- Main title -->
<a class="navbar-brand" href="../..">TabTune Documentation</a>
</div>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="dropdown active">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="active">
<a href="./">Installation</a>
</li>
<li>
<a href="../quick-start/">Quick Start</a>
</li>
<li>
<a href="../basic-concepts/">Basic Concepts</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">User Guide <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
</li>
<li>
<a href="../../user-guide/data-processing/">Data Processing</a>
</li>
<li>
<a href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
</li>
<li>
<a href="../../user-guide/model-selection/">Model Selection</a>
</li>
<li>
<a href="../../user-guide/saving-loading/">Saving and Loading</a>
</li>
<li>
<a href="../../user-guide/leaderboard/">Model Comparison</a>
</li>
<li>
<a href="../../user-guide/troubleshooting/">Troubleshooting</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Models <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../models/overview/">Overview</a>
</li>
<li>
<a href="../../models/tabpfn/">TabPFN</a>
</li>
<li>
<a href="../../models/tabicl/">TabICL</a>
</li>
<li>
<a href="../../models/orion-msp/">Orion MSP</a>
</li>
<li>
<a href="../../models/orion-bix/">Orion BIX</a>
</li>
<li>
<a href="../../models/tabdpt/">TabDPT</a>
</li>
<li>
<a href="../../models/mitra/">Mitra</a>
</li>
<li>
<a href="../../models/contexttab/">ConTextTab</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Advanced Topics <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../advanced/peft-lora/">PEFT &amp; LoRA</a>
</li>
<li>
<a href="../../advanced/custom-preprocessing/">Custom Preprocessing</a>
</li>
<li>
<a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
</li>
<li>
<a href="../../advanced/memory-optimization/">Memory Optimization</a>
</li>
<li>
<a href="../../advanced/multi-gpu/">Multi-GPU Training</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">API Reference <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../api/pipeline/">TabularPipeline</a>
</li>
<li>
<a href="../../api/data-processor/">DataProcessor</a>
</li>
<li>
<a href="../../api/tuning-manager/">TuningManager</a>
</li>
<li>
<a href="../../api/leaderboard/">TabularLeaderboard</a>
</li>
<li>
<a href="../../api/peft-utils/">PEFT Utils</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Examples <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../examples/classification/">Classification Tasks</a>
</li>
<li>
<a href="../../examples/peft-examples/">PEFT Fine-Tuning</a>
</li>
<li>
<a href="../../examples/benchmarking/">Benchmarking</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Project <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="dropdown-submenu">
<a href="" tabindex="-1">Contributing</a>
<ul class="dropdown-menu">
<li>
<a href="../../contributing/setup/">Development Setup</a>
</li>
<li>
<a href="../../contributing/standards/">Code Standards</a>
</li>
<li>
<a href="../../contributing/new-models/">Adding New Models</a>
</li>
<li>
<a href="../../contributing/documentation/">Documentation Guide</a>
</li>
</ul>
</li>
<li class="dropdown-submenu">
<a href="" tabindex="-1">About</a>
<ul class="dropdown-menu">
<li>
<a href="../../about/release-notes/">Release Notes</a>
</li>
<li>
<a href="../../about/roadmap/">Roadmap</a>
</li>
<li>
<a href="../../about/faq/">FAQ</a>
</li>
<li>
<a href="../../about/license/">License</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
<a data-target="#mkdocs_search_modal" data-toggle="modal" href="#">
<i class="fas fa-search"></i> Search
                        </a>
</li>
<li class="disabled">
<a rel="prev">
<i class="fas fa-arrow-left"></i> Previous
                        </a>
</li>
<li>
<a href="../quick-start/" rel="next">
                            Next <i class="fas fa-arrow-right"></i>
</a>
</li>
<li>
<a href="https://github.com/Lexsi-Labs/TabTune/edit/master/docs/getting-started/installation.md">Edit on Lexsi-Labs/TabTune</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
<ul class="nav bs-sidenav">
<li class="first-level active"><a href="#installation">Installation</a></li>
<li class="second-level"><a href="#system-requirements">System Requirements</a></li>
<li class="third-level"><a href="#python-version">Python Version</a></li>
<li class="third-level"><a href="#hardware">Hardware</a></li>
<li class="second-level"><a href="#installation-methods">Installation Methods</a></li>
<li class="third-level"><a href="#method-1-install-from-source-recommended">Method 1: Install from Source (Recommended)</a></li>
<li class="second-level"><a href="#core-dependencies">Core Dependencies</a></li>
<li class="third-level"><a href="#essential-packages">Essential Packages</a></li>
<li class="third-level"><a href="#model-specific-dependencies">Model-Specific Dependencies</a></li>
<li class="second-level"><a href="#verify-installation">Verify Installation</a></li>
<li class="third-level"><a href="#quick-verification">Quick Verification</a></li>
<li class="third-level"><a href="#gpu-verification">GPU Verification</a></li>
<li class="third-level"><a href="#model-loading-test">Model Loading Test</a></li>
<li class="second-level"><a href="#troubleshooting">Troubleshooting</a></li>
<li class="third-level"><a href="#common-installation-issues">Common Installation Issues</a></li>
<li class="third-level"><a href="#memory-issues">Memory Issues</a></li>
<li class="second-level"><a href="#environment-variables">Environment Variables</a></li>
<li class="second-level"><a href="#next-steps">Next Steps</a></li>
</ul>
</div></div>
<div class="col-md-9" role="main">
<h1 id="installation">Installation<a class="headerlink" href="#installation" title="Permanent link">¶</a></h1>
<p>This guide will walk you through installing TabTune and its dependencies for optimal performance across different environments.</p>
<hr/>
<h2 id="system-requirements">System Requirements<a class="headerlink" href="#system-requirements" title="Permanent link">¶</a></h2>
<h3 id="python-version"><strong>Python Version</strong><a class="headerlink" href="#python-version" title="Permanent link">¶</a></h3>
<ul>
<li><strong>Python 3.10+</strong> (required)</li>
<li>Python 3.12+ (recommended for best performance)</li>
</ul>
<h3 id="hardware"><strong>Hardware</strong><a class="headerlink" href="#hardware" title="Permanent link">¶</a></h3>
<ul>
<li><strong>Minimum</strong>: 8GB RAM, 2GB free disk space</li>
<li><strong>Recommended</strong>: 16GB+ RAM, NVIDIA GPU with 8GB+ VRAM</li>
<li><strong>For Large Datasets</strong>: 32GB+ RAM, multiple GPUs</li>
</ul>
<hr/>
<h2 id="installation-methods">Installation Methods<a class="headerlink" href="#installation-methods" title="Permanent link">¶</a></h2>
<h3 id="method-1-install-from-source-recommended"><strong>Method 1: Install from Source (Recommended)</strong><a class="headerlink" href="#method-1-install-from-source-recommended" title="Permanent link">¶</a></h3>
<ol>
<li>
<p><strong>Clone the repository</strong>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/Lexsi-Labs/TabTune.git
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
<span class="nb">cd</span><span class="w"> </span>TabTune
pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span>.
</code></pre></div></p>
</li>
<li>
<p><strong>Create virtual environment</strong>
<div class="highlight"><pre><span></span><code><span class="c1"># Using venv</span>
python<span class="w"> </span>-m<span class="w"> </span>venv<span class="w"> </span>tabtune-env
<span class="nb">source</span><span class="w"> </span>tabtune-env/bin/activate<span class="w">  </span><span class="c1"># Linux/macOS</span>
<span class="c1"># tabtune-env\Scripts\activate   # Windows</span>

<span class="c1"># Or using conda</span>
conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>tabtune<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.11
conda<span class="w"> </span>activate<span class="w"> </span>tabtune
</code></pre></div></p>
</li>
</ol>
<hr/>
<div class="admonition tip">
<p class="admonition-title">GPU Support</p>
<p>For optimal performance with large models, install CUDA-enabled PyTorch. Check your CUDA version with <code>nvidia-smi</code>.</p>
</div>
<hr/>
<h2 id="core-dependencies">Core Dependencies<a class="headerlink" href="#core-dependencies" title="Permanent link">¶</a></h2>
<p>The following packages are automatically installed with TabTune:</p>
<h3 id="essential-packages"><strong>Essential Packages</strong><a class="headerlink" href="#essential-packages" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Core ML libraries</span>
torch&gt;<span class="o">=</span><span class="m">2</span>.0.0
numpy&gt;<span class="o">=</span><span class="m">1</span>.21.0
pandas&gt;<span class="o">=</span><span class="m">1</span>.3.0
scikit-learn&gt;<span class="o">=</span><span class="m">1</span>.0.0

<span class="c1"># Data handling</span>
openml&gt;<span class="o">=</span><span class="m">0</span>.12.0
datasets&gt;<span class="o">=</span><span class="m">2</span>.0.0

<span class="c1"># PEFT support</span>
peft&gt;<span class="o">=</span><span class="m">0</span>.4.0
accelerate&gt;<span class="o">=</span><span class="m">0</span>.20.0
transformers&gt;<span class="o">=</span><span class="m">4</span>.30.0

<span class="c1"># Utilities</span>
joblib&gt;<span class="o">=</span><span class="m">1</span>.0.0
tqdm&gt;<span class="o">=</span><span class="m">4</span>.60.0
</code></pre></div>
<h3 id="model-specific-dependencies"><strong>Model-Specific Dependencies</strong><a class="headerlink" href="#model-specific-dependencies" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># For ContextTab (requires HuggingFace Hub access)</span>
huggingface-hub&gt;<span class="o">=</span><span class="m">0</span>.15.0
sentence-transformers&gt;<span class="o">=</span><span class="m">2</span>.2.0

<span class="c1"># For advanced preprocessing</span>
category-encoders&gt;<span class="o">=</span><span class="m">2</span>.5.0
</code></pre></div>
<hr/>
<h2 id="verify-installation">Verify Installation<a class="headerlink" href="#verify-installation" title="Permanent link">¶</a></h2>
<h3 id="quick-verification"><strong>Quick Verification</strong><a class="headerlink" href="#quick-verification" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"PyTorch version: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Test TabTune import</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"✅ TabTune successfully installed!"</span><span class="p">)</span>
</code></pre></div>
<h3 id="gpu-verification"><strong>GPU Verification</strong><a class="headerlink" href="#gpu-verification" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"✅ CUDA available: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_name</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"GPU Memory: </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"ℹ️ CUDA not available, using CPU"</span><span class="p">)</span>
</code></pre></div>
<h3 id="model-loading-test"><strong>Model Loading Test</strong><a class="headerlink" href="#model-loading-test" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Quick smoke test</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'a'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s1">'b'</span><span class="p">:</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]})</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">"TabPFN"</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s2">"inference"</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"✅ Pipeline creation successful!"</span><span class="p">)</span>
</code></pre></div>
<hr/>
<h2 id="troubleshooting">Troubleshooting<a class="headerlink" href="#troubleshooting" title="Permanent link">¶</a></h2>
<h3 id="common-installation-issues"><strong>Common Installation Issues</strong><a class="headerlink" href="#common-installation-issues" title="Permanent link">¶</a></h3>
<h4 id="issue-modulenotfounderror-for-torch"><strong>Issue: ModuleNotFoundError for torch</strong><a class="headerlink" href="#issue-modulenotfounderror-for-torch" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Solution: Reinstall PyTorch with correct CUDA version</span>
pip<span class="w"> </span>uninstall<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio
pip<span class="w"> </span>install<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio<span class="w"> </span>--index-url<span class="w"> </span>https://download.pytorch.org/whl/check_version_in_requirements
</code></pre></div>
<h4 id="issue-cuda-out-of-memory-during-model-loading"><strong>Issue: CUDA out of memory during model loading</strong><a class="headerlink" href="#issue-cuda-out-of-memory-during-model-loading" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Solution: Use smaller batch sizes or CPU fallback</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">"TabPFN"</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s2">"inference"</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span><span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cpu"</span><span class="p">,</span> <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">16</span><span class="p">}</span>
<span class="p">)</span>
</code></pre></div>
<h4 id="issue-contexttab-model-access-denied"><strong>Issue: ContextTab model access denied</strong><a class="headerlink" href="#issue-contexttab-model-access-denied" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Solution: Set up HuggingFace token</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">HF_TOKEN</span><span class="o">=</span><span class="s2">"your_huggingface_token"</span>
<span class="c1"># Or login interactively</span>
huggingface-cli<span class="w"> </span>login
</code></pre></div>
<h4 id="issue-permission-denied-on-windows"><strong>Issue: Permission denied on Windows</strong><a class="headerlink" href="#issue-permission-denied-on-windows" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Solution: Run as administrator or use --user flag</span>
pip<span class="w"> </span>install<span class="w"> </span>--user<span class="w"> </span>-e<span class="w"> </span>.
</code></pre></div>
<h3 id="memory-issues"><strong>Memory Issues</strong><a class="headerlink" href="#memory-issues" title="Permanent link">¶</a></h3>
<h4 id="large-dataset-handling"><strong>Large Dataset Handling</strong><a class="headerlink" href="#large-dataset-handling" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Use chunked processing for large datasets</span>
<span class="n">tuning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># Reduce batch size</span>
    <span class="s2">"gradient_accumulation_steps"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># Maintain effective batch size</span>
    <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span>
<span class="p">}</span>
</code></pre></div>
<h4 id="peft-memory-optimization"><strong>PEFT Memory Optimization</strong><a class="headerlink" href="#peft-memory-optimization" title="Permanent link">¶</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Use PEFT for memory-efficient fine-tuning</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s2">"TabICL"</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s2">"peft"</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"peft_config"</span><span class="p">:</span> <span class="p">{</span><span class="s2">"r"</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>  <span class="c1"># Lower rank for less memory</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div>
<hr/>
<h2 id="environment-variables">Environment Variables<a class="headerlink" href="#environment-variables" title="Permanent link">¶</a></h2>
<p>Set these environment variables for optimal performance:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># HuggingFace token for gated models</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">HF_TOKEN</span><span class="o">=</span><span class="s2">"your_token_here"</span>

<span class="c1"># Disable tokenizers parallelism warnings</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TOKENIZERS_PARALLELISM</span><span class="o">=</span><span class="nb">false</span>

<span class="c1"># CUDA memory management</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">PYTORCH_CUDA_ALLOC_CONF</span><span class="o">=</span>max_split_size_mb:512

<span class="c1"># For debugging</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">CUDA_LAUNCH_BLOCKING</span><span class="o">=</span><span class="m">1</span>
</code></pre></div>
<hr/>
<h2 id="next-steps">Next Steps<a class="headerlink" href="#next-steps" title="Permanent link">¶</a></h2>
<p>After successful installation:</p>
<ol>
<li><strong><a href="../quick-start/">Quick Start Guide</a></strong> - Run your first tabtune example</li>
<li><strong><a href="../basic-concepts/">Basic Concepts</a></strong> - Understand the core architecture</li>
<li><strong><a href="../../user-guide/model-selection/">Model Selection</a></strong> - Choose the right model for your task</li>
</ol>
<hr/>
<div class="admonition success">
<p class="admonition-title">Installation Complete</p>
<p>You're now ready to start using TabTune! If you encounter any issues, please check our <a href="../../about/faq/">FAQ</a> or open an issue on <a href="https://github.com/Lexsi-Labs/TabTune/issues">GitHub</a>.</p>
</div></div>
</div>
<footer class="col-md-12 text-center">
<hr/>
<p>
<small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
</p>
</footer>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="../../js/bootstrap-3.0.3.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/python.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/yaml.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>var base_url = "../.."</script>
<script src="../../js/base.js"></script>
<script src="../../search/main.js"></script>
<script>
        // Initialize Mermaid v9.x after DOM loads
        // The mermaid2 plugin loads the library and sets window.mermaidConfig
        (function() {
            function initMermaid() {
                if (typeof mermaid !== 'undefined') {
                    // Get configuration from plugin or use defaults
                    const config = window.mermaidConfig || {
                        securityLevel: 'loose',
                        startOnLoad: false
                    };
                    
                    // Initialize mermaid with config
                    mermaid.initialize(config);
                    
                    // Render all mermaid diagrams - mermaid.run() automatically finds .mermaid elements
                    if (typeof mermaid.run === 'function') {
                        mermaid.run();
                    } else {
                        // Fallback for older API - manually initialize elements
                        const mermaidElements = document.querySelectorAll('.mermaid');
                        if (mermaidElements.length > 0) {
                            mermaid.init(undefined, mermaidElements);
                        }
                    }
                } else {
                    // Retry if mermaid library hasn't loaded yet
                    setTimeout(initMermaid, 100);
                }
            }
            
            // Wait for DOM and scripts to be ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', initMermaid);
            } else {
                // DOM already loaded, but scripts might not be
                setTimeout(initMermaid, 100);
            }
        })();
    </script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">×</span>
<span class="sr-only">Close</span>
</button>
<h4 class="modal-title" id="searchModalLabel">Search</h4>
</div>
<div class="modal-body">
<p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="text"/>
</div>
</form>
<div id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
</body>
</html>
