<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="A Unified Library for Inference and Fine-Tuning Tabular Foundation Models" name="description"/>
<meta content="Lexsi Labs" name="author"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<title>Overview - TabTune Documentation</title>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/all.css" rel="stylesheet"/>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css" rel="stylesheet"/>
<link href="//rsms.me/inter/inter.css" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&amp;subset=latin-ext,latin" rel="stylesheet" type="text/css"/>
<link href="../../css/bootstrap-custom.min.css" rel="stylesheet"/>
<link href="../../css/base.min.css" rel="stylesheet"/>
<link href="../../css/cinder.min.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css" rel="stylesheet"/>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../assets/overrides.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->
<link href="../../assets/lexsilabs.ico" rel="icon"/>
<link href="../../assets/lexsilabs.ico" rel="shortcut icon"/>
</head>
<body>
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
<div class="container">
<!-- Collapsed navigation -->
<div class="navbar-header">
<!-- Expander button -->
<button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse" type="button">
<span class="sr-only">Toggle navigation</span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
</button>
<!-- Main title -->
<a class="navbar-brand" href="../..">TabTune Documentation</a>
</div>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../getting-started/installation/">Installation</a>
</li>
<li>
<a href="../../getting-started/quick-start/">Quick Start</a>
</li>
<li>
<a href="../../getting-started/basic-concepts/">Basic Concepts</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">User Guide <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
</li>
<li>
<a href="../../user-guide/data-processing/">Data Processing</a>
</li>
<li>
<a href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
</li>
<li>
<a href="../../user-guide/model-selection/">Model Selection</a>
</li>
<li>
<a href="../../user-guide/saving-loading/">Saving and Loading</a>
</li>
<li>
<a href="../../user-guide/leaderboard/">Model Comparison</a>
</li>
<li>
<a href="../../user-guide/troubleshooting/">Troubleshooting</a>
</li>
</ul>
</li>
<li class="dropdown active">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Models <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="active">
<a href="./">Overview</a>
</li>
<li>
<a href="../tabpfn/">TabPFN</a>
</li>
<li>
<a href="../tabicl/">TabICL</a>
</li>
<li>
<a href="../orion-msp/">Orion MSP</a>
</li>
<li>
<a href="../orion-bix/">Orion BIX</a>
</li>
<li>
<a href="../tabdpt/">TabDPT</a>
</li>
<li>
<a href="../mitra/">Mitra</a>
</li>
<li>
<a href="../contexttab/">ConTextTab</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Advanced Topics <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../advanced/peft-lora/">PEFT &amp; LoRA</a>
</li>
<li>
<a href="../../advanced/custom-preprocessing/">Custom Preprocessing</a>
</li>
<li>
<a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
</li>
<li>
<a href="../../advanced/memory-optimization/">Memory Optimization</a>
</li>
<li>
<a href="../../advanced/multi-gpu/">Multi-GPU Training</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">API Reference <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../api/pipeline/">TabularPipeline</a>
</li>
<li>
<a href="../../api/data-processor/">DataProcessor</a>
</li>
<li>
<a href="../../api/tuning-manager/">TuningManager</a>
</li>
<li>
<a href="../../api/leaderboard/">TabularLeaderboard</a>
</li>
<li>
<a href="../../api/peft-utils/">PEFT Utils</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Examples <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../examples/classification/">Classification Tasks</a>
</li>
<li>
<a href="../../examples/peft-examples/">PEFT Fine-Tuning</a>
</li>
<li>
<a href="../../examples/benchmarking/">Benchmarking</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Project <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="dropdown-submenu">
<a href="" tabindex="-1">Contributing</a>
<ul class="dropdown-menu">
<li>
<a href="../../contributing/setup/">Development Setup</a>
</li>
<li>
<a href="../../contributing/standards/">Code Standards</a>
</li>
<li>
<a href="../../contributing/new-models/">Adding New Models</a>
</li>
<li>
<a href="../../contributing/documentation/">Documentation Guide</a>
</li>
</ul>
</li>
<li class="dropdown-submenu">
<a href="" tabindex="-1">About</a>
<ul class="dropdown-menu">
<li>
<a href="../../about/release-notes/">Release Notes</a>
</li>
<li>
<a href="../../about/roadmap/">Roadmap</a>
</li>
<li>
<a href="../../about/faq/">FAQ</a>
</li>
<li>
<a href="../../about/license/">License</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
<a data-target="#mkdocs_search_modal" data-toggle="modal" href="#">
<i class="fas fa-search"></i> Search
                        </a>
</li>
<li>
<a href="../../user-guide/troubleshooting/" rel="prev">
<i class="fas fa-arrow-left"></i> Previous
                        </a>
</li>
<li>
<a href="../tabpfn/" rel="next">
                            Next <i class="fas fa-arrow-right"></i>
</a>
</li>
<li>
<a href="https://github.com/Lexsi-Labs/TabTune/edit/master/docs/models/overview.md">Edit on Lexsi-Labs/TabTune</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
<ul class="nav bs-sidenav">
<li class="first-level active"><a href="#supported-models-overview">Supported Models Overview</a></li>
<li class="second-level"><a href="#1-model-ecosystem">1. Model Ecosystem</a></li>
<li class="second-level"><a href="#2-model-comparison-matrix">2. Model Comparison Matrix</a></li>
<li class="second-level"><a href="#3-selection-quick-tips">3. Selection Quick Tips</a></li>
<li class="second-level"><a href="#4-feature-support-matrix">4. Feature Support Matrix</a></li>
<li class="second-level"><a href="#5-performance-benchmarks">5. Performance Benchmarks</a></li>
<li class="third-level"><a href="#51-accuracy-benchmarks">5.1 Accuracy Benchmarks</a></li>
<li class="third-level"><a href="#52-training-time-benchmarks">5.2 Training Time Benchmarks</a></li>
<li class="third-level"><a href="#53-memory-usage-estimates">5.3 Memory Usage Estimates</a></li>
<li class="third-level"><a href="#54-inference-latency">5.4 Inference Latency</a></li>
<li class="third-level"><a href="#55-benchmark-methodology">5.5 Benchmark Methodology</a></li>
</ul>
</div></div>
<div class="col-md-9" role="main">
<h1 id="supported-models-overview">Supported Models Overview<a class="headerlink" href="#supported-models-overview" title="Permanent link">¶</a></h1>
<p>TabTune integrates state-of-the-art tabular foundation models, each with unique architectural properties, strengths, and use cases. This document provides a comprehensive overview of all supported models.</p>
<hr/>
<h2 id="1-model-ecosystem">1. Model Ecosystem<a class="headerlink" href="#1-model-ecosystem" title="Permanent link">¶</a></h2>
<div class="mermaid">flowchart TD
    A[Tabular Foundation Models] --&gt; B[ICL-Based Models]
    A --&gt; C[Transformer-Based Models]
    A --&gt; D[PFN-Based Models]

    B --&gt; E[TabICL]
    B --&gt; F[OrionMSP]
    B --&gt; G[Orion BIX]
    B --&gt; H[Mitra]
    B --&gt; I[ContextTab]

    C --&gt; J[TabDPT]

    D --&gt; K[TabPFN]
</div>
<hr/>
<h2 id="2-model-comparison-matrix">2. Model Comparison Matrix<a class="headerlink" href="#2-model-comparison-matrix" title="Permanent link">¶</a></h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>Paradigm</th>
<th>Architecture</th>
<th>Best For</th>
<th>Scaling</th>
<th>Speed</th>
<th>Memory</th>
<th>PEFT</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TabPFN</strong></td>
<td>PFN/ICL</td>
<td>Approximate Bayesian</td>
<td>Small datasets</td>
<td>&lt;10K</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐</td>
<td>⚠️</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>Scalable ICL</td>
<td>Column-Row Attention</td>
<td>Balanced</td>
<td>10K-1M</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐</td>
<td>✅</td>
</tr>
<tr>
<td><strong>OrionMSP</strong></td>
<td>Scalable ICL</td>
<td>Multi‑scale priors</td>
<td>Generalization</td>
<td>50K-2M+</td>
<td>⭐⭐⭐</td>
<td>⭐⭐⭐</td>
<td>✅</td>
</tr>
<tr>
<td><strong>Orion BIX</strong></td>
<td>Scalable ICL</td>
<td>Biaxial interactions</td>
<td>Accuracy</td>
<td>50K-2M+</td>
<td>⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>✅</td>
</tr>
<tr>
<td><strong>TabDPT</strong></td>
<td>Denoising</td>
<td>Transformer</td>
<td>Large Datasets</td>
<td>100K-5M</td>
<td>⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>✅</td>
</tr>
<tr>
<td><strong>Mitra</strong></td>
<td>2D Attention</td>
<td>Cross‑Attention</td>
<td>Complex Patterns</td>
<td>10K-500K</td>
<td>⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>✅</td>
</tr>
<tr>
<td><strong>ContextTab</strong></td>
<td>Semantic ICL</td>
<td>Text + Embeddings</td>
<td>Text-Heavy</td>
<td>10K-500K</td>
<td>⭐⭐</td>
<td>⭐⭐⭐</td>
<td>⚠️</td>
</tr>
</tbody>
</table>
<hr/>
<h2 id="3-selection-quick-tips">3. Selection Quick Tips<a class="headerlink" href="#3-selection-quick-tips" title="Permanent link">¶</a></h2>
<ul>
<li>&lt;10K rows: TabPFN (inference) or TabICL (base‑ft)</li>
<li>50K–2M rows: OrionMSP (balanced) or Orion BIX (accuracy‑oriented)</li>
<li>
<blockquote>
<p>2M rows: TabDPT (base‑ft/PEFT)</p>
</blockquote>
</li>
<li>Text‑heavy features: ContextTab</li>
</ul>
<hr/>
<h2 id="4-feature-support-matrix">4. Feature Support Matrix<a class="headerlink" href="#4-feature-support-matrix" title="Permanent link">¶</a></h2>
<table>
<thead>
<tr>
<th>Feature</th>
<th>TabPFN</th>
<th>TabICL</th>
<th>OrionMSP</th>
<th>OrionBix</th>
<th>TabDPT</th>
<th>Mitra</th>
<th>ContextTab</th>
</tr>
</thead>
<tbody>
<tr>
<td>Numerical Features</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Categorical Features</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Missing Values</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Text Features</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>✅</td>
</tr>
<tr>
<td>Large Datasets (&gt;1M)</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>⚠️</td>
<td>❌</td>
</tr>
<tr>
<td>Small Datasets (&lt;10K)</td>
<td>✅</td>
<td>✅</td>
<td>⚠️</td>
<td>⚠️</td>
<td>⚠️</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>PEFT Support</td>
<td>⚠️</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>⚠️</td>
</tr>
<tr>
<td>Multi-GPU Training</td>
<td>❌</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody>
</table>
<hr/>
<h2 id="5-performance-benchmarks">5. Performance Benchmarks<a class="headerlink" href="#5-performance-benchmarks" title="Permanent link">¶</a></h2>
<p>Performance characteristics vary significantly based on dataset size, hardware, and hyperparameters. The following benchmarks provide rough estimates based on typical configurations.</p>
<div class="admonition note">
<p class="admonition-title">Benchmark Disclaimer</p>
<p>All benchmarks are approximate and depend on:
- Hardware (GPU model, CPU, memory)
- Dataset characteristics (size, features, class distribution)
- Hyperparameter settings
- Software versions</p>
<p>Use these as rough guidelines for relative comparisons.</p>
</div>
<h3 id="51-accuracy-benchmarks">5.1 Accuracy Benchmarks<a class="headerlink" href="#51-accuracy-benchmarks" title="Permanent link">¶</a></h3>
<p>Typical accuracy ranges on standard OpenML datasets (medium-sized, ~10K-50K samples):</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Strategy</th>
<th>Accuracy Range</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TabPFN</strong></td>
<td>inference</td>
<td>0.75-0.85</td>
<td>Best on small, clean datasets</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>base-ft</td>
<td>0.80-0.92</td>
<td>Balanced performance</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>peft</td>
<td>0.78-0.90</td>
<td>~2-5% below base-ft</td>
</tr>
<tr>
<td><strong>OrionMSP</strong></td>
<td>base-ft</td>
<td>0.82-0.93</td>
<td>Strong generalization</td>
</tr>
<tr>
<td><strong>OrionBix</strong></td>
<td>base-ft</td>
<td>0.85-0.94</td>
<td>Highest accuracy potential</td>
</tr>
<tr>
<td><strong>TabDPT</strong></td>
<td>base-ft</td>
<td>0.83-0.92</td>
<td>Excellent on large datasets</td>
</tr>
<tr>
<td><strong>Mitra</strong></td>
<td>base-ft</td>
<td>0.84-0.93</td>
<td>Complex pattern handling</td>
</tr>
<tr>
<td><strong>ContextTab</strong></td>
<td>base-ft</td>
<td>0.75-0.88</td>
<td>Best with text features</td>
</tr>
</tbody>
</table>
<p><strong>Notes:</strong>
- Ranges represent typical performance on diverse datasets
- Your results may vary significantly based on dataset characteristics
- Fine-tuning (base-ft/peft) generally outperforms inference by 5-15%</p>
<h3 id="52-training-time-benchmarks">5.2 Training Time Benchmarks<a class="headerlink" href="#52-training-time-benchmarks" title="Permanent link">¶</a></h3>
<p>Approximate training times (5 epochs, medium dataset ~20K samples, NVIDIA RTX 3090):</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Strategy</th>
<th>Training Time</th>
<th>Speed Factor</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TabPFN</strong></td>
<td>inference</td>
<td>0s</td>
<td>Instant</td>
</tr>
<tr>
<td><strong>TabPFN</strong></td>
<td>base-ft</td>
<td>10-30 min</td>
<td>Fast</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>inference</td>
<td>&lt;1 min</td>
<td>Very fast</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>base-ft</td>
<td>15-45 min</td>
<td>Moderate</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>peft</td>
<td>8-20 min</td>
<td>Fast</td>
</tr>
<tr>
<td><strong>OrionMSP</strong></td>
<td>base-ft</td>
<td>30-90 min</td>
<td>Moderate-Slow</td>
</tr>
<tr>
<td><strong>OrionBix</strong></td>
<td>base-ft</td>
<td>45-120 min</td>
<td>Slow</td>
</tr>
<tr>
<td><strong>TabDPT</strong></td>
<td>base-ft</td>
<td>20-60 min</td>
<td>Moderate</td>
</tr>
<tr>
<td><strong>Mitra</strong></td>
<td>base-ft</td>
<td>60-180 min</td>
<td>Slow</td>
</tr>
<tr>
<td><strong>ContextTab</strong></td>
<td>base-ft</td>
<td>30-90 min</td>
<td>Moderate-Slow</td>
</tr>
</tbody>
</table>
<p><strong>Factors affecting training time:</strong>
- Dataset size (rows × features)
- Number of epochs
- Batch size
- GPU/CPU speed
- Model complexity</p>
<h3 id="53-memory-usage-estimates">5.3 Memory Usage Estimates<a class="headerlink" href="#53-memory-usage-estimates" title="Permanent link">¶</a></h3>
<p>Peak memory usage during training (approximate, GPU memory):</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Strategy</th>
<th>Memory Range</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TabPFN</strong></td>
<td>inference</td>
<td>2-4 GB</td>
<td>Small datasets</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>inference</td>
<td>3-6 GB</td>
<td>Moderate</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>base-ft</td>
<td>8-16 GB</td>
<td>Full model</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>peft</td>
<td>4-8 GB</td>
<td>40-50% reduction</td>
</tr>
<tr>
<td><strong>OrionMSP</strong></td>
<td>base-ft</td>
<td>10-20 GB</td>
<td>Large context</td>
</tr>
<tr>
<td><strong>OrionBix</strong></td>
<td>base-ft</td>
<td>12-24 GB</td>
<td>Biaxial layers</td>
</tr>
<tr>
<td><strong>TabDPT</strong></td>
<td>base-ft</td>
<td>12-28 GB</td>
<td>Large transformer</td>
</tr>
<tr>
<td><strong>Mitra</strong></td>
<td>base-ft</td>
<td>16-32 GB</td>
<td>2D attention</td>
</tr>
<tr>
<td><strong>ContextTab</strong></td>
<td>base-ft</td>
<td>8-16 GB</td>
<td>Embedding overhead</td>
</tr>
</tbody>
</table>
<p><strong>Memory optimization tips:</strong>
- Use PEFT strategy (reduces memory by 40-60%)
- Reduce batch size
- Use gradient accumulation
- Process large datasets in chunks</p>
<h3 id="54-inference-latency">5.4 Inference Latency<a class="headerlink" href="#54-inference-latency" title="Permanent link">¶</a></h3>
<p>Average inference time per batch (batch_size=32, GPU):</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Latency (ms/batch)</th>
<th>Throughput (samples/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TabPFN</strong></td>
<td>10-50</td>
<td>640-3200</td>
</tr>
<tr>
<td><strong>TabICL</strong></td>
<td>20-80</td>
<td>400-1600</td>
</tr>
<tr>
<td><strong>OrionMSP</strong></td>
<td>40-120</td>
<td>267-800</td>
</tr>
<tr>
<td><strong>OrionBix</strong></td>
<td>60-150</td>
<td>213-533</td>
</tr>
<tr>
<td><strong>TabDPT</strong></td>
<td>30-100</td>
<td>320-1067</td>
</tr>
<tr>
<td><strong>Mitra</strong></td>
<td>80-200</td>
<td>160-400</td>
</tr>
<tr>
<td><strong>ContextTab</strong></td>
<td>100-300</td>
<td>107-320</td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong> Latency increases with dataset size (for ICL models that use training data as context).</p>
<h3 id="55-benchmark-methodology">5.5 Benchmark Methodology<a class="headerlink" href="#55-benchmark-methodology" title="Permanent link">¶</a></h3>
<p>When comparing models:</p>
<ol>
<li><strong>Use same dataset splits</strong>: Ensure train/test consistency</li>
<li><strong>Same preprocessing</strong>: Use identical DataProcessor settings</li>
<li><strong>Multiple runs</strong>: Average over 3-5 runs with different seeds</li>
<li><strong>Hardware consistency</strong>: Same GPU/CPU for fair comparison</li>
<li><strong>Hyperparameter tuning</strong>: Optimize each model fairly</li>
</ol>
<p><strong>Recommended benchmark datasets:</strong>
- OpenML datasets (42178, 1489, etc.)
- Your domain-specific datasets
- Standard UCI ML datasets</p>
<hr/>
<p>Each model excels in different scenarios. Use this overview to pick the best fit for your task.</p></div>
</div>
<footer class="col-md-12 text-center">
<hr/>
<p>
<small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
</p>
</footer>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="../../js/bootstrap-3.0.3.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/python.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/yaml.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>var base_url = "../.."</script>
<script src="../../js/base.js"></script>
<script src="../../search/main.js"></script>
<script>
        // Initialize Mermaid v9.x after DOM loads
        // The mermaid2 plugin loads the library and sets window.mermaidConfig
        (function() {
            function initMermaid() {
                if (typeof mermaid !== 'undefined') {
                    // Get configuration from plugin or use defaults
                    const config = window.mermaidConfig || {
                        securityLevel: 'loose',
                        startOnLoad: false
                    };
                    
                    // Initialize mermaid with config
                    mermaid.initialize(config);
                    
                    // Render all mermaid diagrams - mermaid.run() automatically finds .mermaid elements
                    if (typeof mermaid.run === 'function') {
                        mermaid.run();
                    } else {
                        // Fallback for older API - manually initialize elements
                        const mermaidElements = document.querySelectorAll('.mermaid');
                        if (mermaidElements.length > 0) {
                            mermaid.init(undefined, mermaidElements);
                        }
                    }
                } else {
                    // Retry if mermaid library hasn't loaded yet
                    setTimeout(initMermaid, 100);
                }
            }
            
            // Wait for DOM and scripts to be ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', initMermaid);
            } else {
                // DOM already loaded, but scripts might not be
                setTimeout(initMermaid, 100);
            }
        })();
    </script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">×</span>
<span class="sr-only">Close</span>
</button>
<h4 class="modal-title" id="searchModalLabel">Search</h4>
</div>
<div class="modal-body">
<p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="text"/>
</div>
</form>
<div id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
<script src="https://unpkg.com/mermaid@9.4.3/dist/mermaid.min.js"></script><script>mermaid.initialize({
    securityLevel: "loose",
    startOnLoad: false
});</script></body>
</html>
