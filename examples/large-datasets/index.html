<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="TabTune Development Team" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Large Datasets - TabTune Documentation</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" />
        <link href="../../assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Large Datasets";
        var mkdocs_page_input_path = "examples/large-datasets.md";
        var mkdocs_page_url = null;
      </script>
    
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/languages/yaml.min.js"></script>
      <script>hljs.highlightAll();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../..">
          <img src="../../assets/tabtune.svg" class="logo" alt="Logo"/>
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Getting Started</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/installation/">Installation</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../getting-started/quick-start/">Quick Start</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../getting-started/basic-concepts.md">Basic Concepts</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">User Guide</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/data-processing/">Data Processing</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/model-selection/">Model Selection</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/saving-loading/">Saving and Loading</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../user-guide/leaderboard/">Model Comparison</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Models</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/overview/">Overview</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/tabpfn/">TabPFN</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/tabicl/">TabICL</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../models/tabbiaxial.md">TabBiaxial</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/tabdpt/">TabDPT</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/mitra/">Mitra</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../models/contexttab/">ConTextTab</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Advanced Topics</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../advanced/peft-lora/">PEFT & LoRA</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">API Reference</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../../api/pipeline.md">TabularPipeline</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../api/data-processor.md">DataProcessor</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../api/tuning-manager.md">TuningManager</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../api/leaderboard.md">TabularLeaderboard</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../api/peft-utils.md">PEFT Utils</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Examples</span></p>
              <ul class="current">
                  <li class="toctree-l1"><a class="reference internal" href="../classification/">Classification Tasks</a>
                  </li>
                  <li class="toctree-l1 current"><a class="reference internal current" href="#">Large Datasets</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../peft-examples/">PEFT Fine-Tuning</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../benchmarking.md">Benchmarking</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Contributing</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../../contributing/setup.md">Development Setup</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../contributing/standards.md">Code Standards</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../contributing/new-models.md">Adding New Models</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../contributing/documentation.md">Documentation Guide</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">About</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../../about/release-notes.md">Release Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../about/roadmap.md">Roadmap</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../about/faq.md">FAQ</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../about/license.md">License</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">TabTune Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a></li>
          <li class="breadcrumb-item">Examples</li>
      <li class="breadcrumb-item active">Large Datasets</li>
    <li class="wy-breadcrumbs-aside">
          <a href="https://github.com/Lexsi-Labs/TabTune_Internal/edit/master/docs/examples/large-datasets.md">Edit on Lexsi-Labs/TabTune_Internal</a>
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <!-- # Large Datasets: Strategies for Training on Big Data with TabTune

This document provides comprehensive strategies for efficiently training TabTune models on large datasets (100K+ rows), covering data loading, batch processing, memory management, and distributed training.

---

## 1. Introduction

Large dataset challenges:

- **Memory**: Dataset may not fit in GPU/CPU memory
- **Speed**: Training time becomes impractical
- **I/O**: Data loading becomes bottleneck
- **Distribution**: Need for multi-GPU/multi-machine training

This guide covers techniques for each challenge.

---

## 2. Data Size Categories

<div class="highlight"><pre><span></span><code>Small:        &lt; 10K rows     → Fit in memory, single GPU
Medium:       10K - 100K     → Fit in memory, may need optimization
Large:        100K - 1M      → Requires batching, multi-GPU recommended
Very Large:   1M - 10M       → Multi-GPU necessary, streaming required
Massive:      10M+           → Distributed systems, data infrastructure
</code></pre></div>

---

## 3. Dataset Streaming & Loading

### 3.1 Efficient Data Loading

**Problem**: Loading entire dataset to memory fails

<div class="highlight"><pre><span></span><code><span class="c1"># ❌ BAD: Load all at once</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;huge_file.csv&#39;</span><span class="p">)</span>  <span class="c1"># Out of memory!</span>

<span class="c1"># ✅ GOOD: Stream in chunks</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_data_chunks</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load data in chunks.&quot;&quot;&quot;</span>
    <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
        <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># ✅ BETTER: Process directly without loading all</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_in_chunks</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process chunks without loading entire dataset.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">chunk</span>
</code></pre></div>

### 3.2 Using Parquet for Efficiency

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>

<span class="c1"># Convert large CSV to Parquet (faster, efficient)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;snappy&#39;</span><span class="p">)</span>

<span class="c1"># Load Parquet efficiently</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

<span class="c1"># Or read specific columns only</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
</code></pre></div>

### 3.3 PyArrow for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>

<span class="c1"># Efficient columnar storage</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">float32</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;feature2&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int8</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Read with filtering (push-down predicates)</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
    <span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span>
    <span class="n">filters</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;&gt;=&#39;</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>  <span class="c1"># Filter at read time</span>
<span class="p">)</span>
</code></pre></div>

---

## 4. Batch Processing Strategy

### 4.1 Mini-Batch Training Loop

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_with_batching</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train on large dataset using mini-batches.&quot;&quot;&quot;</span>

    <span class="c1"># Load data in chunks</span>
    <span class="n">all_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">all_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">all_data</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Train</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>  <span class="c1"># Best for large data</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
            <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>  <span class="c1"># Large context for TabDPT</span>
            <span class="s1">&#39;show_progress&#39;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy on </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipeline</span>
</code></pre></div>

### 4.2 Data Generator for Memory Efficiency

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DataGenerator</span><span class="p">(</span><span class="n">Sequence</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate batches from disk without loading all data.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get shape only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_rows</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get batch at index.&quot;&quot;&quot;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span>
            <span class="n">skiprows</span><span class="o">=</span><span class="n">start</span><span class="p">,</span>
            <span class="n">nrows</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">batch</span>

<span class="c1"># Usage</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="s1">&#39;huge_data.csv&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="c1"># Process batch</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch shape: </span><span class="si">{</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

---

## 5. Model Selection for Large Data

### 5.1 Recommended Models by Dataset Size

<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">choose_model_for_size</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">available_memory_gb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Recommend model based on dataset size and resources.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">50000</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabPFN&#39;</span>  <span class="c1"># Zero-shot, very fast</span>
    <span class="k">elif</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">500000</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">available_memory_gb</span> <span class="o">&gt;</span> <span class="mi">12</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">&#39;TabBiaxial&#39;</span>  <span class="c1"># High accuracy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">&#39;TabICL&#39;</span>  <span class="c1"># Balanced</span>
    <span class="k">elif</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">5000000</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabDPT&#39;</span>  <span class="c1"># Large-scale champion</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabDPT&#39;</span>  <span class="c1"># Must use most scalable</span>

<span class="c1"># Check system resources</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">available_gpus</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
<span class="n">gpu_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="mf">1e9</span>

<span class="n">recommended_model</span> <span class="o">=</span> <span class="n">choose_model_for_size</span><span class="p">(</span>
    <span class="n">num_rows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
    <span class="n">available_memory_gb</span><span class="o">=</span><span class="n">gpu_memory</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recommended model: </span><span class="si">{</span><span class="n">recommended_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

### 5.2 TabDPT for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># TabDPT is specifically designed for large datasets</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>      <span class="c1"># Large context</span>
        <span class="s1">&#39;query_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
        <span class="s1">&#39;k_neighbors&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>          <span class="c1"># k-NN context</span>
        <span class="s1">&#39;steps_per_epoch&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>  <span class="c1"># Memory efficient</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

---

## 6. Memory Optimization for Large Data

### 6.1 Memory Budget Analysis

<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">estimate_memory_requirements</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate GPU memory needed.&quot;&quot;&quot;</span>

    <span class="c1"># Rough estimates (in GB)</span>
    <span class="n">estimates</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;TabPFN&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">,</span>
        <span class="s1">&#39;TabICL&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;TabBiaxial&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s1">&#39;TabDPT&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mf">3.5</span>
    <span class="p">}</span>

    <span class="n">base_mem</span> <span class="o">=</span> <span class="n">estimates</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Add optimizer, gradients, buffers (~2x)</span>
    <span class="n">total_mem</span> <span class="o">=</span> <span class="n">base_mem</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">total_mem</span>

<span class="c1"># Example</span>
<span class="n">mem_needed</span> <span class="o">=</span> <span class="n">estimate_memory_requirements</span><span class="p">(</span>
    <span class="n">n_rows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated memory needed: </span><span class="si">{</span><span class="n">mem_needed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

<span class="c1"># With PEFT (70% reduction)</span>
<span class="n">mem_peft</span> <span class="o">=</span> <span class="n">mem_needed</span> <span class="o">*</span> <span class="mf">0.3</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;With PEFT: </span><span class="si">{</span><span class="n">mem_peft</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>
</code></pre></div>

### 6.2 PEFT for Large Data Training

<div class="highlight"><pre><span></span><code><span class="c1"># Use PEFT to train large models with limited memory</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>  <span class="c1"># Can still use large support</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="mf">0.05</span>
        <span class="p">},</span>
        <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div>

---

## 7. Distributed Training for Large Data

### 7.1 Multi-GPU Training

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedDataParallel</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_distributed_large</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train on large data across multiple GPUs.&quot;&quot;&quot;</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Load dataset</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_large_dataset</span><span class="p">()</span>

    <span class="c1"># Create distributed sampler</span>
    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
        <span class="n">num_replicas</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span>
    <span class="p">)</span>

    <span class="c1"># Scale learning rate with world size</span>
    <span class="n">base_lr</span> <span class="o">=</span> <span class="mf">2e-5</span>
    <span class="n">scaled_lr</span> <span class="o">=</span> <span class="n">base_lr</span> <span class="o">*</span> <span class="n">world_size</span>

    <span class="c1"># Create and train</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">scaled_lr</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Wrap with DDP</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Train on subset</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">train_sampler</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">X_train_local</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">y_train_local</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_local</span><span class="p">,</span> <span class="n">y_train_local</span><span class="p">)</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>

<span class="c1"># Launch with: torchrun --nproc_per_node=4 script.py</span>
</code></pre></div>

---

## 8. Data Preprocessing at Scale

### 8.1 Streaming Preprocessing

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">class</span><span class="w"> </span><span class="nc">StreamingPreprocessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply preprocessing in streaming fashion.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit on sample of large dataset.&quot;&quot;&quot;</span>
        <span class="c1"># Fit on first chunk only</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">output_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform large file in chunks.&quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">first_chunk</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
                <span class="n">transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">first_chunk</span><span class="p">:</span>
                    <span class="n">transformed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">first_chunk</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">transformed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">StreamingPreprocessor</span><span class="p">()</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="s1">&#39;large_data.csv&#39;</span><span class="p">)</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">transform_file</span><span class="p">(</span><span class="s1">&#39;large_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;processed_data.csv&#39;</span><span class="p">)</span>
</code></pre></div>

### 8.2 Feature Selection for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="k">def</span><span class="w"> </span><span class="nf">select_important_features</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select top-k features to reduce dimensionality.&quot;&quot;&quot;</span>

    <span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original features: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">selected_features</span><span class="p">,</span> <span class="n">selector</span>

<span class="c1"># Usage</span>
<span class="n">important_features</span><span class="p">,</span> <span class="n">selector</span> <span class="o">=</span> <span class="n">select_important_features</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>

<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">important_features</span><span class="p">]</span>
<span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">important_features</span><span class="p">]</span>
</code></pre></div>

---

## 9. Production Pipeline for Large Data

### 9.1 Complete Large-Data Training Pipeline

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LargeDataPipeline</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Production pipeline for large datasets.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">important_features</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load data efficiently.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading data from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">total_rows</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">):</span>
            <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">total_rows</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">total_rows</span> <span class="o">%</span> <span class="mi">500000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">total_rows</span><span class="si">}</span><span class="s2"> rows...&quot;</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total rows loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reduce memory footprint.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preprocessing...&quot;</span><span class="p">)</span>

        <span class="c1"># Convert to optimal dtypes</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">]):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">]):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory usage: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train on large dataset.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training...&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
            <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
                <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
                <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
                <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span>
                <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save trained model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load trained model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">large_pipeline</span> <span class="o">=</span> <span class="n">LargeDataPipeline</span><span class="p">(</span>
        <span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;large_dataset.csv&#39;</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span>
    <span class="p">)</span>

    <span class="c1"># Load data (can specify nrows for testing)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="c1"># Preprocess</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Split</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Train</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

    <span class="c1"># Save</span>
    <span class="n">large_pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;large_model.joblib&#39;</span><span class="p">)</span>
</code></pre></div>

---

## 10. Performance Tuning for Large Data

### 10.1 Bottleneck Analysis

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PerformanceMonitor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Monitor training performance.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">report</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print bottleneck analysis.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Performance Report ===&quot;</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">phase</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">percent</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">8.2f</span><span class="si">}</span><span class="s2">s (</span><span class="si">{</span><span class="n">percent</span><span class="si">:</span><span class="s2">5.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Total&#39;</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">total</span><span class="si">:</span><span class="s2">8.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">monitor</span> <span class="o">=</span> <span class="n">PerformanceMonitor</span><span class="p">()</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;data_loading&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">load_large_dataset</span><span class="p">()</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;data_loading&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;preprocessing&#39;</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;preprocessing&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">report</span><span class="p">()</span>
</code></pre></div>

### 10.2 Optimization Checklist

<div class="highlight"><pre><span></span><code><span class="n">optimization_checklist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Data Loading&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use Parquet instead of CSV&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Stream data in chunks&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use PyArrow for efficiency&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Memory&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use PEFT if memory-constrained&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use mixed precision (fp16)&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Reduce batch size if needed&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use gradient accumulation&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Speed&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use multi-GPU training&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Enable data parallelism&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Optimize learning rate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use larger support_size for TabDPT&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use base-ft if memory allows&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Increase epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Try TabDPT for large data&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use cross-validation&#39;</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">optimization_checklist</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">item</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

---

## 11. Troubleshooting Large Data Issues

### 11.1 Common Problems & Solutions

<div class="highlight"><pre><span></span><code>Problem: Data loading is slow
Solutions:
  - Convert CSV to Parquet
  - Use column selection
  - Increase chunksize
  - Use parallel loading (Dask)

Problem: Training takes too long
Solutions:
  - Use multi-GPU training
  - Reduce dataset size (sampling)
  - Use smaller models (TabPFN vs TabDPT)
  - Use PEFT instead of base-ft

Problem: Out of memory during training
Solutions:
  - Use PEFT strategy
  - Reduce batch size
  - Use mixed precision (fp16)
  - Use gradient accumulation
  - Reduce support_size

Problem: Accuracy worse with large data
Solutions:
  - Ensure proper train/test split
  - Check for data quality issues
  - Use cross-validation
  - Increase training epochs
</code></pre></div>

---

## 12. Best Practices

### ✅ Do's

- ✅ Profile data loading first
- ✅ Use Parquet for large datasets
- ✅ Use PEFT for memory efficiency
- ✅ Monitor memory during training
- ✅ Use multi-GPU when available
- ✅ Use TabDPT for 100K+ rows
- ✅ Implement proper checkpointing
- ✅ Test on sample before full dataset

### ❌ Don'ts

- ❌ Don't load entire large dataset at once
- ❌ Don't use small batch sizes without necessity
- ❌ Don't ignore data quality
- ❌ Don't skip train/validation split
- ❌ Don't forget to scale learning rate for multi-GPU

---

## 13. Quick Reference

| Dataset Size | Recommended Model | Strategy | PEFT | Multi-GPU |
|--------------|-------------------|----------|------|-----------|
| 100K | TabICL | base-ft | No | Optional |
| 500K | TabDPT | base-ft | No | Recommended |
| 1M | TabDPT | base-ft | Optional | Yes |
| 5M+ | TabDPT | peft | Yes | Yes |

---

## 14. Next Steps

- [Memory Optimization](memory-optimization.md) - Detailed memory techniques
- [Multi-GPU Training](multi-gpu.md) - Distributed training details
- [Model Selection](../user-guide/model-selection.md) - Choose right model
- [Tuning Strategies](../user-guide/tuning-strategies.md) - Optimization strategies

---

Train TabTune models efficiently on datasets ranging from hundreds of thousands to millions of samples! -->
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../classification/" class="btn btn-neutral float-left" title="Classification Tasks"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../peft-examples/" class="btn btn-neutral float-right" title="PEFT Fine-Tuning">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/Lexsi-Labs/TabTune_Internal" class="fa fa-code-fork" style="color: #fcfcfc"> Lexsi-Labs/TabTune_Internal</a>
        </span>
    
    
      <span><a href="../classification/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../peft-examples/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script src="../../js/jquery-3.6.0.min.js"></script>
    <script>var base_url = "../..";</script>
    <script src="../../js/theme_extra.js"></script>
    <script src="../../js/theme.js"></script>
      <script src="../../search/main.js"></script>
    <script>
        jQuery(function () {
            SphinxRtdTheme.Navigation.enable(true);
        });
    </script>

</body>
</html>
