<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Advanced Library for Tabular Model Training and Adaptation">
    <meta name="author" content="TabTune Development Team">
    
    <link rel="shortcut icon" href="../../img/favicon.ico">

    
    <title>Large Datasets - TabTune Documentation</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../../css/base.min.css" rel="stylesheet">
    <link href="../../css/cinder.min.css" rel="stylesheet">

    
        
        <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css">
        
    
    <link href="../../assets/_mkdocstrings.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            
              <a class="navbar-brand" href="../..">TabTune Documentation</a>
            
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../..">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Getting Started <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../getting-started/installation/">Installation</a>
</li>

                        
                            
<li >
    <a href="../../getting-started/quick-start/">Quick Start</a>
</li>

                        
                            
<li >
    <a href="../../getting-started/basic-concepts.md">Basic Concepts</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">User Guide <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
</li>

                        
                            
<li >
    <a href="../../user-guide/data-processing/">Data Processing</a>
</li>

                        
                            
<li >
    <a href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
</li>

                        
                            
<li >
    <a href="../../user-guide/model-selection/">Model Selection</a>
</li>

                        
                            
<li >
    <a href="../../user-guide/saving-loading/">Saving and Loading</a>
</li>

                        
                            
<li >
    <a href="../../user-guide/leaderboard/">Model Comparison</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Models <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../models/overview/">Overview</a>
</li>

                        
                            
<li >
    <a href="../../models/tabpfn/">TabPFN</a>
</li>

                        
                            
<li >
    <a href="../../models/tabicl/">TabICL</a>
</li>

                        
                            
<li >
    <a href="../../models/tabbiaxial.md">TabBiaxial</a>
</li>

                        
                            
<li >
    <a href="../../models/tabdpt/">TabDPT</a>
</li>

                        
                            
<li >
    <a href="../../models/mitra/">Mitra</a>
</li>

                        
                            
<li >
    <a href="../../models/contexttab/">ConTextTab</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced Topics <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../advanced/peft-lora/">PEFT & LoRA</a>
</li>

                        
                            
<li >
    <a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">API Reference <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../api/pipeline.md">TabularPipeline</a>
</li>

                        
                            
<li >
    <a href="../../api/data-processor.md">DataProcessor</a>
</li>

                        
                            
<li >
    <a href="../../api/tuning-manager.md">TuningManager</a>
</li>

                        
                            
<li >
    <a href="../../api/leaderboard.md">TabularLeaderboard</a>
</li>

                        
                            
<li >
    <a href="../../api/peft-utils.md">PEFT Utils</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Examples <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../classification/">Classification Tasks</a>
</li>

                        
                            
<li class="active">
    <a href="./">Large Datasets</a>
</li>

                        
                            
<li >
    <a href="../peft-examples/">PEFT Fine-Tuning</a>
</li>

                        
                            
<li >
    <a href="../benchmarking.md">Benchmarking</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Contributing <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../contributing/setup.md">Development Setup</a>
</li>

                        
                            
<li >
    <a href="../../contributing/standards.md">Code Standards</a>
</li>

                        
                            
<li >
    <a href="../../contributing/new-models.md">Adding New Models</a>
</li>

                        
                            
<li >
    <a href="../../contributing/documentation.md">Documentation Guide</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">About <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../../about/release-notes.md">Release Notes</a>
</li>

                        
                            
<li >
    <a href="../../about/roadmap.md">Roadmap</a>
</li>

                        
                            
<li >
    <a href="../../about/faq.md">FAQ</a>
</li>

                        
                            
<li >
    <a href="../../about/license.md">License</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../classification/">
                            <i class="fas fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="next" href="../peft-examples/">
                            Next <i class="fas fa-arrow-right"></i>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/Lexsi-Labs/TabTune_Internal/edit/master/docs/examples/large-datasets.md">Edit on Lexsi-Labs/TabTune_Internal</a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<!-- # Large Datasets: Strategies for Training on Big Data with TabTune

This document provides comprehensive strategies for efficiently training TabTune models on large datasets (100K+ rows), covering data loading, batch processing, memory management, and distributed training.

---

## 1. Introduction

Large dataset challenges:

- **Memory**: Dataset may not fit in GPU/CPU memory
- **Speed**: Training time becomes impractical
- **I/O**: Data loading becomes bottleneck
- **Distribution**: Need for multi-GPU/multi-machine training

This guide covers techniques for each challenge.

---

## 2. Data Size Categories

<div class="highlight"><pre><span></span><code>Small:        &lt; 10K rows     → Fit in memory, single GPU
Medium:       10K - 100K     → Fit in memory, may need optimization
Large:        100K - 1M      → Requires batching, multi-GPU recommended
Very Large:   1M - 10M       → Multi-GPU necessary, streaming required
Massive:      10M+           → Distributed systems, data infrastructure
</code></pre></div>

---

## 3. Dataset Streaming & Loading

### 3.1 Efficient Data Loading

**Problem**: Loading entire dataset to memory fails

<div class="highlight"><pre><span></span><code><span class="c1"># ❌ BAD: Load all at once</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;huge_file.csv&#39;</span><span class="p">)</span>  <span class="c1"># Out of memory!</span>

<span class="c1"># ✅ GOOD: Stream in chunks</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_data_chunks</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load data in chunks.&quot;&quot;&quot;</span>
    <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
        <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># ✅ BETTER: Process directly without loading all</span>
<span class="k">def</span><span class="w"> </span><span class="nf">process_in_chunks</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process chunks without loading entire dataset.&quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
        <span class="k">yield</span> <span class="n">chunk</span>
</code></pre></div>

### 3.2 Using Parquet for Efficiency

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>

<span class="c1"># Convert large CSV to Parquet (faster, efficient)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_parquet</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;snappy&#39;</span><span class="p">)</span>

<span class="c1"># Load Parquet efficiently</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

<span class="c1"># Or read specific columns only</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span><span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
</code></pre></div>

### 3.3 PyArrow for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pa</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pyarrow.parquet</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pq</span>

<span class="c1"># Efficient columnar storage</span>
<span class="n">schema</span> <span class="o">=</span> <span class="n">pa</span><span class="o">.</span><span class="n">schema</span><span class="p">([</span>
    <span class="p">(</span><span class="s1">&#39;feature1&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">float32</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;feature2&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int32</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">pa</span><span class="o">.</span><span class="n">int8</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Read with filtering (push-down predicates)</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pq</span><span class="o">.</span><span class="n">read_table</span><span class="p">(</span>
    <span class="s1">&#39;data.parquet&#39;</span><span class="p">,</span>
    <span class="n">filters</span><span class="o">=</span><span class="p">[(</span><span class="s1">&#39;year&#39;</span><span class="p">,</span> <span class="s1">&#39;&gt;=&#39;</span><span class="p">,</span> <span class="mi">2020</span><span class="p">)]</span>  <span class="c1"># Filter at read time</span>
<span class="p">)</span>
</code></pre></div>

---

## 4. Batch Processing Strategy

### 4.1 Mini-Batch Training Loop

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_with_batching</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train on large dataset using mini-batches.&quot;&quot;&quot;</span>

    <span class="c1"># Load data in chunks</span>
    <span class="n">all_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">all_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">all_data</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Train</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>  <span class="c1"># Best for large data</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
            <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>  <span class="c1"># Large context for TabDPT</span>
            <span class="s1">&#39;show_progress&#39;</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy on </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pipeline</span>
</code></pre></div>

### 4.2 Data Generator for Memory Efficiency

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequence</span>

<span class="k">class</span><span class="w"> </span><span class="nc">DataGenerator</span><span class="p">(</span><span class="n">Sequence</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate batches from disk without loading all data.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Get shape only</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">total_rows</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">total_rows</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get batch at index.&quot;&quot;&quot;</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">idx</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span>
            <span class="n">skiprows</span><span class="o">=</span><span class="n">start</span><span class="p">,</span>
            <span class="n">nrows</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">batch</span>

<span class="c1"># Usage</span>
<span class="n">generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="s1">&#39;huge_data.csv&#39;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">50000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total batches: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">generator</span><span class="p">:</span>
    <span class="c1"># Process batch</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Batch shape: </span><span class="si">{</span><span class="n">batch</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

---

## 5. Model Selection for Large Data

### 5.1 Recommended Models by Dataset Size

<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">choose_model_for_size</span><span class="p">(</span><span class="n">num_rows</span><span class="p">,</span> <span class="n">available_memory_gb</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Recommend model based on dataset size and resources.&quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">50000</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabPFN&#39;</span>  <span class="c1"># Zero-shot, very fast</span>
    <span class="k">elif</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">500000</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">available_memory_gb</span> <span class="o">&gt;</span> <span class="mi">12</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">&#39;TabBiaxial&#39;</span>  <span class="c1"># High accuracy</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s1">&#39;TabICL&#39;</span>  <span class="c1"># Balanced</span>
    <span class="k">elif</span> <span class="n">num_rows</span> <span class="o">&lt;</span> <span class="mi">5000000</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabDPT&#39;</span>  <span class="c1"># Large-scale champion</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;TabDPT&#39;</span>  <span class="c1"># Must use most scalable</span>

<span class="c1"># Check system resources</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="n">available_gpus</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
<span class="n">gpu_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="mf">1e9</span>

<span class="n">recommended_model</span> <span class="o">=</span> <span class="n">choose_model_for_size</span><span class="p">(</span>
    <span class="n">num_rows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
    <span class="n">available_memory_gb</span><span class="o">=</span><span class="n">gpu_memory</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Recommended model: </span><span class="si">{</span><span class="n">recommended_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

### 5.2 TabDPT for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># TabDPT is specifically designed for large datasets</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">2048</span><span class="p">,</span>      <span class="c1"># Large context</span>
        <span class="s1">&#39;query_size&#39;</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
        <span class="s1">&#39;k_neighbors&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>          <span class="c1"># k-NN context</span>
        <span class="s1">&#39;steps_per_epoch&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>  <span class="c1"># Memory efficient</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

---

## 6. Memory Optimization for Large Data

### 6.1 Memory Budget Analysis

<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">estimate_memory_requirements</span><span class="p">(</span><span class="n">n_rows</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate GPU memory needed.&quot;&quot;&quot;</span>

    <span class="c1"># Rough estimates (in GB)</span>
    <span class="n">estimates</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;TabPFN&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mf">1.5</span><span class="p">,</span>
        <span class="s1">&#39;TabICL&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;TabBiaxial&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s1">&#39;TabDPT&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">n_rows</span> <span class="o">*</span> <span class="n">n_features</span> <span class="o">*</span> <span class="mi">4</span><span class="p">)</span> <span class="o">/</span> <span class="mf">1e9</span> <span class="o">*</span> <span class="mf">3.5</span>
    <span class="p">}</span>

    <span class="n">base_mem</span> <span class="o">=</span> <span class="n">estimates</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

    <span class="c1"># Add optimizer, gradients, buffers (~2x)</span>
    <span class="n">total_mem</span> <span class="o">=</span> <span class="n">base_mem</span> <span class="o">*</span> <span class="mi">2</span>

    <span class="k">return</span> <span class="n">total_mem</span>

<span class="c1"># Example</span>
<span class="n">mem_needed</span> <span class="o">=</span> <span class="n">estimate_memory_requirements</span><span class="p">(</span>
    <span class="n">n_rows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Estimated memory needed: </span><span class="si">{</span><span class="n">mem_needed</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

<span class="c1"># With PEFT (70% reduction)</span>
<span class="n">mem_peft</span> <span class="o">=</span> <span class="n">mem_needed</span> <span class="o">*</span> <span class="mf">0.3</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;With PEFT: </span><span class="si">{</span><span class="n">mem_peft</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>
</code></pre></div>

### 6.2 PEFT for Large Data Training

<div class="highlight"><pre><span></span><code><span class="c1"># Use PEFT to train large models with limited memory</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>  <span class="c1"># Can still use large support</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="mf">0.05</span>
        <span class="p">},</span>
        <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>
    <span class="p">}</span>
<span class="p">)</span>
</code></pre></div>

---

## 7. Distributed Training for Large Data

### 7.1 Multi-GPU Training

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.distributed</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.nn.parallel</span><span class="w"> </span><span class="kn">import</span> <span class="n">DistributedDataParallel</span>

<span class="k">def</span><span class="w"> </span><span class="nf">train_distributed_large</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Train on large data across multiple GPUs.&quot;&quot;&quot;</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">)</span>
    <span class="n">rank</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_rank</span><span class="p">()</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">get_world_size</span><span class="p">()</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;cuda:</span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="c1"># Load dataset</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_large_dataset</span><span class="p">()</span>

    <span class="c1"># Create distributed sampler</span>
    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
        <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)),</span>
        <span class="n">num_replicas</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="n">rank</span>
    <span class="p">)</span>

    <span class="c1"># Scale learning rate with world size</span>
    <span class="n">base_lr</span> <span class="o">=</span> <span class="mf">2e-5</span>
    <span class="n">scaled_lr</span> <span class="o">=</span> <span class="n">base_lr</span> <span class="o">*</span> <span class="n">world_size</span>

    <span class="c1"># Create and train</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;base-ft&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="n">device</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">scaled_lr</span><span class="p">,</span>
            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Wrap with DDP</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span>
        <span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
        <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="c1"># Train on subset</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">train_sampler</span><span class="o">.</span><span class="n">indices</span>
    <span class="n">X_train_local</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">y_train_local</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_local</span><span class="p">,</span> <span class="n">y_train_local</span><span class="p">)</span>

    <span class="n">dist</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>

<span class="c1"># Launch with: torchrun --nproc_per_node=4 script.py</span>
</code></pre></div>

---

## 8. Data Preprocessing at Scale

### 8.1 Streaming Preprocessing

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataProcessor</span>

<span class="k">class</span><span class="w"> </span><span class="nc">StreamingPreprocessor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply preprocessing in streaming fashion.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span> <span class="o">=</span> <span class="n">DataProcessor</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fit on sample of large dataset.&quot;&quot;&quot;</span>
        <span class="c1"># Fit on first chunk only</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">transform_file</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_path</span><span class="p">,</span> <span class="n">output_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform large file in chunks.&quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">out</span><span class="p">:</span>
            <span class="n">first_chunk</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">input_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="n">chunksize</span><span class="p">):</span>
                <span class="n">transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">first_chunk</span><span class="p">:</span>
                    <span class="n">transformed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">first_chunk</span> <span class="o">=</span> <span class="kc">False</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">transformed</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">StreamingPreprocessor</span><span class="p">()</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="s1">&#39;large_data.csv&#39;</span><span class="p">)</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">transform_file</span><span class="p">(</span><span class="s1">&#39;large_data.csv&#39;</span><span class="p">,</span> <span class="s1">&#39;processed_data.csv&#39;</span><span class="p">)</span>
</code></pre></div>

### 8.2 Feature Selection for Large Data

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">f_classif</span>

<span class="k">def</span><span class="w"> </span><span class="nf">select_important_features</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Select top-k features to reduce dimensionality.&quot;&quot;&quot;</span>

    <span class="n">selector</span> <span class="o">=</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">f_classif</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">X_selected</span> <span class="o">=</span> <span class="n">selector</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">selected_features</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">selector</span><span class="o">.</span><span class="n">get_support</span><span class="p">()]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Original features: </span><span class="si">{</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Selected features: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Features: </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">selected_features</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">selected_features</span><span class="p">,</span> <span class="n">selector</span>

<span class="c1"># Usage</span>
<span class="n">important_features</span><span class="p">,</span> <span class="n">selector</span> <span class="o">=</span> <span class="n">select_important_features</span><span class="p">(</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">50</span>
<span class="p">)</span>

<span class="n">X_train_selected</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">important_features</span><span class="p">]</span>
<span class="n">X_test_selected</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">important_features</span><span class="p">]</span>
</code></pre></div>

---

## 9. Production Pipeline for Large Data

### 9.1 Complete Large-Data Training Pipeline

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">LargeDataPipeline</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Production pipeline for large datasets.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_path</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_path</span> <span class="o">=</span> <span class="n">data_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="n">model_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">important_features</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load data efficiently.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loading data from </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>

        <span class="n">chunks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">total_rows</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_path</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">nrows</span><span class="o">=</span><span class="n">nrows</span><span class="p">):</span>
            <span class="n">chunks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
            <span class="n">total_rows</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">total_rows</span> <span class="o">%</span> <span class="mi">500000</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="n">total_rows</span><span class="si">}</span><span class="s2"> rows...&quot;</span><span class="p">)</span>

        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">chunks</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total rows loaded: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">df</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">preprocess</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reduce memory footprint.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Preprocessing...&quot;</span><span class="p">)</span>

        <span class="c1"># Convert to optimal dtypes</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;float64&#39;</span><span class="p">]):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;int64&#39;</span><span class="p">]):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Memory usage: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">memory_usage</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> GB&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train on large dataset.&quot;&quot;&quot;</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Training...&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span>
            <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
            <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
                <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
                <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
                <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>
                <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">},</span>
                <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Validation accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">metrics</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Save trained model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model saved to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">load</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load trained model.&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model loaded from </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="c1"># Create pipeline</span>
    <span class="n">large_pipeline</span> <span class="o">=</span> <span class="n">LargeDataPipeline</span><span class="p">(</span>
        <span class="n">data_path</span><span class="o">=</span><span class="s1">&#39;large_dataset.csv&#39;</span><span class="p">,</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span>
    <span class="p">)</span>

    <span class="c1"># Load data (can specify nrows for testing)</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1000000</span><span class="p">)</span>

    <span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>

    <span class="c1"># Preprocess</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1"># Split</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
    <span class="p">)</span>

    <span class="c1"># Train</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">large_pipeline</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

    <span class="c1"># Save</span>
    <span class="n">large_pipeline</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;large_model.joblib&#39;</span><span class="p">)</span>
</code></pre></div>

---

## 10. Performance Tuning for Large Data

### 10.1 Bottleneck Analysis

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="k">class</span><span class="w"> </span><span class="nc">PerformanceMonitor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Monitor training performance.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">phase</span><span class="p">):</span>
        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span> <span class="o">=</span> <span class="n">elapsed</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">elapsed</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">report</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Print bottleneck analysis.&quot;&quot;&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Performance Report ===&quot;</span><span class="p">)</span>
        <span class="n">total</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">phase</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">times</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
            <span class="n">percent</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span> <span class="o">/</span> <span class="n">total</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">phase</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s2">8.2f</span><span class="si">}</span><span class="s2">s (</span><span class="si">{</span><span class="n">percent</span><span class="si">:</span><span class="s2">5.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;Total&#39;</span><span class="si">:</span><span class="s2">20</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">total</span><span class="si">:</span><span class="s2">8.2f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

<span class="c1"># Usage</span>
<span class="n">monitor</span> <span class="o">=</span> <span class="n">PerformanceMonitor</span><span class="p">()</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;data_loading&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">load_large_dataset</span><span class="p">()</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;data_loading&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;preprocessing&#39;</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;preprocessing&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">monitor</span><span class="o">.</span><span class="n">end</span><span class="p">(</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>

<span class="n">monitor</span><span class="o">.</span><span class="n">report</span><span class="p">()</span>
</code></pre></div>

### 10.2 Optimization Checklist

<div class="highlight"><pre><span></span><code><span class="n">optimization_checklist</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;Data Loading&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use Parquet instead of CSV&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Stream data in chunks&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use PyArrow for efficiency&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Memory&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use PEFT if memory-constrained&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use mixed precision (fp16)&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Reduce batch size if needed&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use gradient accumulation&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Speed&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use multi-GPU training&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Enable data parallelism&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Optimize learning rate&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use larger support_size for TabDPT&#39;</span>
    <span class="p">],</span>
    <span class="s1">&#39;Accuracy&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;✓ Use base-ft if memory allows&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Increase epochs&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Try TabDPT for large data&#39;</span><span class="p">,</span>
        <span class="s1">&#39;✓ Use cross-validation&#39;</span>
    <span class="p">]</span>
<span class="p">}</span>

<span class="k">for</span> <span class="n">category</span><span class="p">,</span> <span class="n">items</span> <span class="ow">in</span> <span class="n">optimization_checklist</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">category</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">items</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">item</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

---

## 11. Troubleshooting Large Data Issues

### 11.1 Common Problems & Solutions

<div class="highlight"><pre><span></span><code>Problem: Data loading is slow
Solutions:
  - Convert CSV to Parquet
  - Use column selection
  - Increase chunksize
  - Use parallel loading (Dask)

Problem: Training takes too long
Solutions:
  - Use multi-GPU training
  - Reduce dataset size (sampling)
  - Use smaller models (TabPFN vs TabDPT)
  - Use PEFT instead of base-ft

Problem: Out of memory during training
Solutions:
  - Use PEFT strategy
  - Reduce batch size
  - Use mixed precision (fp16)
  - Use gradient accumulation
  - Reduce support_size

Problem: Accuracy worse with large data
Solutions:
  - Ensure proper train/test split
  - Check for data quality issues
  - Use cross-validation
  - Increase training epochs
</code></pre></div>

---

## 12. Best Practices

### ✅ Do's

- ✅ Profile data loading first
- ✅ Use Parquet for large datasets
- ✅ Use PEFT for memory efficiency
- ✅ Monitor memory during training
- ✅ Use multi-GPU when available
- ✅ Use TabDPT for 100K+ rows
- ✅ Implement proper checkpointing
- ✅ Test on sample before full dataset

### ❌ Don'ts

- ❌ Don't load entire large dataset at once
- ❌ Don't use small batch sizes without necessity
- ❌ Don't ignore data quality
- ❌ Don't skip train/validation split
- ❌ Don't forget to scale learning rate for multi-GPU

---

## 13. Quick Reference

| Dataset Size | Recommended Model | Strategy | PEFT | Multi-GPU |
|--------------|-------------------|----------|------|-----------|
| 100K | TabICL | base-ft | No | Optional |
| 500K | TabDPT | base-ft | No | Recommended |
| 1M | TabDPT | base-ft | Optional | Yes |
| 5M+ | TabDPT | peft | Yes | Yes |

---

## 14. Next Steps

- [Memory Optimization](memory-optimization.md) - Detailed memory techniques
- [Multi-GPU Training](multi-gpu.md) - Distributed training details
- [Model Selection](../user-guide/model-selection.md) - Choose right model
- [Tuning Strategies](../user-guide/tuning-strategies.md) - Optimization strategies

---

Train TabTune models efficiently on datasets ranging from hundreds of thousands to millions of samples! --></div>
        
        
    </div>

    
      <footer class="col-md-12 text-center">
          
          
            <hr>
            <p>
            <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
            </p>
          

          
          
      </footer>
    
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../../js/bootstrap-3.0.3.min.js"></script>

    
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
        
    <script>hljs.initHighlightingOnLoad();</script>
    

    <script>var base_url = "../.."</script>
    
    <script src="../../js/base.js"></script>
    <script src="../../search/main.js"></script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>

</html>
