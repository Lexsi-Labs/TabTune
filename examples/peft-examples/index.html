<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="A Unified Library for Inference and Fine-Tuning Tabular Foundation Models" name="description"/>
<meta content="Lexsi Labs" name="author"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<title>PEFT Fine-Tuning - TabTune Documentation</title>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/all.css" rel="stylesheet"/>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css" rel="stylesheet"/>
<link href="//rsms.me/inter/inter.css" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&amp;subset=latin-ext,latin" rel="stylesheet" type="text/css"/>
<link href="../../css/bootstrap-custom.min.css" rel="stylesheet"/>
<link href="../../css/base.min.css" rel="stylesheet"/>
<link href="../../css/cinder.min.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css" rel="stylesheet"/>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../assets/overrides.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->
<link href="../../assets/lexsilabs.ico" rel="icon"/>
<link href="../../assets/lexsilabs.ico" rel="shortcut icon"/>
</head>
<body>
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
<div class="container">
<!-- Collapsed navigation -->
<div class="navbar-header">
<!-- Expander button -->
<button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse" type="button">
<span class="sr-only">Toggle navigation</span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
</button>
<!-- Main title -->
<a class="navbar-brand" href="../..">TabTune Documentation</a>
</div>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../getting-started/installation/">Installation</a>
</li>
<li>
<a href="../../getting-started/quick-start/">Quick Start</a>
</li>
<li>
<a href="../../getting-started/basic-concepts/">Basic Concepts</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">User Guide <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
</li>
<li>
<a href="../../user-guide/data-processing/">Data Processing</a>
</li>
<li>
<a href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
</li>
<li>
<a href="../../user-guide/model-selection/">Model Selection</a>
</li>
<li>
<a href="../../user-guide/saving-loading/">Saving and Loading</a>
</li>
<li>
<a href="../../user-guide/leaderboard/">Model Comparison</a>
</li>
<li>
<a href="../../user-guide/troubleshooting/">Troubleshooting</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Models <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../models/overview/">Overview</a>
</li>
<li>
<a href="../../models/tabpfn/">TabPFN</a>
</li>
<li>
<a href="../../models/tabicl/">TabICL</a>
</li>
<li>
<a href="../../models/orion-msp/">Orion MSP</a>
</li>
<li>
<a href="../../models/orion-bix/">Orion BIX</a>
</li>
<li>
<a href="../../models/tabdpt/">TabDPT</a>
</li>
<li>
<a href="../../models/mitra/">Mitra</a>
</li>
<li>
<a href="../../models/contexttab/">ConTextTab</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Advanced Topics <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../advanced/peft-lora/">PEFT &amp; LoRA</a>
</li>
<li>
<a href="../../advanced/custom-preprocessing/">Custom Preprocessing</a>
</li>
<li>
<a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
</li>
<li>
<a href="../../advanced/memory-optimization/">Memory Optimization</a>
</li>
<li>
<a href="../../advanced/multi-gpu/">Multi-GPU Training</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">API Reference <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../api/pipeline/">TabularPipeline</a>
</li>
<li>
<a href="../../api/data-processor/">DataProcessor</a>
</li>
<li>
<a href="../../api/tuning-manager/">TuningManager</a>
</li>
<li>
<a href="../../api/leaderboard/">TabularLeaderboard</a>
</li>
<li>
<a href="../../api/peft-utils/">PEFT Utils</a>
</li>
</ul>
</li>
<li class="dropdown active">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Examples <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../classification/">Classification Tasks</a>
</li>
<li class="active">
<a href="./">PEFT Fine-Tuning</a>
</li>
<li>
<a href="../benchmarking/">Benchmarking</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Project <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="dropdown-submenu">
<a href="" tabindex="-1">Contributing</a>
<ul class="dropdown-menu">
<li>
<a href="../../contributing/setup/">Development Setup</a>
</li>
<li>
<a href="../../contributing/standards/">Code Standards</a>
</li>
<li>
<a href="../../contributing/new-models/">Adding New Models</a>
</li>
<li>
<a href="../../contributing/documentation/">Documentation Guide</a>
</li>
</ul>
</li>
<li class="dropdown-submenu">
<a href="" tabindex="-1">About</a>
<ul class="dropdown-menu">
<li>
<a href="../../about/release-notes/">Release Notes</a>
</li>
<li>
<a href="../../about/roadmap/">Roadmap</a>
</li>
<li>
<a href="../../about/faq/">FAQ</a>
</li>
<li>
<a href="../../about/license/">License</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
<a data-target="#mkdocs_search_modal" data-toggle="modal" href="#">
<i class="fas fa-search"></i> Search
                        </a>
</li>
<li>
<a href="../classification/" rel="prev">
<i class="fas fa-arrow-left"></i> Previous
                        </a>
</li>
<li>
<a href="../benchmarking/" rel="next">
                            Next <i class="fas fa-arrow-right"></i>
</a>
</li>
<li>
<a href="https://github.com/Lexsi-Labs/TabTune/edit/master/docs/examples/peft-examples.md">Edit on Lexsi-Labs/TabTune</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
<ul class="nav bs-sidenav">
<li class="first-level active"><a href="#peft-examples-practical-parameter-efficient-fine-tuning-workflows">PEFT Examples: Practical Parameter-Efficient Fine-Tuning Workflows</a></li>
<li class="second-level"><a href="#1-quick-start-peft">1. Quick Start PEFT</a></li>
<li class="third-level"><a href="#11-5-minute-peft-example">1.1 5-Minute PEFT Example</a></li>
<li class="third-level"><a href="#12-comparing-base-ft-vs-peft">1.2 Comparing Base-FT vs PEFT</a></li>
<li class="second-level"><a href="#2-memory-constrained-training">2. Memory-Constrained Training</a></li>
<li class="third-level"><a href="#21-training-on-limited-gpu-4gb">2.1 Training on Limited GPU (4GB)</a></li>
<li class="second-level"><a href="#4-lora-rank-selection">4. LoRA Rank Selection</a></li>
<li class="third-level"><a href="#41-choosing-optimal-rank">4.1 Choosing Optimal Rank</a></li>
<li class="second-level"><a href="#6-advanced-peft-techniques">6. Advanced PEFT Techniques</a></li>
<li class="third-level"><a href="#61-custom-target-modules">6.1 Custom Target Modules</a></li>
<li class="third-level"><a href="#62-lora-with-different-learning-rates">6.2 LoRA with Different Learning Rates</a></li>
<li class="second-level"><a href="#9-troubleshooting-peft">9. Troubleshooting PEFT</a></li>
<li class="third-level"><a href="#91-common-peft-issues">9.1 Common PEFT Issues</a></li>
<li class="second-level"><a href="#10-peft-best-practices">10. PEFT Best Practices</a></li>
<li class="third-level"><a href="#dos">✅ Do's</a></li>
<li class="third-level"><a href="#donts">❌ Don'ts</a></li>
<li class="second-level"><a href="#11-peft-performance-summary">11. PEFT Performance Summary</a></li>
<li class="second-level"><a href="#12-quick-reference">12. Quick Reference</a></li>
<li class="second-level"><a href="#13-next-steps">13. Next Steps</a></li>
</ul>
</div></div>
<div class="col-md-9" role="main">
<h1 id="peft-examples-practical-parameter-efficient-fine-tuning-workflows">PEFT Examples: Practical Parameter-Efficient Fine-Tuning Workflows<a class="headerlink" href="#peft-examples-practical-parameter-efficient-fine-tuning-workflows" title="Permanent link">¶</a></h1>
<p>This document provides practical, production-ready examples for using LoRA and PEFT techniques with TabTune across various scenarios and constraints.</p>
<hr/>
<h2 id="1-quick-start-peft">1. Quick Start PEFT<a class="headerlink" href="#1-quick-start-peft" title="Permanent link">¶</a></h2>
<h3 id="11-5-minute-peft-example">1.1 5-Minute PEFT Example<a class="headerlink" href="#11-5-minute-peft-example" title="Permanent link">¶</a></h3>
<p>Minimal code to use LoRA:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="c1"># Create PEFT pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">'lora_dropout'</span><span class="p">:</span> <span class="mf">0.05</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="c1"># Train (much faster and lighter than base-ft)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Model size: 1-2% of full model"</span><span class="p">)</span>
</code></pre></div>
<h3 id="12-comparing-base-ft-vs-peft">1.2 Comparing Base-FT vs PEFT<a class="headerlink" href="#12-comparing-base-ft-vs-peft" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Method 1: Base Fine-Tuning</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"=== Base Fine-Tuning ==="</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">pipeline_base</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'base-ft'</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span><span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">}</span>
<span class="p">)</span>
<span class="n">pipeline_base</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">base_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">base_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1e9</span>

<span class="n">metrics_base</span> <span class="o">=</span> <span class="n">pipeline_base</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Time: </span><span class="si">{</span><span class="n">base_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Memory: </span><span class="si">{</span><span class="n">base_memory</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">metrics_base</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Method 2: PEFT</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== PEFT (LoRA) ==="</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">()</span>

<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">pipeline_peft</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">pipeline_peft</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">peft_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
<span class="n">peft_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span><span class="p">()</span> <span class="o">/</span> <span class="mf">1e9</span>

<span class="n">metrics_peft</span> <span class="o">=</span> <span class="n">pipeline_peft</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Time: </span><span class="si">{</span><span class="n">peft_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">s"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Memory: </span><span class="si">{</span><span class="n">peft_memory</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy: </span><span class="si">{</span><span class="n">metrics_peft</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">=== Comparison ==="</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Speedup: </span><span class="si">{</span><span class="n">base_time</span><span class="o">/</span><span class="n">peft_time</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">x"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Memory savings: </span><span class="si">{</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">peft_memory</span><span class="o">/</span><span class="n">base_memory</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracy loss: </span><span class="si">{</span><span class="p">(</span><span class="n">metrics_base</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">metrics_peft</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>
</code></pre></div>
<hr/>
<h2 id="2-memory-constrained-training">2. Memory-Constrained Training<a class="headerlink" href="#2-memory-constrained-training" title="Permanent link">¶</a></h2>
<h3 id="21-training-on-limited-gpu-4gb">2.1 Training on Limited GPU (4GB)<a class="headerlink" href="#21-training-on-limited-gpu-4gb" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># Check available GPU memory</span>
<span class="n">available_memory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">get_device_properties</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">total_memory</span> <span class="o">/</span> <span class="mf">1e9</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Available GPU memory: </span><span class="si">{</span><span class="n">available_memory</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">GB"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">available_memory</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Using ultra-efficient PEFT configuration..."</span><span class="p">)</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
            <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>           <span class="c1"># Small batch</span>
            <span class="s1">'support_size'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>        <span class="c1"># Small context</span>
            <span class="s1">'query_size'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">'num_workers'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>          <span class="c1"># No parallel loading</span>
            <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">'r'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>                <span class="c1"># Very low rank</span>
                <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
                <span class="s1">'lora_dropout'</span><span class="p">:</span> <span class="mf">0.1</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="k">elif</span> <span class="n">available_memory</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Using efficient PEFT configuration..."</span><span class="p">)</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
            <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">'support_size'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
            <span class="s1">'query_size'</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
                <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
                <span class="s1">'lora_dropout'</span><span class="p">:</span> <span class="mf">0.05</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Sufficient memory. Using standard PEFT..."</span><span class="p">)</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
            <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="c1"># Train</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<!-- ### 2.2 Combining PEFT with Mixed Precision

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># Ultra-efficient: PEFT + Mixed Precision + Gradient Accumulation</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
        <span class="s1">&#39;gradient_accumulation_steps&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>  <span class="c1"># Effective batch: 32</span>
        <span class="s1">&#39;mixed_precision&#39;</span><span class="p">:</span> <span class="s1">&#39;fp16&#39;</span><span class="p">,</span>         <span class="c1"># Half precision</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="mf">0.1</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Result: Similar effective batch size to batch_size=32</span>
<span class="c1"># But memory usage of batch_size=4</span>
</code></pre></div>
 -->
<hr/>
<!-- ## 3. Multi-Model PEFT Training

### 3.1 Compare All Models with PEFT

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularLeaderboard</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">()</span>

<span class="c1"># Create leaderboard</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">TabularLeaderboard</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Add all models with PEFT</span>
<span class="n">models_to_test</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;TabPFN&#39;</span><span class="p">,</span> <span class="s1">&#39;TabICL&#39;</span><span class="p">,</span> <span class="s1">&#39;OrionMSP&#39;</span><span class="p">,</span> <span class="s1">&#39;OrionBix&#39;</span><span class="p">,</span> <span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span> <span class="s1">&#39;Mitra&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models_to_test</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">model</span> <span class="o">==</span> <span class="s1">&#39;TabPFN&#39;</span><span class="p">:</span>
        <span class="c1"># TabPFN doesn&#39;t need PEFT as much (already fast)</span>
        <span class="n">lb</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">&#39;inference&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">-Inference&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lb</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span>
            <span class="n">model</span><span class="p">,</span>
            <span class="s1">&#39;peft&#39;</span><span class="p">,</span>
            <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">model</span><span class="si">}</span><span class="s1">-PEFT-r8&#39;</span><span class="p">,</span>
            <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
                <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
                <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
                <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">}</span>
            <span class="p">}</span>
        <span class="p">)</span>

<span class="c1"># Run benchmarks</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Running PEFT comparison across all models...&quot;</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">rank_by</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Display results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PEFT Model Comparison&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">70</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lb</span><span class="o">.</span><span class="n">get_ranking</span><span class="p">())</span>

<span class="c1"># Export for analysis</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">get_results_dataframe</span><span class="p">()</span>
<span class="n">results_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;peft_comparison.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

### 3.2 Rank Ablation Study

Compare LoRA ranks for single model:

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularLeaderboard</span>

<span class="n">lb</span> <span class="o">=</span> <span class="n">TabularLeaderboard</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="c1"># Test different ranks</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]:</span>
    <span class="n">lb</span><span class="o">.</span><span class="n">add_model</span><span class="p">(</span>
        <span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
        <span class="s1">&#39;peft&#39;</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;TabICL-r</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
            <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span>
                <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="p">,</span>
                <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="mf">0.05</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">rank_by</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>

<span class="c1"># Analyze trade-offs</span>
<span class="n">results_df</span> <span class="o">=</span> <span class="n">lb</span><span class="o">.</span><span class="n">get_results_dataframe</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Rank Ablation Study ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">results_df</span><span class="p">[[</span><span class="s1">&#39;model_name&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;training_time&#39;</span><span class="p">]])</span>

<span class="c1"># Find sweet spot</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Recommendations:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">results_df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;model_name&#39;</span><span class="p">]</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
    <span class="n">time</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;training_time&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model</span><span class="si">:</span><span class="s2">15</span><span class="si">}</span><span class="s2"> | Accuracy: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> | Time: </span><span class="si">{</span><span class="n">time</span><span class="si">:</span><span class="s2">6.1f</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>
</code></pre></div>
 -->
<hr/>
<h2 id="4-lora-rank-selection">4. LoRA Rank Selection<a class="headerlink" href="#4-lora-rank-selection" title="Permanent link">¶</a></h2>
<h3 id="41-choosing-optimal-rank">4.1 Choosing Optimal Rank<a class="headerlink" href="#41-choosing-optimal-rank" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_rank</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Evaluate specific LoRA rank."""</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
            <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">'r'</span><span class="p">:</span> <span class="n">rank</span><span class="p">,</span>
                <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">rank</span><span class="p">,</span>
                <span class="s1">'lora_dropout'</span><span class="p">:</span> <span class="mf">0.05</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">metrics</span>

<span class="c1"># Evaluate multiple ranks</span>
<span class="n">ranks</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Evaluating LoRA ranks..."</span><span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  Testing rank </span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2">..."</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">evaluate_rank</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
    <span class="n">results</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">" Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># Find optimal rank</span>
<span class="n">optimal_rank</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">results</span><span class="o">.</span><span class="n">get</span><span class="p">)</span>
<span class="n">optimal_acc</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="n">optimal_rank</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Optimal rank: </span><span class="si">{</span><span class="n">optimal_rank</span><span class="si">}</span><span class="s2"> (Accuracy: </span><span class="si">{</span><span class="n">optimal_acc</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="c1"># Plot results</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ranks</span><span class="p">,</span> <span class="p">[</span><span class="n">results</span><span class="p">[</span><span class="n">r</span><span class="p">]</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">ranks</span><span class="p">],</span> <span class="s1">'o-'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'LoRA Rank'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'LoRA Rank vs Model Accuracy'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">'rank_analysis.png'</span><span class="p">)</span>
</code></pre></div>
<hr/>
<h2 id="6-advanced-peft-techniques">6. Advanced PEFT Techniques<a class="headerlink" href="#6-advanced-peft-techniques" title="Permanent link">¶</a></h2>
<h3 id="61-custom-target-modules">6.1 Custom Target Modules<a class="headerlink" href="#61-custom-target-modules" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># Train only specific layers</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">'target_modules'</span><span class="p">:</span> <span class="p">[</span>
                <span class="s1">'col_embedder.tf_col'</span><span class="p">,</span>      <span class="c1"># Column embedder only</span>
                <span class="s1">'icl_predictor.decoder'</span>     <span class="c1"># Plus decoder</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<h3 id="62-lora-with-different-learning-rates">6.2 LoRA with Different Learning Rates<a class="headerlink" href="#62-lora-with-different-learning-rates" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># Higher learning rate for smaller LoRA modules</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">'TabICL'</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">'peft'</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span><span class="p">,</span>
        <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">,</span>  <span class="c1"># 10x higher for PEFT</span>
        <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">'r'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">16</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<!-- ### 6.3 Sequential Fine-Tuning

Gradually unfreeze layers:

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># Phase 1: Train only head</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 1: Train only prediction head...&quot;</span><span class="p">)</span>
<span class="n">pipeline1</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;icl_predictor.decoder&#39;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">pipeline1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Phase 2: Train more modules</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 2: Train more modules...&quot;</span><span class="p">)</span>
<span class="n">pipeline2</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">&#39;target_modules&#39;</span><span class="p">:</span> <span class="p">[</span>
                <span class="s1">&#39;col_embedder.tf_col&#39;</span><span class="p">,</span>
                <span class="s1">&#39;icl_predictor.tf_icl&#39;</span><span class="p">,</span>
                <span class="s1">&#39;icl_predictor.decoder&#39;</span>
            <span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>
<span class="n">pipeline2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline2</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final Accuracy: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="err">```</span> <span class="o">--&gt;</span>

<span class="o">---</span>

<span class="c1">## 7. PEFT for Different Models</span>

<span class="c1">### 7.1 TabDPT with PEFT for Large Data</span>

<span class="err">```</span><span class="n">python</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># PEFT enables TabDPT on memory-limited systems</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabDPT&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">1024</span><span class="p">,</span>  <span class="c1"># Still use large context</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">16</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

### 7.2 Mitra with PEFT for 2D Attention

<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="c1"># PEFT makes memory-hungry Mitra practical</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;Mitra&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
        <span class="s1">&#39;support_size&#39;</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
        <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>  <span class="c1"># Still small due to 2D attention</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">8</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>

---

<!-- ## 8. PEFT Hyperparameter Tuning

### 8.1 Bayesian Optimization for PEFT

<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">optuna</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabtune</span><span class="w"> </span><span class="kn">import</span> <span class="n">TabularPipeline</span>

<span class="k">def</span><span class="w"> </span><span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Optimize PEFT hyperparameters.&quot;&quot;&quot;</span>

    <span class="c1"># Suggest PEFT hyperparameters</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s1">&#39;dropout&#39;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>

    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
        <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
        <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
        <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
            <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
            <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="n">r</span><span class="p">,</span>
                <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">r</span><span class="p">,</span>
                <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="n">dropout</span>
            <span class="p">}</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>

<span class="c1"># Run optimization</span>
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s1">&#39;maximize&#39;</span><span class="p">)</span>
<span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best accuracy: </span><span class="si">{</span><span class="n">study</span><span class="o">.</span><span class="n">best_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best PEFT config: </span><span class="si">{</span><span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Train final model</span>
<span class="n">best_pipeline</span> <span class="o">=</span> <span class="n">TabularPipeline</span><span class="p">(</span>
    <span class="n">model_name</span><span class="o">=</span><span class="s1">&#39;TabICL&#39;</span><span class="p">,</span>
    <span class="n">tuning_strategy</span><span class="o">=</span><span class="s1">&#39;peft&#39;</span><span class="p">,</span>
    <span class="n">tuning_params</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">&#39;device&#39;</span><span class="p">:</span> <span class="s1">&#39;cuda&#39;</span><span class="p">,</span>
        <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
        <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">],</span>
        <span class="s1">&#39;peft_config&#39;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;r&#39;</span><span class="p">:</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">],</span>
            <span class="s1">&#39;lora_alpha&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="o">*</span><span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;r&#39;</span><span class="p">],</span>
            <span class="s1">&#39;lora_dropout&#39;</span><span class="p">:</span> <span class="n">study</span><span class="o">.</span><span class="n">best_params</span><span class="p">[</span><span class="s1">&#39;dropout&#39;</span><span class="p">]</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">)</span>

<span class="n">best_pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">final_metrics</span> <span class="o">=</span> <span class="n">best_pipeline</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final test accuracy: </span><span class="si">{</span><span class="n">final_metrics</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

--- -->
<hr/>
<h2 id="9-troubleshooting-peft">9. Troubleshooting PEFT<a class="headerlink" href="#9-troubleshooting-peft" title="Permanent link">¶</a></h2>
<h3 id="91-common-peft-issues">9.1 Common PEFT Issues<a class="headerlink" href="#91-common-peft-issues" title="Permanent link">¶</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Issue 1: PEFT accuracy much lower than base-ft</span>
<span class="c1"># Solution: Increase rank</span>
<span class="n">peft_config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'r'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>  <span class="c1"># Instead of 4</span>
    <span class="s1">'lora_alpha'</span><span class="p">:</span> <span class="mi">32</span>
<span class="p">}</span>

<span class="c1"># Issue 2: PEFT training diverging</span>
<span class="c1"># Solution: Reduce learning rate</span>
<span class="n">tuning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">1e-4</span>  <span class="c1"># Instead of 2e-4</span>
<span class="p">}</span>

<span class="c1"># Issue 3: PEFT still using too much memory</span>
<span class="c1"># Solution: Combine PEFT + mixed precision + gradient accumulation</span>
<span class="n">tuning_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">2e-4</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">'gradient_accumulation_steps'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s1">'mixed_precision'</span><span class="p">:</span> <span class="s1">'fp16'</span><span class="p">,</span>
    <span class="s1">'peft_config'</span><span class="p">:</span> <span class="p">{</span><span class="s1">'r'</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Issue 4: PEFT slower than expected</span>
<span class="c1"># Solution: Verify LoRA is applied</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipeline</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># Check for LoRA modules</span>
</code></pre></div>
<hr/>
<h2 id="10-peft-best-practices">10. PEFT Best Practices<a class="headerlink" href="#10-peft-best-practices" title="Permanent link">¶</a></h2>
<h3 id="dos">✅ Do's<a class="headerlink" href="#dos" title="Permanent link">¶</a></h3>
<ul>
<li>✅ Start with r=8 (good default)</li>
<li>✅ Use 2x learning rate for PEFT</li>
<li>✅ Include warmup steps</li>
<li>✅ Monitor gradient norms</li>
<li>✅ Use gradient clipping</li>
<li>✅ Test rank selection</li>
<li>✅ Save adapter weights separately</li>
</ul>
<h3 id="donts">❌ Don'ts<a class="headerlink" href="#donts" title="Permanent link">¶</a></h3>
<ul>
<li>❌ Don't use same learning rate as base-ft</li>
<li>❌ Don't use rank &lt; 2</li>
<li>❌ Don't skip regularization</li>
<li>❌ Don't forget to scale learning rate</li>
<li>❌ Don't train very long (overfit risk)</li>
</ul>
<hr/>
<h2 id="11-peft-performance-summary">11. PEFT Performance Summary<a class="headerlink" href="#11-peft-performance-summary" title="Permanent link">¶</a></h2>
<div class="highlight"><pre><span></span><code>Typical Results on 100K Sample Classification Task:

Base Fine-Tuning:
  Training Time: 30 minutes
  Memory: 12 GB
  Accuracy: 90.5%
  Model Size: 500 MB

PEFT (r=8):
  Training Time: 10 minutes (3x faster)
  Memory: 3 GB (75% reduction)
  Accuracy: 89.8% (0.7% loss)
  Model Size: 5 MB (100x smaller)

Trade-off Analysis:
  Speed: 3x faster
  Memory: 75% reduction
  Storage: 100x smaller
  Accuracy: Only 0.7% lower
  RECOMMENDATION: Use PEFT for most scenarios
</code></pre></div>
<hr/>
<h2 id="12-quick-reference">12. Quick Reference<a class="headerlink" href="#12-quick-reference" title="Permanent link">¶</a></h2>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>r</th>
<th>alpha</th>
<th>dropout</th>
<th>LR</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Memory constrained</td>
<td>4</td>
<td>8</td>
<td>0.1</td>
<td>1e-4</td>
<td>Ultra-low resource</td>
</tr>
<tr>
<td>Standard</td>
<td>8</td>
<td>16</td>
<td>0.05</td>
<td>2e-4</td>
<td>Default, balanced</td>
</tr>
<tr>
<td>High accuracy</td>
<td>16</td>
<td>32</td>
<td>0.02</td>
<td>1e-4</td>
<td>Best results</td>
</tr>
<tr>
<td>Large data (1M)</td>
<td>8</td>
<td>16</td>
<td>0.05</td>
<td>2e-4</td>
<td>TabDPT recommended</td>
</tr>
</tbody>
</table>
<hr/>
<h2 id="13-next-steps">13. Next Steps<a class="headerlink" href="#13-next-steps" title="Permanent link">¶</a></h2>
<ul>
<li><a href="../../advanced/peft-lora/">PEFT &amp; LoRA</a> - Theory and mathematics</li>
<li><a href="../../advanced/memory-optimization/">Memory Optimization</a> - Memory techniques</li>
<li><a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a> - Optimization</li>
<li><a href="../classification/">Classification Examples</a> - Complete workflows</li>
</ul>
<hr/>
<p>Master PEFT for efficient, production-ready fine-tuning!</p></div>
</div>
<footer class="col-md-12 text-center">
<hr/>
<p>
<small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
</p>
</footer>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="../../js/bootstrap-3.0.3.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/python.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/yaml.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>var base_url = "../.."</script>
<script src="../../js/base.js"></script>
<script src="../../search/main.js"></script>
<script>
        // Initialize Mermaid v9.x after DOM loads
        // The mermaid2 plugin loads the library and sets window.mermaidConfig
        (function() {
            function initMermaid() {
                if (typeof mermaid !== 'undefined') {
                    // Get configuration from plugin or use defaults
                    const config = window.mermaidConfig || {
                        securityLevel: 'loose',
                        startOnLoad: false
                    };
                    
                    // Initialize mermaid with config
                    mermaid.initialize(config);
                    
                    // Render all mermaid diagrams - mermaid.run() automatically finds .mermaid elements
                    if (typeof mermaid.run === 'function') {
                        mermaid.run();
                    } else {
                        // Fallback for older API - manually initialize elements
                        const mermaidElements = document.querySelectorAll('.mermaid');
                        if (mermaidElements.length > 0) {
                            mermaid.init(undefined, mermaidElements);
                        }
                    }
                } else {
                    // Retry if mermaid library hasn't loaded yet
                    setTimeout(initMermaid, 100);
                }
            }
            
            // Wait for DOM and scripts to be ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', initMermaid);
            } else {
                // DOM already loaded, but scripts might not be
                setTimeout(initMermaid, 100);
            }
        })();
    </script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">×</span>
<span class="sr-only">Close</span>
</button>
<h4 class="modal-title" id="searchModalLabel">Search</h4>
</div>
<div class="modal-body">
<p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="text"/>
</div>
</form>
<div id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true">×</span><span class="sr-only">Close</span></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
</body>
</html>
