<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="IE=edge" http-equiv="X-UA-Compatible"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta content="A Unified Library for Inference and Fine-Tuning Tabular Foundation Models" name="description"/>
<meta content="Lexsi Labs" name="author"/>
<link href="../../img/favicon.ico" rel="shortcut icon"/>
<title>TuningManager - TabTune Documentation</title>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/all.css" rel="stylesheet"/>
<link href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css" rel="stylesheet"/>
<link href="//rsms.me/inter/inter.css" rel="stylesheet" type="text/css"/>
<link href="//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&amp;subset=latin-ext,latin" rel="stylesheet" type="text/css"/>
<link href="../../css/bootstrap-custom.min.css" rel="stylesheet"/>
<link href="../../css/base.min.css" rel="stylesheet"/>
<link href="../../css/cinder.min.css" rel="stylesheet"/>
<link href="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/styles/github.min.css" rel="stylesheet"/>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../assets/overrides.css" rel="stylesheet"/>
<!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->
</head>
<body>
<div class="navbar navbar-default navbar-fixed-top" role="navigation">
<div class="container">
<!-- Collapsed navigation -->
<div class="navbar-header">
<!-- Expander button -->
<button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse" type="button">
<span class="sr-only">Toggle navigation</span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
<span class="icon-bar"></span>
</button>
<!-- Main title -->
<a class="navbar-brand" href="../..">TabTune Documentation</a>
</div>
<!-- Expanded navigation -->
<div class="navbar-collapse collapse">
<!-- Main navigation -->
<ul class="nav navbar-nav">
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../getting-started/installation/">Installation</a>
</li>
<li>
<a href="../../getting-started/quick-start/">Quick Start</a>
</li>
<li>
<a href="../../getting-started/basic-concepts/">Basic Concepts</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">User Guide <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../user-guide/pipeline-overview/">TabularPipeline Overview</a>
</li>
<li>
<a href="../../user-guide/data-processing/">Data Processing</a>
</li>
<li>
<a href="../../user-guide/tuning-strategies/">Tuning Strategies</a>
</li>
<li>
<a href="../../user-guide/model-selection/">Model Selection</a>
</li>
<li>
<a href="../../user-guide/saving-loading/">Saving and Loading</a>
</li>
<li>
<a href="../../user-guide/leaderboard/">Model Comparison</a>
</li>
<li>
<a href="../../user-guide/troubleshooting/">Troubleshooting</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Models <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../models/overview/">Overview</a>
</li>
<li>
<a href="../../models/tabpfn/">TabPFN</a>
</li>
<li>
<a href="../../models/tabicl/">TabICL</a>
</li>
<li>
<a href="../../models/orion-msp/">Orion MSP</a>
</li>
<li>
<a href="../../models/orion-bix/">Orion BIX</a>
</li>
<li>
<a href="../../models/tabdpt/">TabDPT</a>
</li>
<li>
<a href="../../models/mitra/">Mitra</a>
</li>
<li>
<a href="../../models/contexttab/">ConTextTab</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Advanced Topics <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../advanced/peft-lora/">PEFT &amp; LoRA</a>
</li>
<li>
<a href="../../advanced/custom-preprocessing/">Custom Preprocessing</a>
</li>
<li>
<a href="../../advanced/hyperparameter-tuning/">Hyperparameter Tuning</a>
</li>
<li>
<a href="../../advanced/memory-optimization/">Memory Optimization</a>
</li>
<li>
<a href="../../advanced/multi-gpu/">Multi-GPU Training</a>
</li>
</ul>
</li>
<li class="dropdown active">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">API Reference <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../pipeline/">TabularPipeline</a>
</li>
<li>
<a href="../data-processor/">DataProcessor</a>
</li>
<li class="active">
<a href="./">TuningManager</a>
</li>
<li>
<a href="../leaderboard/">TabularLeaderboard</a>
</li>
<li>
<a href="../peft-utils/">PEFT Utils</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Examples <b class="caret"></b></a>
<ul class="dropdown-menu">
<li>
<a href="../../examples/classification/">Classification Tasks</a>
</li>
<li>
<a href="../../examples/peft-examples/">PEFT Fine-Tuning</a>
</li>
<li>
<a href="../../examples/benchmarking/">Benchmarking</a>
</li>
</ul>
</li>
<li class="dropdown">
<a class="dropdown-toggle" data-toggle="dropdown" href="#">Project <b class="caret"></b></a>
<ul class="dropdown-menu">
<li class="dropdown-submenu">
<a href="" tabindex="-1">Contributing</a>
<ul class="dropdown-menu">
<li>
<a href="../../contributing/setup/">Development Setup</a>
</li>
<li>
<a href="../../contributing/standards/">Code Standards</a>
</li>
<li>
<a href="../../contributing/new-models/">Adding New Models</a>
</li>
<li>
<a href="../../contributing/documentation/">Documentation Guide</a>
</li>
</ul>
</li>
<li class="dropdown-submenu">
<a href="" tabindex="-1">About</a>
<ul class="dropdown-menu">
<li>
<a href="../../about/release-notes/">Release Notes</a>
</li>
<li>
<a href="../../about/roadmap/">Roadmap</a>
</li>
<li>
<a href="../../about/faq/">FAQ</a>
</li>
<li>
<a href="../../about/license/">License</a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
<a data-target="#mkdocs_search_modal" data-toggle="modal" href="#">
<i class="fas fa-search"></i> Search
                        </a>
</li>
<li>
<a href="../data-processor/" rel="prev">
<i class="fas fa-arrow-left"></i> Previous
                        </a>
</li>
<li>
<a href="../leaderboard/" rel="next">
                            Next <i class="fas fa-arrow-right"></i>
</a>
</li>
<li>
<a href="https://github.com/Lexsi-Labs/TabTune/edit/master/docs/api/tuning-manager.md">Edit on Lexsi-Labs/TabTune</a>
</li>
</ul>
</div>
</div>
</div>
<div class="container">
<div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
<ul class="nav bs-sidenav">
<li class="first-level active"><a href="#api-tuningmanager">API: TuningManager</a></li>
<li class="second-level"><a href="#tabtune.TuningManager.tuning.TuningManager">TuningManager</a></li>
<li class="second-level"><a href="#tabtune.TuningManager.tuning.TuningManager.load_checkpoint">load_checkpoint</a></li>
</ul>
</div></div>
<div class="col-md-9" role="main">
<h1 id="api-tuningmanager">API: TuningManager<a class="headerlink" href="#api-tuningmanager" title="Permanent link">Â¶</a></h1>
<div class="doc doc-object doc-class">
<a id="tabtune.TuningManager.tuning.TuningManager"></a>
<div class="doc doc-contents first">
<p>Handles the model adaptation process</p>
<details class="quote">
<summary>Source code in <code>tabtune/TuningManager/tuning.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  44</span>
<span class="normal">  45</span>
<span class="normal">  46</span>
<span class="normal">  47</span>
<span class="normal">  48</span>
<span class="normal">  49</span>
<span class="normal">  50</span>
<span class="normal">  51</span>
<span class="normal">  52</span>
<span class="normal">  53</span>
<span class="normal">  54</span>
<span class="normal">  55</span>
<span class="normal">  56</span>
<span class="normal">  57</span>
<span class="normal">  58</span>
<span class="normal">  59</span>
<span class="normal">  60</span>
<span class="normal">  61</span>
<span class="normal">  62</span>
<span class="normal">  63</span>
<span class="normal">  64</span>
<span class="normal">  65</span>
<span class="normal">  66</span>
<span class="normal">  67</span>
<span class="normal">  68</span>
<span class="normal">  69</span>
<span class="normal">  70</span>
<span class="normal">  71</span>
<span class="normal">  72</span>
<span class="normal">  73</span>
<span class="normal">  74</span>
<span class="normal">  75</span>
<span class="normal">  76</span>
<span class="normal">  77</span>
<span class="normal">  78</span>
<span class="normal">  79</span>
<span class="normal">  80</span>
<span class="normal">  81</span>
<span class="normal">  82</span>
<span class="normal">  83</span>
<span class="normal">  84</span>
<span class="normal">  85</span>
<span class="normal">  86</span>
<span class="normal">  87</span>
<span class="normal">  88</span>
<span class="normal">  89</span>
<span class="normal">  90</span>
<span class="normal">  91</span>
<span class="normal">  92</span>
<span class="normal">  93</span>
<span class="normal">  94</span>
<span class="normal">  95</span>
<span class="normal">  96</span>
<span class="normal">  97</span>
<span class="normal">  98</span>
<span class="normal">  99</span>
<span class="normal"> 100</span>
<span class="normal"> 101</span>
<span class="normal"> 102</span>
<span class="normal"> 103</span>
<span class="normal"> 104</span>
<span class="normal"> 105</span>
<span class="normal"> 106</span>
<span class="normal"> 107</span>
<span class="normal"> 108</span>
<span class="normal"> 109</span>
<span class="normal"> 110</span>
<span class="normal"> 111</span>
<span class="normal"> 112</span>
<span class="normal"> 113</span>
<span class="normal"> 114</span>
<span class="normal"> 115</span>
<span class="normal"> 116</span>
<span class="normal"> 117</span>
<span class="normal"> 118</span>
<span class="normal"> 119</span>
<span class="normal"> 120</span>
<span class="normal"> 121</span>
<span class="normal"> 122</span>
<span class="normal"> 123</span>
<span class="normal"> 124</span>
<span class="normal"> 125</span>
<span class="normal"> 126</span>
<span class="normal"> 127</span>
<span class="normal"> 128</span>
<span class="normal"> 129</span>
<span class="normal"> 130</span>
<span class="normal"> 131</span>
<span class="normal"> 132</span>
<span class="normal"> 133</span>
<span class="normal"> 134</span>
<span class="normal"> 135</span>
<span class="normal"> 136</span>
<span class="normal"> 137</span>
<span class="normal"> 138</span>
<span class="normal"> 139</span>
<span class="normal"> 140</span>
<span class="normal"> 141</span>
<span class="normal"> 142</span>
<span class="normal"> 143</span>
<span class="normal"> 144</span>
<span class="normal"> 145</span>
<span class="normal"> 146</span>
<span class="normal"> 147</span>
<span class="normal"> 148</span>
<span class="normal"> 149</span>
<span class="normal"> 150</span>
<span class="normal"> 151</span>
<span class="normal"> 152</span>
<span class="normal"> 153</span>
<span class="normal"> 154</span>
<span class="normal"> 155</span>
<span class="normal"> 156</span>
<span class="normal"> 157</span>
<span class="normal"> 158</span>
<span class="normal"> 159</span>
<span class="normal"> 160</span>
<span class="normal"> 161</span>
<span class="normal"> 162</span>
<span class="normal"> 163</span>
<span class="normal"> 164</span>
<span class="normal"> 165</span>
<span class="normal"> 166</span>
<span class="normal"> 167</span>
<span class="normal"> 168</span>
<span class="normal"> 169</span>
<span class="normal"> 170</span>
<span class="normal"> 171</span>
<span class="normal"> 172</span>
<span class="normal"> 173</span>
<span class="normal"> 174</span>
<span class="normal"> 175</span>
<span class="normal"> 176</span>
<span class="normal"> 177</span>
<span class="normal"> 178</span>
<span class="normal"> 179</span>
<span class="normal"> 180</span>
<span class="normal"> 181</span>
<span class="normal"> 182</span>
<span class="normal"> 183</span>
<span class="normal"> 184</span>
<span class="normal"> 185</span>
<span class="normal"> 186</span>
<span class="normal"> 187</span>
<span class="normal"> 188</span>
<span class="normal"> 189</span>
<span class="normal"> 190</span>
<span class="normal"> 191</span>
<span class="normal"> 192</span>
<span class="normal"> 193</span>
<span class="normal"> 194</span>
<span class="normal"> 195</span>
<span class="normal"> 196</span>
<span class="normal"> 197</span>
<span class="normal"> 198</span>
<span class="normal"> 199</span>
<span class="normal"> 200</span>
<span class="normal"> 201</span>
<span class="normal"> 202</span>
<span class="normal"> 203</span>
<span class="normal"> 204</span>
<span class="normal"> 205</span>
<span class="normal"> 206</span>
<span class="normal"> 207</span>
<span class="normal"> 208</span>
<span class="normal"> 209</span>
<span class="normal"> 210</span>
<span class="normal"> 211</span>
<span class="normal"> 212</span>
<span class="normal"> 213</span>
<span class="normal"> 214</span>
<span class="normal"> 215</span>
<span class="normal"> 216</span>
<span class="normal"> 217</span>
<span class="normal"> 218</span>
<span class="normal"> 219</span>
<span class="normal"> 220</span>
<span class="normal"> 221</span>
<span class="normal"> 222</span>
<span class="normal"> 223</span>
<span class="normal"> 224</span>
<span class="normal"> 225</span>
<span class="normal"> 226</span>
<span class="normal"> 227</span>
<span class="normal"> 228</span>
<span class="normal"> 229</span>
<span class="normal"> 230</span>
<span class="normal"> 231</span>
<span class="normal"> 232</span>
<span class="normal"> 233</span>
<span class="normal"> 234</span>
<span class="normal"> 235</span>
<span class="normal"> 236</span>
<span class="normal"> 237</span>
<span class="normal"> 238</span>
<span class="normal"> 239</span>
<span class="normal"> 240</span>
<span class="normal"> 241</span>
<span class="normal"> 242</span>
<span class="normal"> 243</span>
<span class="normal"> 244</span>
<span class="normal"> 245</span>
<span class="normal"> 246</span>
<span class="normal"> 247</span>
<span class="normal"> 248</span>
<span class="normal"> 249</span>
<span class="normal"> 250</span>
<span class="normal"> 251</span>
<span class="normal"> 252</span>
<span class="normal"> 253</span>
<span class="normal"> 254</span>
<span class="normal"> 255</span>
<span class="normal"> 256</span>
<span class="normal"> 257</span>
<span class="normal"> 258</span>
<span class="normal"> 259</span>
<span class="normal"> 260</span>
<span class="normal"> 261</span>
<span class="normal"> 262</span>
<span class="normal"> 263</span>
<span class="normal"> 264</span>
<span class="normal"> 265</span>
<span class="normal"> 266</span>
<span class="normal"> 267</span>
<span class="normal"> 268</span>
<span class="normal"> 269</span>
<span class="normal"> 270</span>
<span class="normal"> 271</span>
<span class="normal"> 272</span>
<span class="normal"> 273</span>
<span class="normal"> 274</span>
<span class="normal"> 275</span>
<span class="normal"> 276</span>
<span class="normal"> 277</span>
<span class="normal"> 278</span>
<span class="normal"> 279</span>
<span class="normal"> 280</span>
<span class="normal"> 281</span>
<span class="normal"> 282</span>
<span class="normal"> 283</span>
<span class="normal"> 284</span>
<span class="normal"> 285</span>
<span class="normal"> 286</span>
<span class="normal"> 287</span>
<span class="normal"> 288</span>
<span class="normal"> 289</span>
<span class="normal"> 290</span>
<span class="normal"> 291</span>
<span class="normal"> 292</span>
<span class="normal"> 293</span>
<span class="normal"> 294</span>
<span class="normal"> 295</span>
<span class="normal"> 296</span>
<span class="normal"> 297</span>
<span class="normal"> 298</span>
<span class="normal"> 299</span>
<span class="normal"> 300</span>
<span class="normal"> 301</span>
<span class="normal"> 302</span>
<span class="normal"> 303</span>
<span class="normal"> 304</span>
<span class="normal"> 305</span>
<span class="normal"> 306</span>
<span class="normal"> 307</span>
<span class="normal"> 308</span>
<span class="normal"> 309</span>
<span class="normal"> 310</span>
<span class="normal"> 311</span>
<span class="normal"> 312</span>
<span class="normal"> 313</span>
<span class="normal"> 314</span>
<span class="normal"> 315</span>
<span class="normal"> 316</span>
<span class="normal"> 317</span>
<span class="normal"> 318</span>
<span class="normal"> 319</span>
<span class="normal"> 320</span>
<span class="normal"> 321</span>
<span class="normal"> 322</span>
<span class="normal"> 323</span>
<span class="normal"> 324</span>
<span class="normal"> 325</span>
<span class="normal"> 326</span>
<span class="normal"> 327</span>
<span class="normal"> 328</span>
<span class="normal"> 329</span>
<span class="normal"> 330</span>
<span class="normal"> 331</span>
<span class="normal"> 332</span>
<span class="normal"> 333</span>
<span class="normal"> 334</span>
<span class="normal"> 335</span>
<span class="normal"> 336</span>
<span class="normal"> 337</span>
<span class="normal"> 338</span>
<span class="normal"> 339</span>
<span class="normal"> 340</span>
<span class="normal"> 341</span>
<span class="normal"> 342</span>
<span class="normal"> 343</span>
<span class="normal"> 344</span>
<span class="normal"> 345</span>
<span class="normal"> 346</span>
<span class="normal"> 347</span>
<span class="normal"> 348</span>
<span class="normal"> 349</span>
<span class="normal"> 350</span>
<span class="normal"> 351</span>
<span class="normal"> 352</span>
<span class="normal"> 353</span>
<span class="normal"> 354</span>
<span class="normal"> 355</span>
<span class="normal"> 356</span>
<span class="normal"> 357</span>
<span class="normal"> 358</span>
<span class="normal"> 359</span>
<span class="normal"> 360</span>
<span class="normal"> 361</span>
<span class="normal"> 362</span>
<span class="normal"> 363</span>
<span class="normal"> 364</span>
<span class="normal"> 365</span>
<span class="normal"> 366</span>
<span class="normal"> 367</span>
<span class="normal"> 368</span>
<span class="normal"> 369</span>
<span class="normal"> 370</span>
<span class="normal"> 371</span>
<span class="normal"> 372</span>
<span class="normal"> 373</span>
<span class="normal"> 374</span>
<span class="normal"> 375</span>
<span class="normal"> 376</span>
<span class="normal"> 377</span>
<span class="normal"> 378</span>
<span class="normal"> 379</span>
<span class="normal"> 380</span>
<span class="normal"> 381</span>
<span class="normal"> 382</span>
<span class="normal"> 383</span>
<span class="normal"> 384</span>
<span class="normal"> 385</span>
<span class="normal"> 386</span>
<span class="normal"> 387</span>
<span class="normal"> 388</span>
<span class="normal"> 389</span>
<span class="normal"> 390</span>
<span class="normal"> 391</span>
<span class="normal"> 392</span>
<span class="normal"> 393</span>
<span class="normal"> 394</span>
<span class="normal"> 395</span>
<span class="normal"> 396</span>
<span class="normal"> 397</span>
<span class="normal"> 398</span>
<span class="normal"> 399</span>
<span class="normal"> 400</span>
<span class="normal"> 401</span>
<span class="normal"> 402</span>
<span class="normal"> 403</span>
<span class="normal"> 404</span>
<span class="normal"> 405</span>
<span class="normal"> 406</span>
<span class="normal"> 407</span>
<span class="normal"> 408</span>
<span class="normal"> 409</span>
<span class="normal"> 410</span>
<span class="normal"> 411</span>
<span class="normal"> 412</span>
<span class="normal"> 413</span>
<span class="normal"> 414</span>
<span class="normal"> 415</span>
<span class="normal"> 416</span>
<span class="normal"> 417</span>
<span class="normal"> 418</span>
<span class="normal"> 419</span>
<span class="normal"> 420</span>
<span class="normal"> 421</span>
<span class="normal"> 422</span>
<span class="normal"> 423</span>
<span class="normal"> 424</span>
<span class="normal"> 425</span>
<span class="normal"> 426</span>
<span class="normal"> 427</span>
<span class="normal"> 428</span>
<span class="normal"> 429</span>
<span class="normal"> 430</span>
<span class="normal"> 431</span>
<span class="normal"> 432</span>
<span class="normal"> 433</span>
<span class="normal"> 434</span>
<span class="normal"> 435</span>
<span class="normal"> 436</span>
<span class="normal"> 437</span>
<span class="normal"> 438</span>
<span class="normal"> 439</span>
<span class="normal"> 440</span>
<span class="normal"> 441</span>
<span class="normal"> 442</span>
<span class="normal"> 443</span>
<span class="normal"> 444</span>
<span class="normal"> 445</span>
<span class="normal"> 446</span>
<span class="normal"> 447</span>
<span class="normal"> 448</span>
<span class="normal"> 449</span>
<span class="normal"> 450</span>
<span class="normal"> 451</span>
<span class="normal"> 452</span>
<span class="normal"> 453</span>
<span class="normal"> 454</span>
<span class="normal"> 455</span>
<span class="normal"> 456</span>
<span class="normal"> 457</span>
<span class="normal"> 458</span>
<span class="normal"> 459</span>
<span class="normal"> 460</span>
<span class="normal"> 461</span>
<span class="normal"> 462</span>
<span class="normal"> 463</span>
<span class="normal"> 464</span>
<span class="normal"> 465</span>
<span class="normal"> 466</span>
<span class="normal"> 467</span>
<span class="normal"> 468</span>
<span class="normal"> 469</span>
<span class="normal"> 470</span>
<span class="normal"> 471</span>
<span class="normal"> 472</span>
<span class="normal"> 473</span>
<span class="normal"> 474</span>
<span class="normal"> 475</span>
<span class="normal"> 476</span>
<span class="normal"> 477</span>
<span class="normal"> 478</span>
<span class="normal"> 479</span>
<span class="normal"> 480</span>
<span class="normal"> 481</span>
<span class="normal"> 482</span>
<span class="normal"> 483</span>
<span class="normal"> 484</span>
<span class="normal"> 485</span>
<span class="normal"> 486</span>
<span class="normal"> 487</span>
<span class="normal"> 488</span>
<span class="normal"> 489</span>
<span class="normal"> 490</span>
<span class="normal"> 491</span>
<span class="normal"> 492</span>
<span class="normal"> 493</span>
<span class="normal"> 494</span>
<span class="normal"> 495</span>
<span class="normal"> 496</span>
<span class="normal"> 497</span>
<span class="normal"> 498</span>
<span class="normal"> 499</span>
<span class="normal"> 500</span>
<span class="normal"> 501</span>
<span class="normal"> 502</span>
<span class="normal"> 503</span>
<span class="normal"> 504</span>
<span class="normal"> 505</span>
<span class="normal"> 506</span>
<span class="normal"> 507</span>
<span class="normal"> 508</span>
<span class="normal"> 509</span>
<span class="normal"> 510</span>
<span class="normal"> 511</span>
<span class="normal"> 512</span>
<span class="normal"> 513</span>
<span class="normal"> 514</span>
<span class="normal"> 515</span>
<span class="normal"> 516</span>
<span class="normal"> 517</span>
<span class="normal"> 518</span>
<span class="normal"> 519</span>
<span class="normal"> 520</span>
<span class="normal"> 521</span>
<span class="normal"> 522</span>
<span class="normal"> 523</span>
<span class="normal"> 524</span>
<span class="normal"> 525</span>
<span class="normal"> 526</span>
<span class="normal"> 527</span>
<span class="normal"> 528</span>
<span class="normal"> 529</span>
<span class="normal"> 530</span>
<span class="normal"> 531</span>
<span class="normal"> 532</span>
<span class="normal"> 533</span>
<span class="normal"> 534</span>
<span class="normal"> 535</span>
<span class="normal"> 536</span>
<span class="normal"> 537</span>
<span class="normal"> 538</span>
<span class="normal"> 539</span>
<span class="normal"> 540</span>
<span class="normal"> 541</span>
<span class="normal"> 542</span>
<span class="normal"> 543</span>
<span class="normal"> 544</span>
<span class="normal"> 545</span>
<span class="normal"> 546</span>
<span class="normal"> 547</span>
<span class="normal"> 548</span>
<span class="normal"> 549</span>
<span class="normal"> 550</span>
<span class="normal"> 551</span>
<span class="normal"> 552</span>
<span class="normal"> 553</span>
<span class="normal"> 554</span>
<span class="normal"> 555</span>
<span class="normal"> 556</span>
<span class="normal"> 557</span>
<span class="normal"> 558</span>
<span class="normal"> 559</span>
<span class="normal"> 560</span>
<span class="normal"> 561</span>
<span class="normal"> 562</span>
<span class="normal"> 563</span>
<span class="normal"> 564</span>
<span class="normal"> 565</span>
<span class="normal"> 566</span>
<span class="normal"> 567</span>
<span class="normal"> 568</span>
<span class="normal"> 569</span>
<span class="normal"> 570</span>
<span class="normal"> 571</span>
<span class="normal"> 572</span>
<span class="normal"> 573</span>
<span class="normal"> 574</span>
<span class="normal"> 575</span>
<span class="normal"> 576</span>
<span class="normal"> 577</span>
<span class="normal"> 578</span>
<span class="normal"> 579</span>
<span class="normal"> 580</span>
<span class="normal"> 581</span>
<span class="normal"> 582</span>
<span class="normal"> 583</span>
<span class="normal"> 584</span>
<span class="normal"> 585</span>
<span class="normal"> 586</span>
<span class="normal"> 587</span>
<span class="normal"> 588</span>
<span class="normal"> 589</span>
<span class="normal"> 590</span>
<span class="normal"> 591</span>
<span class="normal"> 592</span>
<span class="normal"> 593</span>
<span class="normal"> 594</span>
<span class="normal"> 595</span>
<span class="normal"> 596</span>
<span class="normal"> 597</span>
<span class="normal"> 598</span>
<span class="normal"> 599</span>
<span class="normal"> 600</span>
<span class="normal"> 601</span>
<span class="normal"> 602</span>
<span class="normal"> 603</span>
<span class="normal"> 604</span>
<span class="normal"> 605</span>
<span class="normal"> 606</span>
<span class="normal"> 607</span>
<span class="normal"> 608</span>
<span class="normal"> 609</span>
<span class="normal"> 610</span>
<span class="normal"> 611</span>
<span class="normal"> 612</span>
<span class="normal"> 613</span>
<span class="normal"> 614</span>
<span class="normal"> 615</span>
<span class="normal"> 616</span>
<span class="normal"> 617</span>
<span class="normal"> 618</span>
<span class="normal"> 619</span>
<span class="normal"> 620</span>
<span class="normal"> 621</span>
<span class="normal"> 622</span>
<span class="normal"> 623</span>
<span class="normal"> 624</span>
<span class="normal"> 625</span>
<span class="normal"> 626</span>
<span class="normal"> 627</span>
<span class="normal"> 628</span>
<span class="normal"> 629</span>
<span class="normal"> 630</span>
<span class="normal"> 631</span>
<span class="normal"> 632</span>
<span class="normal"> 633</span>
<span class="normal"> 634</span>
<span class="normal"> 635</span>
<span class="normal"> 636</span>
<span class="normal"> 637</span>
<span class="normal"> 638</span>
<span class="normal"> 639</span>
<span class="normal"> 640</span>
<span class="normal"> 641</span>
<span class="normal"> 642</span>
<span class="normal"> 643</span>
<span class="normal"> 644</span>
<span class="normal"> 645</span>
<span class="normal"> 646</span>
<span class="normal"> 647</span>
<span class="normal"> 648</span>
<span class="normal"> 649</span>
<span class="normal"> 650</span>
<span class="normal"> 651</span>
<span class="normal"> 652</span>
<span class="normal"> 653</span>
<span class="normal"> 654</span>
<span class="normal"> 655</span>
<span class="normal"> 656</span>
<span class="normal"> 657</span>
<span class="normal"> 658</span>
<span class="normal"> 659</span>
<span class="normal"> 660</span>
<span class="normal"> 661</span>
<span class="normal"> 662</span>
<span class="normal"> 663</span>
<span class="normal"> 664</span>
<span class="normal"> 665</span>
<span class="normal"> 666</span>
<span class="normal"> 667</span>
<span class="normal"> 668</span>
<span class="normal"> 669</span>
<span class="normal"> 670</span>
<span class="normal"> 671</span>
<span class="normal"> 672</span>
<span class="normal"> 673</span>
<span class="normal"> 674</span>
<span class="normal"> 675</span>
<span class="normal"> 676</span>
<span class="normal"> 677</span>
<span class="normal"> 678</span>
<span class="normal"> 679</span>
<span class="normal"> 680</span>
<span class="normal"> 681</span>
<span class="normal"> 682</span>
<span class="normal"> 683</span>
<span class="normal"> 684</span>
<span class="normal"> 685</span>
<span class="normal"> 686</span>
<span class="normal"> 687</span>
<span class="normal"> 688</span>
<span class="normal"> 689</span>
<span class="normal"> 690</span>
<span class="normal"> 691</span>
<span class="normal"> 692</span>
<span class="normal"> 693</span>
<span class="normal"> 694</span>
<span class="normal"> 695</span>
<span class="normal"> 696</span>
<span class="normal"> 697</span>
<span class="normal"> 698</span>
<span class="normal"> 699</span>
<span class="normal"> 700</span>
<span class="normal"> 701</span>
<span class="normal"> 702</span>
<span class="normal"> 703</span>
<span class="normal"> 704</span>
<span class="normal"> 705</span>
<span class="normal"> 706</span>
<span class="normal"> 707</span>
<span class="normal"> 708</span>
<span class="normal"> 709</span>
<span class="normal"> 710</span>
<span class="normal"> 711</span>
<span class="normal"> 712</span>
<span class="normal"> 713</span>
<span class="normal"> 714</span>
<span class="normal"> 715</span>
<span class="normal"> 716</span>
<span class="normal"> 717</span>
<span class="normal"> 718</span>
<span class="normal"> 719</span>
<span class="normal"> 720</span>
<span class="normal"> 721</span>
<span class="normal"> 722</span>
<span class="normal"> 723</span>
<span class="normal"> 724</span>
<span class="normal"> 725</span>
<span class="normal"> 726</span>
<span class="normal"> 727</span>
<span class="normal"> 728</span>
<span class="normal"> 729</span>
<span class="normal"> 730</span>
<span class="normal"> 731</span>
<span class="normal"> 732</span>
<span class="normal"> 733</span>
<span class="normal"> 734</span>
<span class="normal"> 735</span>
<span class="normal"> 736</span>
<span class="normal"> 737</span>
<span class="normal"> 738</span>
<span class="normal"> 739</span>
<span class="normal"> 740</span>
<span class="normal"> 741</span>
<span class="normal"> 742</span>
<span class="normal"> 743</span>
<span class="normal"> 744</span>
<span class="normal"> 745</span>
<span class="normal"> 746</span>
<span class="normal"> 747</span>
<span class="normal"> 748</span>
<span class="normal"> 749</span>
<span class="normal"> 750</span>
<span class="normal"> 751</span>
<span class="normal"> 752</span>
<span class="normal"> 753</span>
<span class="normal"> 754</span>
<span class="normal"> 755</span>
<span class="normal"> 756</span>
<span class="normal"> 757</span>
<span class="normal"> 758</span>
<span class="normal"> 759</span>
<span class="normal"> 760</span>
<span class="normal"> 761</span>
<span class="normal"> 762</span>
<span class="normal"> 763</span>
<span class="normal"> 764</span>
<span class="normal"> 765</span>
<span class="normal"> 766</span>
<span class="normal"> 767</span>
<span class="normal"> 768</span>
<span class="normal"> 769</span>
<span class="normal"> 770</span>
<span class="normal"> 771</span>
<span class="normal"> 772</span>
<span class="normal"> 773</span>
<span class="normal"> 774</span>
<span class="normal"> 775</span>
<span class="normal"> 776</span>
<span class="normal"> 777</span>
<span class="normal"> 778</span>
<span class="normal"> 779</span>
<span class="normal"> 780</span>
<span class="normal"> 781</span>
<span class="normal"> 782</span>
<span class="normal"> 783</span>
<span class="normal"> 784</span>
<span class="normal"> 785</span>
<span class="normal"> 786</span>
<span class="normal"> 787</span>
<span class="normal"> 788</span>
<span class="normal"> 789</span>
<span class="normal"> 790</span>
<span class="normal"> 791</span>
<span class="normal"> 792</span>
<span class="normal"> 793</span>
<span class="normal"> 794</span>
<span class="normal"> 795</span>
<span class="normal"> 796</span>
<span class="normal"> 797</span>
<span class="normal"> 798</span>
<span class="normal"> 799</span>
<span class="normal"> 800</span>
<span class="normal"> 801</span>
<span class="normal"> 802</span>
<span class="normal"> 803</span>
<span class="normal"> 804</span>
<span class="normal"> 805</span>
<span class="normal"> 806</span>
<span class="normal"> 807</span>
<span class="normal"> 808</span>
<span class="normal"> 809</span>
<span class="normal"> 810</span>
<span class="normal"> 811</span>
<span class="normal"> 812</span>
<span class="normal"> 813</span>
<span class="normal"> 814</span>
<span class="normal"> 815</span>
<span class="normal"> 816</span>
<span class="normal"> 817</span>
<span class="normal"> 818</span>
<span class="normal"> 819</span>
<span class="normal"> 820</span>
<span class="normal"> 821</span>
<span class="normal"> 822</span>
<span class="normal"> 823</span>
<span class="normal"> 824</span>
<span class="normal"> 825</span>
<span class="normal"> 826</span>
<span class="normal"> 827</span>
<span class="normal"> 828</span>
<span class="normal"> 829</span>
<span class="normal"> 830</span>
<span class="normal"> 831</span>
<span class="normal"> 832</span>
<span class="normal"> 833</span>
<span class="normal"> 834</span>
<span class="normal"> 835</span>
<span class="normal"> 836</span>
<span class="normal"> 837</span>
<span class="normal"> 838</span>
<span class="normal"> 839</span>
<span class="normal"> 840</span>
<span class="normal"> 841</span>
<span class="normal"> 842</span>
<span class="normal"> 843</span>
<span class="normal"> 844</span>
<span class="normal"> 845</span>
<span class="normal"> 846</span>
<span class="normal"> 847</span>
<span class="normal"> 848</span>
<span class="normal"> 849</span>
<span class="normal"> 850</span>
<span class="normal"> 851</span>
<span class="normal"> 852</span>
<span class="normal"> 853</span>
<span class="normal"> 854</span>
<span class="normal"> 855</span>
<span class="normal"> 856</span>
<span class="normal"> 857</span>
<span class="normal"> 858</span>
<span class="normal"> 859</span>
<span class="normal"> 860</span>
<span class="normal"> 861</span>
<span class="normal"> 862</span>
<span class="normal"> 863</span>
<span class="normal"> 864</span>
<span class="normal"> 865</span>
<span class="normal"> 866</span>
<span class="normal"> 867</span>
<span class="normal"> 868</span>
<span class="normal"> 869</span>
<span class="normal"> 870</span>
<span class="normal"> 871</span>
<span class="normal"> 872</span>
<span class="normal"> 873</span>
<span class="normal"> 874</span>
<span class="normal"> 875</span>
<span class="normal"> 876</span>
<span class="normal"> 877</span>
<span class="normal"> 878</span>
<span class="normal"> 879</span>
<span class="normal"> 880</span>
<span class="normal"> 881</span>
<span class="normal"> 882</span>
<span class="normal"> 883</span>
<span class="normal"> 884</span>
<span class="normal"> 885</span>
<span class="normal"> 886</span>
<span class="normal"> 887</span>
<span class="normal"> 888</span>
<span class="normal"> 889</span>
<span class="normal"> 890</span>
<span class="normal"> 891</span>
<span class="normal"> 892</span>
<span class="normal"> 893</span>
<span class="normal"> 894</span>
<span class="normal"> 895</span>
<span class="normal"> 896</span>
<span class="normal"> 897</span>
<span class="normal"> 898</span>
<span class="normal"> 899</span>
<span class="normal"> 900</span>
<span class="normal"> 901</span>
<span class="normal"> 902</span>
<span class="normal"> 903</span>
<span class="normal"> 904</span>
<span class="normal"> 905</span>
<span class="normal"> 906</span>
<span class="normal"> 907</span>
<span class="normal"> 908</span>
<span class="normal"> 909</span>
<span class="normal"> 910</span>
<span class="normal"> 911</span>
<span class="normal"> 912</span>
<span class="normal"> 913</span>
<span class="normal"> 914</span>
<span class="normal"> 915</span>
<span class="normal"> 916</span>
<span class="normal"> 917</span>
<span class="normal"> 918</span>
<span class="normal"> 919</span>
<span class="normal"> 920</span>
<span class="normal"> 921</span>
<span class="normal"> 922</span>
<span class="normal"> 923</span>
<span class="normal"> 924</span>
<span class="normal"> 925</span>
<span class="normal"> 926</span>
<span class="normal"> 927</span>
<span class="normal"> 928</span>
<span class="normal"> 929</span>
<span class="normal"> 930</span>
<span class="normal"> 931</span>
<span class="normal"> 932</span>
<span class="normal"> 933</span>
<span class="normal"> 934</span>
<span class="normal"> 935</span>
<span class="normal"> 936</span>
<span class="normal"> 937</span>
<span class="normal"> 938</span>
<span class="normal"> 939</span>
<span class="normal"> 940</span>
<span class="normal"> 941</span>
<span class="normal"> 942</span>
<span class="normal"> 943</span>
<span class="normal"> 944</span>
<span class="normal"> 945</span>
<span class="normal"> 946</span>
<span class="normal"> 947</span>
<span class="normal"> 948</span>
<span class="normal"> 949</span>
<span class="normal"> 950</span>
<span class="normal"> 951</span>
<span class="normal"> 952</span>
<span class="normal"> 953</span>
<span class="normal"> 954</span>
<span class="normal"> 955</span>
<span class="normal"> 956</span>
<span class="normal"> 957</span>
<span class="normal"> 958</span>
<span class="normal"> 959</span>
<span class="normal"> 960</span>
<span class="normal"> 961</span>
<span class="normal"> 962</span>
<span class="normal"> 963</span>
<span class="normal"> 964</span>
<span class="normal"> 965</span>
<span class="normal"> 966</span>
<span class="normal"> 967</span>
<span class="normal"> 968</span>
<span class="normal"> 969</span>
<span class="normal"> 970</span>
<span class="normal"> 971</span>
<span class="normal"> 972</span>
<span class="normal"> 973</span>
<span class="normal"> 974</span>
<span class="normal"> 975</span>
<span class="normal"> 976</span>
<span class="normal"> 977</span>
<span class="normal"> 978</span>
<span class="normal"> 979</span>
<span class="normal"> 980</span>
<span class="normal"> 981</span>
<span class="normal"> 982</span>
<span class="normal"> 983</span>
<span class="normal"> 984</span>
<span class="normal"> 985</span>
<span class="normal"> 986</span>
<span class="normal"> 987</span>
<span class="normal"> 988</span>
<span class="normal"> 989</span>
<span class="normal"> 990</span>
<span class="normal"> 991</span>
<span class="normal"> 992</span>
<span class="normal"> 993</span>
<span class="normal"> 994</span>
<span class="normal"> 995</span>
<span class="normal"> 996</span>
<span class="normal"> 997</span>
<span class="normal"> 998</span>
<span class="normal"> 999</span>
<span class="normal">1000</span>
<span class="normal">1001</span>
<span class="normal">1002</span>
<span class="normal">1003</span>
<span class="normal">1004</span>
<span class="normal">1005</span>
<span class="normal">1006</span>
<span class="normal">1007</span>
<span class="normal">1008</span>
<span class="normal">1009</span>
<span class="normal">1010</span>
<span class="normal">1011</span>
<span class="normal">1012</span>
<span class="normal">1013</span>
<span class="normal">1014</span>
<span class="normal">1015</span>
<span class="normal">1016</span>
<span class="normal">1017</span>
<span class="normal">1018</span>
<span class="normal">1019</span>
<span class="normal">1020</span>
<span class="normal">1021</span>
<span class="normal">1022</span>
<span class="normal">1023</span>
<span class="normal">1024</span>
<span class="normal">1025</span>
<span class="normal">1026</span>
<span class="normal">1027</span>
<span class="normal">1028</span>
<span class="normal">1029</span>
<span class="normal">1030</span>
<span class="normal">1031</span>
<span class="normal">1032</span>
<span class="normal">1033</span>
<span class="normal">1034</span>
<span class="normal">1035</span>
<span class="normal">1036</span>
<span class="normal">1037</span>
<span class="normal">1038</span>
<span class="normal">1039</span>
<span class="normal">1040</span>
<span class="normal">1041</span>
<span class="normal">1042</span>
<span class="normal">1043</span>
<span class="normal">1044</span>
<span class="normal">1045</span>
<span class="normal">1046</span>
<span class="normal">1047</span>
<span class="normal">1048</span>
<span class="normal">1049</span>
<span class="normal">1050</span>
<span class="normal">1051</span>
<span class="normal">1052</span>
<span class="normal">1053</span>
<span class="normal">1054</span>
<span class="normal">1055</span>
<span class="normal">1056</span>
<span class="normal">1057</span>
<span class="normal">1058</span>
<span class="normal">1059</span>
<span class="normal">1060</span>
<span class="normal">1061</span>
<span class="normal">1062</span>
<span class="normal">1063</span>
<span class="normal">1064</span>
<span class="normal">1065</span>
<span class="normal">1066</span>
<span class="normal">1067</span>
<span class="normal">1068</span>
<span class="normal">1069</span>
<span class="normal">1070</span>
<span class="normal">1071</span>
<span class="normal">1072</span>
<span class="normal">1073</span>
<span class="normal">1074</span>
<span class="normal">1075</span>
<span class="normal">1076</span>
<span class="normal">1077</span>
<span class="normal">1078</span>
<span class="normal">1079</span>
<span class="normal">1080</span>
<span class="normal">1081</span>
<span class="normal">1082</span>
<span class="normal">1083</span>
<span class="normal">1084</span>
<span class="normal">1085</span>
<span class="normal">1086</span>
<span class="normal">1087</span>
<span class="normal">1088</span>
<span class="normal">1089</span>
<span class="normal">1090</span>
<span class="normal">1091</span>
<span class="normal">1092</span>
<span class="normal">1093</span>
<span class="normal">1094</span>
<span class="normal">1095</span>
<span class="normal">1096</span>
<span class="normal">1097</span>
<span class="normal">1098</span>
<span class="normal">1099</span>
<span class="normal">1100</span>
<span class="normal">1101</span>
<span class="normal">1102</span>
<span class="normal">1103</span>
<span class="normal">1104</span>
<span class="normal">1105</span>
<span class="normal">1106</span>
<span class="normal">1107</span>
<span class="normal">1108</span>
<span class="normal">1109</span>
<span class="normal">1110</span>
<span class="normal">1111</span>
<span class="normal">1112</span>
<span class="normal">1113</span>
<span class="normal">1114</span>
<span class="normal">1115</span>
<span class="normal">1116</span>
<span class="normal">1117</span>
<span class="normal">1118</span>
<span class="normal">1119</span>
<span class="normal">1120</span>
<span class="normal">1121</span>
<span class="normal">1122</span>
<span class="normal">1123</span>
<span class="normal">1124</span>
<span class="normal">1125</span>
<span class="normal">1126</span>
<span class="normal">1127</span>
<span class="normal">1128</span>
<span class="normal">1129</span>
<span class="normal">1130</span>
<span class="normal">1131</span>
<span class="normal">1132</span>
<span class="normal">1133</span>
<span class="normal">1134</span>
<span class="normal">1135</span>
<span class="normal">1136</span>
<span class="normal">1137</span>
<span class="normal">1138</span>
<span class="normal">1139</span>
<span class="normal">1140</span>
<span class="normal">1141</span>
<span class="normal">1142</span>
<span class="normal">1143</span>
<span class="normal">1144</span>
<span class="normal">1145</span>
<span class="normal">1146</span>
<span class="normal">1147</span>
<span class="normal">1148</span>
<span class="normal">1149</span>
<span class="normal">1150</span>
<span class="normal">1151</span>
<span class="normal">1152</span>
<span class="normal">1153</span>
<span class="normal">1154</span>
<span class="normal">1155</span>
<span class="normal">1156</span>
<span class="normal">1157</span>
<span class="normal">1158</span>
<span class="normal">1159</span>
<span class="normal">1160</span>
<span class="normal">1161</span>
<span class="normal">1162</span>
<span class="normal">1163</span>
<span class="normal">1164</span>
<span class="normal">1165</span>
<span class="normal">1166</span>
<span class="normal">1167</span>
<span class="normal">1168</span>
<span class="normal">1169</span>
<span class="normal">1170</span>
<span class="normal">1171</span>
<span class="normal">1172</span>
<span class="normal">1173</span>
<span class="normal">1174</span>
<span class="normal">1175</span>
<span class="normal">1176</span>
<span class="normal">1177</span>
<span class="normal">1178</span>
<span class="normal">1179</span>
<span class="normal">1180</span>
<span class="normal">1181</span>
<span class="normal">1182</span>
<span class="normal">1183</span>
<span class="normal">1184</span>
<span class="normal">1185</span>
<span class="normal">1186</span>
<span class="normal">1187</span>
<span class="normal">1188</span>
<span class="normal">1189</span>
<span class="normal">1190</span>
<span class="normal">1191</span>
<span class="normal">1192</span>
<span class="normal">1193</span>
<span class="normal">1194</span>
<span class="normal">1195</span>
<span class="normal">1196</span>
<span class="normal">1197</span>
<span class="normal">1198</span>
<span class="normal">1199</span>
<span class="normal">1200</span>
<span class="normal">1201</span>
<span class="normal">1202</span>
<span class="normal">1203</span>
<span class="normal">1204</span>
<span class="normal">1205</span>
<span class="normal">1206</span>
<span class="normal">1207</span>
<span class="normal">1208</span>
<span class="normal">1209</span>
<span class="normal">1210</span>
<span class="normal">1211</span>
<span class="normal">1212</span>
<span class="normal">1213</span>
<span class="normal">1214</span>
<span class="normal">1215</span>
<span class="normal">1216</span>
<span class="normal">1217</span>
<span class="normal">1218</span>
<span class="normal">1219</span>
<span class="normal">1220</span>
<span class="normal">1221</span>
<span class="normal">1222</span>
<span class="normal">1223</span>
<span class="normal">1224</span>
<span class="normal">1225</span>
<span class="normal">1226</span>
<span class="normal">1227</span>
<span class="normal">1228</span>
<span class="normal">1229</span>
<span class="normal">1230</span>
<span class="normal">1231</span>
<span class="normal">1232</span>
<span class="normal">1233</span>
<span class="normal">1234</span>
<span class="normal">1235</span>
<span class="normal">1236</span>
<span class="normal">1237</span>
<span class="normal">1238</span>
<span class="normal">1239</span>
<span class="normal">1240</span>
<span class="normal">1241</span>
<span class="normal">1242</span>
<span class="normal">1243</span>
<span class="normal">1244</span>
<span class="normal">1245</span>
<span class="normal">1246</span>
<span class="normal">1247</span>
<span class="normal">1248</span>
<span class="normal">1249</span>
<span class="normal">1250</span>
<span class="normal">1251</span>
<span class="normal">1252</span>
<span class="normal">1253</span>
<span class="normal">1254</span>
<span class="normal">1255</span>
<span class="normal">1256</span>
<span class="normal">1257</span>
<span class="normal">1258</span>
<span class="normal">1259</span>
<span class="normal">1260</span>
<span class="normal">1261</span>
<span class="normal">1262</span>
<span class="normal">1263</span>
<span class="normal">1264</span>
<span class="normal">1265</span>
<span class="normal">1266</span>
<span class="normal">1267</span>
<span class="normal">1268</span>
<span class="normal">1269</span>
<span class="normal">1270</span>
<span class="normal">1271</span>
<span class="normal">1272</span>
<span class="normal">1273</span>
<span class="normal">1274</span>
<span class="normal">1275</span>
<span class="normal">1276</span>
<span class="normal">1277</span>
<span class="normal">1278</span>
<span class="normal">1279</span>
<span class="normal">1280</span>
<span class="normal">1281</span>
<span class="normal">1282</span>
<span class="normal">1283</span>
<span class="normal">1284</span>
<span class="normal">1285</span>
<span class="normal">1286</span>
<span class="normal">1287</span>
<span class="normal">1288</span>
<span class="normal">1289</span>
<span class="normal">1290</span>
<span class="normal">1291</span>
<span class="normal">1292</span>
<span class="normal">1293</span>
<span class="normal">1294</span>
<span class="normal">1295</span>
<span class="normal">1296</span>
<span class="normal">1297</span>
<span class="normal">1298</span>
<span class="normal">1299</span>
<span class="normal">1300</span>
<span class="normal">1301</span>
<span class="normal">1302</span>
<span class="normal">1303</span>
<span class="normal">1304</span>
<span class="normal">1305</span>
<span class="normal">1306</span>
<span class="normal">1307</span>
<span class="normal">1308</span>
<span class="normal">1309</span>
<span class="normal">1310</span>
<span class="normal">1311</span>
<span class="normal">1312</span>
<span class="normal">1313</span>
<span class="normal">1314</span>
<span class="normal">1315</span>
<span class="normal">1316</span>
<span class="normal">1317</span>
<span class="normal">1318</span>
<span class="normal">1319</span>
<span class="normal">1320</span>
<span class="normal">1321</span>
<span class="normal">1322</span>
<span class="normal">1323</span>
<span class="normal">1324</span>
<span class="normal">1325</span>
<span class="normal">1326</span>
<span class="normal">1327</span>
<span class="normal">1328</span>
<span class="normal">1329</span>
<span class="normal">1330</span>
<span class="normal">1331</span>
<span class="normal">1332</span>
<span class="normal">1333</span>
<span class="normal">1334</span>
<span class="normal">1335</span>
<span class="normal">1336</span>
<span class="normal">1337</span>
<span class="normal">1338</span>
<span class="normal">1339</span>
<span class="normal">1340</span>
<span class="normal">1341</span>
<span class="normal">1342</span>
<span class="normal">1343</span>
<span class="normal">1344</span>
<span class="normal">1345</span>
<span class="normal">1346</span>
<span class="normal">1347</span>
<span class="normal">1348</span>
<span class="normal">1349</span>
<span class="normal">1350</span>
<span class="normal">1351</span>
<span class="normal">1352</span>
<span class="normal">1353</span>
<span class="normal">1354</span>
<span class="normal">1355</span>
<span class="normal">1356</span>
<span class="normal">1357</span>
<span class="normal">1358</span>
<span class="normal">1359</span>
<span class="normal">1360</span>
<span class="normal">1361</span>
<span class="normal">1362</span>
<span class="normal">1363</span>
<span class="normal">1364</span>
<span class="normal">1365</span>
<span class="normal">1366</span>
<span class="normal">1367</span>
<span class="normal">1368</span>
<span class="normal">1369</span>
<span class="normal">1370</span>
<span class="normal">1371</span>
<span class="normal">1372</span>
<span class="normal">1373</span>
<span class="normal">1374</span>
<span class="normal">1375</span>
<span class="normal">1376</span>
<span class="normal">1377</span>
<span class="normal">1378</span>
<span class="normal">1379</span>
<span class="normal">1380</span>
<span class="normal">1381</span>
<span class="normal">1382</span>
<span class="normal">1383</span>
<span class="normal">1384</span>
<span class="normal">1385</span>
<span class="normal">1386</span>
<span class="normal">1387</span>
<span class="normal">1388</span>
<span class="normal">1389</span>
<span class="normal">1390</span>
<span class="normal">1391</span>
<span class="normal">1392</span>
<span class="normal">1393</span>
<span class="normal">1394</span>
<span class="normal">1395</span>
<span class="normal">1396</span>
<span class="normal">1397</span>
<span class="normal">1398</span>
<span class="normal">1399</span>
<span class="normal">1400</span>
<span class="normal">1401</span>
<span class="normal">1402</span>
<span class="normal">1403</span>
<span class="normal">1404</span>
<span class="normal">1405</span>
<span class="normal">1406</span>
<span class="normal">1407</span>
<span class="normal">1408</span>
<span class="normal">1409</span>
<span class="normal">1410</span>
<span class="normal">1411</span>
<span class="normal">1412</span>
<span class="normal">1413</span>
<span class="normal">1414</span>
<span class="normal">1415</span>
<span class="normal">1416</span>
<span class="normal">1417</span>
<span class="normal">1418</span>
<span class="normal">1419</span>
<span class="normal">1420</span>
<span class="normal">1421</span>
<span class="normal">1422</span>
<span class="normal">1423</span>
<span class="normal">1424</span>
<span class="normal">1425</span>
<span class="normal">1426</span>
<span class="normal">1427</span>
<span class="normal">1428</span>
<span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span>
<span class="normal">1555</span>
<span class="normal">1556</span>
<span class="normal">1557</span>
<span class="normal">1558</span>
<span class="normal">1559</span>
<span class="normal">1560</span>
<span class="normal">1561</span>
<span class="normal">1562</span>
<span class="normal">1563</span>
<span class="normal">1564</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">TuningManager</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Handles the model adaptation process</span>
<span class="sd">    """</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">tune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">'inference'</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>

        <span class="n">params_copy</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="p">{}</span>
        <span class="n">finetune_mode</span> <span class="o">=</span> <span class="n">params_copy</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'finetune_mode'</span><span class="p">,</span> <span class="s1">'meta-learning'</span><span class="p">)</span>
        <span class="n">save_checkpoint_path</span> <span class="o">=</span> <span class="n">params_copy</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'save_checkpoint_path'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">save_checkpoint_path</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">default_dir</span> <span class="o">=</span> <span class="n">params_copy</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"checkpoint_dir"</span><span class="p">,</span> <span class="s2">"./checkpoints"</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">default_dir</span><span class="p">):</span>
                <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">default_dir</span><span class="p">)</span>
            <span class="n">save_checkpoint_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">default_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_latest.pt"</span><span class="p">)</span>

        <span class="c1"># Strategy selection: accept either explicit 'peft' strategy or finetune_method='peft'</span>
        <span class="n">finetune_method</span> <span class="o">=</span> <span class="n">params_copy</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'finetune_method'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">peft_config</span> <span class="o">=</span> <span class="n">params_copy</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'peft_config'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">selected_strategy</span> <span class="o">=</span> <span class="n">strategy</span>
        <span class="k">if</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s1">'finetune'</span> <span class="ow">and</span> <span class="n">finetune_method</span> <span class="o">==</span> <span class="s1">'peft'</span><span class="p">:</span>
            <span class="n">selected_strategy</span> <span class="o">=</span> <span class="s1">'peft'</span>
        <span class="k">elif</span> <span class="n">strategy</span> <span class="o">==</span> <span class="s1">'finetune'</span><span class="p">:</span>
            <span class="n">selected_strategy</span> <span class="o">=</span> <span class="s1">'base-ft'</span>

        <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">original_is_tab2d</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Tab2D</span><span class="p">)</span>


        <span class="k">if</span> <span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">Tab2D</span><span class="p">)</span> <span class="ow">or</span> <span class="n">original_is_tab2d</span><span class="p">)</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'finetune'</span><span class="p">,</span> <span class="s1">'base-ft'</span><span class="p">,</span> <span class="s1">'peft'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">finetune_mode</span> <span class="o">==</span> <span class="s1">'sft'</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Pure SFT for Mitra (task-optimized)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_mitra_pure_sft</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># default: 'meta-learning'</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Episodic Meta-Learning for Mitra (default)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_mitra</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">TabPFNClassifier</span><span class="p">)</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'finetune'</span><span class="p">,</span> <span class="s1">'base-ft'</span><span class="p">,</span> <span class="s1">'peft'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">finetune_mode</span> <span class="o">==</span> <span class="s1">'sft'</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Pure SFT for TabPFN (task-optimized)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabpfn_pure_sft</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># default: 'meta-learning'</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Episodic Meta-Learning for TabPFN (default)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabpfn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">TabICLClassifier</span><span class="p">,</span> <span class="n">OrionMSPClassifier</span><span class="p">,</span> <span class="n">OrionBixClassifier</span><span class="p">))</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'finetune'</span><span class="p">,</span> <span class="s1">'base-ft'</span><span class="p">,</span> <span class="s1">'peft'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">finetune_mode</span> <span class="o">==</span> <span class="s1">'meta-learning'</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Meta Learning based FT"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabicl</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Performing SFT"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabicl_simple_sft</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ConTextTabClassifier</span><span class="p">)</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'finetune'</span><span class="p">,</span> <span class="s1">'base-ft'</span><span class="p">,</span> <span class="s1">'peft'</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_full_finetune_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">TabDPTClassifier</span><span class="p">)</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">'finetune'</span><span class="p">,</span> <span class="s1">'base-ft'</span><span class="p">,</span> <span class="s1">'peft'</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">finetune_mode</span> <span class="o">==</span> <span class="s1">'sft'</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Pure SFT for TabDPT (task-optimized)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabdpt_pure_sft</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># default: 'meta-learning'</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Using Episodic Meta-Learning for TabDPT (default)"</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_finetune_tabdpt</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params_copy</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">)</span>
            <span class="n">is_finetuned</span> <span class="o">=</span> <span class="kc">True</span>


        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">Tab2D</span><span class="p">))</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="o">==</span> <span class="s1">'inference'</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] In-context learning model in inference mode. No training needed."</span><span class="p">)</span>
            <span class="k">pass</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="p">(</span><span class="n">TabICLClassifier</span><span class="p">,</span> <span class="n">OrionMSPClassifier</span><span class="p">,</span> <span class="n">OrionBixClassifier</span><span class="p">))</span> <span class="ow">and</span> <span class="n">selected_strategy</span> <span class="o">==</span> <span class="s1">'inference'</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Applying standard .fit() for TabICL setup (inference mode)"</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Applying standard model fitting (.fit)"</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>


        <span class="k">if</span> <span class="n">is_finetuned</span> <span class="ow">and</span> <span class="n">save_checkpoint_path</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">save_checkpoint_path</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Saved fine-tuned checkpoint to </span><span class="si">{</span><span class="n">save_checkpoint_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">save_checkpoint_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Reloaded fine-tuned weights into model for inference"</span><span class="p">)</span>


            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model'</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model_'</span><span class="p">):</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>


            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Reloaded fine-tuned weights and set model to eval mode"</span><span class="p">)</span>


        <span class="k">return</span> <span class="n">model</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">_maybe_save_epoch_ckpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">ckpt_epochs</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">prefix</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">ckpt_dir</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="ow">in</span> <span class="n">ckpt_epochs</span><span class="p">):</span>
            <span class="n">fname</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">prefix</span><span class="si">}</span><span class="s2">_epoch</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">.pt"</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_save_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_save_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Saving model checkpoint to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">torch_model</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model_'</span><span class="p">):</span>  <span class="c1"># For TabPFN, TabICL, OrionMSP, OrionBix</span>
            <span class="n">torch_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model'</span><span class="p">):</span>  <span class="c1"># For ContextTab, TabDPT</span>
            <span class="n">torch_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>  <span class="c1"># For Mitra</span>
            <span class="n">torch_model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="k">if</span> <span class="n">torch_model</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
            <span class="c1"># Ensure path is a string here!</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Checkpoint path must be a string"</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">path</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Checkpoint saved successfully to </span><span class="si">{</span><span class="n">path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Failed to save checkpoint: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] No compatible torch model found to save checkpoint"</span><span class="p">)</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Loads a checkpoint automatically to correct submodule."""</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Checkpoint path </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2"> not found"</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">model</span>

        <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'model_state_dict'</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
        <span class="n">candidates</span> <span class="o">=</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model_'</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model'</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">model</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">candidate</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Loaded checkpoint weights into </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                    <span class="k">return</span> <span class="n">model</span>
                <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Could not load into </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"[TuningManager] Failed to load weights into model"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_full_finetune_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Performs a standard full fine-tuning loop. This has been refactored to</span>
<span class="sd">        use the model's own tokenizer for batch preparation, ensuring correctness.</span>
<span class="sd">        """</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Starting full fine-tuning for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using fine-tuning config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">is_contexttab</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ConTextTabClassifier</span><span class="p">)</span>
        <span class="n">torch_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="n">torch_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">torch_model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">torch_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">is_contexttab</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Fitting the ConTextTab wrapper to set its data context"</span><span class="p">)</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] WARNING: ConTextTab PEFT support is currently experimental and may cause prediction issues"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] ConTextTab's complex embedding pipeline may conflict with LoRA adapters"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] RECOMMENDATION: Use 'base-ft' strategy for ConTextTab instead of 'peft'"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] FALLBACK: Proceeding with standard base fine-tuning"</span><span class="p">)</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Disable PEFT for ConTextTab</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">torch_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="c1"># Create a simple dataset of indices</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)))</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">dataloader</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Finetuning Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">batch_indices</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="c1"># Get the raw data for the current batch</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="s1">'iloc'</span><span class="p">):</span>  <span class="c1"># DataFrame</span>
                    <span class="n">X_batch_raw</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
                    <span class="n">y_batch_raw</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
                <span class="k">else</span><span class="p">:</span>  <span class="c1"># numpy array</span>
                    <span class="n">X_batch_raw</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>
                    <span class="n">y_batch_raw</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">batch_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">is_contexttab</span><span class="p">:</span>
                    <span class="c1"># Use the model's own tokenizer to prepare the batch</span>
                    <span class="c1"># This guarantees the correct format.</span>
                    <span class="n">data_batch</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_tokenized_data</span><span class="p">(</span><span class="n">X_batch_raw</span><span class="p">,</span> <span class="n">bagging_index</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

                    <span class="c1"># Move tensors to the correct device</span>
                    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">data_batch</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                            <span class="n">data_batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span> <span class="c1"># Handle nested dicts like â â¯data['data']â¯â </span>
                             <span class="k">for</span> <span class="n">k_inner</span><span class="p">,</span> <span class="n">v_inner</span> <span class="ow">in</span> <span class="n">v</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                                 <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v_inner</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                                     <span class="n">v</span><span class="p">[</span><span class="n">k_inner</span><span class="p">]</span> <span class="o">=</span> <span class="n">v_inner</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">data_batch</span><span class="p">[</span><span class="s1">'data'</span><span class="p">][</span><span class="s1">'target'</span><span class="p">]</span>
                    <span class="c1"># Ensure y_batch is Long type for cross-entropy loss (ContextTab may return Float)</span>
                    <span class="k">if</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">:</span>
                        <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="o">**</span><span class="n">data_batch</span><span class="p">)</span>

                <span class="k">else</span><span class="p">:</span> <span class="c1"># Fallback for other potential models</span>
                    <span class="n">X_batch_processed</span><span class="p">,</span> <span class="n">y_batch_processed</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_batch_raw</span><span class="p">,</span> <span class="n">y_batch_raw</span><span class="p">)</span>
                    <span class="n">X_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X_batch_processed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y_batch_processed</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="n">X_batch</span><span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Full fine-tuning complete"</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabpfn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">TabPFNClassifier</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Starting advanced TabPFN fine-tuning"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span> <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span> <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span> 
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using fine-tuning config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] WARNING: TabPFN PEFT support is currently experimental and unstable"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] TabPFN's batched inference engine conflicts with LoRA adapter state"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] RECOMMENDATION: Use 'base-ft' strategy for TabPFN instead of 'peft'"</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] FALLBACK: Proceeding with standard base fine-tuning"</span><span class="p">)</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Disable PEFT for TabPFN</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
        <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">stratified_splitter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">            </span><span class="sd">"""</span>
<span class="sd">            A robust splitter that attempts to stratify and falls back gracefully.</span>
<span class="sd">            """</span>
            <span class="c1"># Check if the target is multiclass and has at least 2 samples per class</span>
            <span class="n">y_series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">y_series</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># If stratification is possible, use it.</span>
                <span class="k">return</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Otherwise, use a standard random split.</span>
                <span class="k">return</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="c1"># Use our new, robust splitter function directly.</span>
        <span class="n">splitter</span> <span class="o">=</span> <span class="n">stratified_splitter</span>

        <span class="c1">#splitter = partial(train_test_split, test_size=0.3, stratify=None)</span>
        <span class="n">training_datasets</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_preprocessed_datasets</span><span class="p">(</span>
            <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">splitter</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">finetuning_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">training_datasets</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="n">meta_dataset_collator</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">finetuning_dataloader</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">finetuning_dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Finetuning Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">_move_to_device</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">target_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">target_device</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">return</span> <span class="p">[</span><span class="n">_move_to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_move_to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">item</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
                <span class="k">return</span> <span class="n">item</span>

            <span class="k">for</span> <span class="p">(</span><span class="n">X_train_batch</span><span class="p">,</span> <span class="n">X_test_batch</span><span class="p">,</span> <span class="n">y_train_batch</span><span class="p">,</span> <span class="n">y_test_batch</span><span class="p">,</span> <span class="n">cat_ixs</span><span class="p">,</span> <span class="n">confs</span><span class="p">)</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train_batch</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_test_batch</span><span class="p">)):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"[TuningManager] Skipping batch with inconsistent number of classes between train and test splits"</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">X_train_batch</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">X_train_batch</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">y_train_batch</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">y_train_batch</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">X_test_batch</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">X_test_batch</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">y_test_batch</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">y_test_batch</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>


                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">model</span><span class="o">.</span><span class="n">fit_from_preprocessed</span><span class="p">(</span><span class="n">X_train_batch</span><span class="p">,</span> <span class="n">y_train_batch</span><span class="p">,</span> <span class="n">cat_ixs</span><span class="p">,</span> <span class="n">confs</span><span class="p">)</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_test_batch</span><span class="p">,</span> <span class="n">return_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">device</span><span class="p">:</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="c1"># y_test_batch has already been moved above; in rare cases where it is a list</span>
                <span class="c1"># choose the first element (batch_size == 1 in our collator)</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_test_batch</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test_batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">y_test_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">target</span> <span class="o">=</span> <span class="n">y_test_batch</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">batched</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Fine-tuning complete"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">"[TuningManager] Setting fine-tuned model context for inference..."</span><span class="p">)</span>
        <span class="c1">#model.fit(X_train_processed, y_train_processed)</span>




    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabpfn_pure_sft</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">TabPFNClassifier</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Performs SFT-style finetuning.</span>

<span class="sd">        This is different from the meta-learning loop by:</span>
<span class="sd">        1. Using the *entire* dataset to create ONE single, large (Support, Query) episode.</span>
<span class="sd">        2. Training repeatedly over this single episode for multiple epochs.</span>

<span class="sd">        This forces the model to specialize on the single task derived from the </span>
<span class="sd">        full dataset, giving the "SFT sense".</span>
<span class="sd">        """</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
        <span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">LabelEncoder</span>

        <span class="c1"># This collator is required by the TabPFN API</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">..models.tabpfn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">meta_dataset_collator</span>
        <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"[TuningManager] FATAL: meta_dataset_collator not found. Please fix the import path"</span><span class="p">)</span>
            <span class="c1"># Define a minimal fallback if import fails</span>
            <span class="k">def</span><span class="w"> </span><span class="nf">meta_dataset_collator</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span> <span class="k">return</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] Using a placeholder meta_dataset_collator. This may fail"</span><span class="p">)</span>

        <span class="c1"># Helper to move tensors</span>
        <span class="k">def</span><span class="w"> </span><span class="nf">_move_to_device</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">target_device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">item</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">target_device</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">[</span><span class="n">_move_to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">item</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">_move_to_device</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">item</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
                <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">target_device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">item</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
            <span class="k">return</span> <span class="n">item</span>


        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Starting TabPFN SFT fine-tuning"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>  <span class="c1"># More epochs needed as we only have one "batch"</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"max_episode_size"</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">),</span>
            <span class="s2">"query_set_ratio"</span><span class="p">:</span> <span class="mf">0.3</span><span class="p">,</span>
            <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="c1"># Allow user to override SFT defaults</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
            <span class="c1"># Ensure max_episode_size isn't accidentally overridden by 'batch_size'</span>
            <span class="k">if</span> <span class="s1">'batch_size'</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] Ignoring 'batch_size' param, using 'max_episode_size' for SFT"</span><span class="p">)</span>
                <span class="n">config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'batch_size'</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using SFT-style config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Set to train mode</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] TabPFN PEFT not supported, falling back to base fine-tuning"</span><span class="p">)</span>
            <span class="n">peft_config</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> 
                         <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">],</span> 
                         <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
        <span class="n">loss_function</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="c1"># --- Data &amp; Label Preprocessing ---</span>
        <span class="c1"># (This section is the same as the meta-learning function)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">X_train_processed_np</span> <span class="o">=</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train_processed_np</span> <span class="o">=</span> <span class="n">X_train_processed</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">,</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)):</span>
            <span class="n">y_train_processed_np</span> <span class="o">=</span> <span class="n">y_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">y_train_processed_np</span> <span class="o">=</span> <span class="n">y_train_processed</span>

        <span class="k">if</span> <span class="n">y_train_processed_np</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">issubdtype</span><span class="p">(</span><span class="n">y_train_processed_np</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">number</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Converting non-numeric labels..."</span><span class="p">)</span>
            <span class="n">le</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
            <span class="n">y_train_processed_np</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train_processed_np</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'label_encoder_'</span><span class="p">):</span>
                 <span class="n">model</span><span class="o">.</span><span class="n">label_encoder_</span> <span class="o">=</span> <span class="n">le</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">sft_episode_splitter</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="n">y_series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">test_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"query_set_ratio"</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">y_series</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y_series</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Creating a single SFT task from </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_processed_np</span><span class="p">)</span><span class="si">}</span><span class="s2"> samples..."</span><span class="p">)</span>
        <span class="n">training_datasets</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_preprocessed_datasets</span><span class="p">(</span>
            <span class="n">X_train_processed_np</span><span class="p">,</span> 
            <span class="n">y_train_processed_np</span><span class="p">,</span> 
            <span class="n">sft_episode_splitter</span><span class="p">,</span> 
            <span class="n">config</span><span class="p">[</span><span class="s2">"max_episode_size"</span><span class="p">]</span> <span class="c1"># &lt;-- This makes it ONE episode</span>
        <span class="p">)</span>

        <span class="n">episode_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
            <span class="n">training_datasets</span><span class="p">,</span> 
            <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
            <span class="n">collate_fn</span><span class="o">=</span><span class="n">meta_dataset_collator</span><span class="p">,</span>
            <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

            <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">episode_dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"SFT Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">epoch_losses</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="p">(</span><span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span><span class="p">,</span> <span class="n">y_support</span><span class="p">,</span> <span class="n">y_query</span><span class="p">,</span> <span class="n">cat_ixs</span><span class="p">,</span> <span class="n">confs</span><span class="p">)</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_support</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_query</span><span class="p">)):</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] Skipping epoch: Inconsistent classes in SFT split"</span><span class="p">)</span>
                    <span class="k">continue</span>

                <span class="n">X_support</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">X_support</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">y_support</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">y_support</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">X_query</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
                <span class="n">y_query</span> <span class="o">=</span> <span class="n">_move_to_device</span><span class="p">(</span><span class="n">y_query</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># 1. Set the (large) Support Set as the prompt</span>
                <span class="n">model</span><span class="o">.</span><span class="n">fit_from_preprocessed</span><span class="p">(</span><span class="n">X_support</span><span class="p">,</span> <span class="n">y_support</span><span class="p">,</span> <span class="n">cat_ixs</span><span class="p">,</span> <span class="n">confs</span><span class="p">)</span>

                <span class="c1"># 2. Predict on the (large) Query Set</span>
                <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_query</span><span class="p">,</span> <span class="n">return_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="n">predictions</span><span class="o">.</span><span class="n">device</span> <span class="o">!=</span> <span class="n">device</span><span class="p">:</span>
                    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">target</span> <span class="o">=</span> <span class="n">y_query</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_query</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="n">y_query</span>

                <span class="c1"># 3. Calculate loss and backpropagate</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

                <span class="c1"># SFT HINT 4: Add gradient clipping for stability</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">epoch_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_losses</span><span class="p">)</span> <span class="k">if</span> <span class="n">epoch_losses</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">'nan'</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span><span class="si">}</span><span class="s2">]: Task Loss = </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">batched</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] SFT-style finetuning complete"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabicl</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="p">(</span><span class="n">TabICLClassifier</span><span class="p">,</span> <span class="n">OrionMSPClassifier</span><span class="p">,</span> <span class="n">OrionBixClassifier</span><span class="p">),</span> <span class="n">X_train_processed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Starting advanced TabICL/OrionMSP/OrionBix fine-tuning"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">2e-6</span><span class="p">,</span> <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"support_size"</span><span class="p">:</span> <span class="mi">48</span><span class="p">,</span> <span class="s2">"query_size"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s2">"n_episodes"</span><span class="p">:</span> <span class="mi">1000</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using fine-tuning config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">_load_model</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">)</span> 

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">OrionBixClassifier</span><span class="p">):</span> 
                    <span class="n">model_key</span> <span class="o">=</span> <span class="s2">"OrionBix"</span> 
                <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">OrionMSPClassifier</span><span class="p">):</span>
                    <span class="n">model_key</span> <span class="o">=</span> <span class="s2">"OrionMSP"</span>
                <span class="k">else</span> <span class="p">:</span>
                    <span class="n">model_key</span> <span class="o">=</span> <span class="s2">"TabICL"</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model_</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="n">model_key</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] PEFT SUCCESS: Applied LoRA adapters to </span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2"> model"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] PEFT FAILED: TabICL/OrionMSP/OrionBix incompatible with PEFT: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] FALLBACK: Proceeding with base fine-tuning (fully supported)"</span><span class="p">)</span>


        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="c1"># --- discover the true logits width from a safe 1-class probe ---</span>
        <span class="n">C_out</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># make one tiny 1-class episode from the first few rows</span>
            <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">y_np</span> <span class="o">=</span> <span class="n">y_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">y_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

            <span class="c1"># pick a class that has &gt;= (support_size + query_size) examples; fall back to any class</span>
            <span class="n">s_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"support_size"</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span>
            <span class="n">q_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"query_size"</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
            <span class="n">need</span> <span class="o">=</span> <span class="n">s_sz</span> <span class="o">+</span> <span class="n">q_sz</span>

            <span class="bp">cls</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_np</span><span class="p">):</span>
                <span class="n">cand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">y_np</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">cand</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;=</span> <span class="n">need</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">cand</span><span class="p">[:</span><span class="n">need</span><span class="p">]</span>
                    <span class="bp">cls</span> <span class="o">=</span> <span class="n">c</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">need</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_np</span><span class="p">)))</span>
                <span class="bp">cls</span> <span class="o">=</span> <span class="n">y_np</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">X_ep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_np</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># [1, S+Q, F]</span>
            <span class="n">ys</span>   <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">s_sz</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>       <span class="c1"># all support -&gt; class 0</span>
            <span class="c1"># pack as your forward expects: first S as support, rest as query</span>
            <span class="n">logits_probe</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_ep</span><span class="p">,</span> <span class="n">ys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>                   <span class="c1"># [1, Q, C_eff] typically</span>
            <span class="n">C_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">logits_probe</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># safety</span>
        <span class="k">if</span> <span class="n">C_out</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Could not infer logits width (C_out)."</span><span class="p">)</span>



        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="n">meta_dataset</span> <span class="o">=</span> <span class="n">TabICLMetaDataset</span><span class="p">(</span>
            <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span>
            <span class="n">support_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"support_size"</span><span class="p">,</span> <span class="mi">48</span><span class="p">)),</span>
            <span class="n">query_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"query_size"</span><span class="p">,</span> <span class="mi">32</span><span class="p">)),</span>
            <span class="n">n_episodes</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"n_episodes"</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">meta_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">dataloader</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Finetuning Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">X_episode</span><span class="p">,</span> <span class="n">y_support</span><span class="p">,</span> <span class="n">y_query</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">X_episode</span><span class="p">,</span> <span class="n">y_support</span><span class="p">,</span> <span class="n">y_query</span> <span class="o">=</span> <span class="n">X_episode</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_support</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y_query</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">ys</span> <span class="o">=</span> <span class="n">y_support</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">yq</span> <span class="o">=</span> <span class="n">y_query</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

                <span class="n">supp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
                <span class="c1"># keep at most C_out classes so the head can represent them</span>
                <span class="n">keep</span> <span class="o">=</span> <span class="n">supp</span><span class="p">[:</span><span class="n">C_out</span><span class="p">]</span>

                <span class="c1"># build map only for kept classes; others -&gt; -1 (excluded)</span>
                <span class="n">yq_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">yq</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">keep</span><span class="p">):</span>
                    <span class="n">ys_m</span><span class="p">[</span><span class="n">ys</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">yq_m</span><span class="p">[</span><span class="n">yq</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

                <span class="c1"># prune support rows that were dropped</span>
                <span class="n">keep_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">ys_m</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">ys_m</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
                <span class="n">X_support_kept</span> <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:][:,</span> <span class="n">keep_mask</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">X_query_part</span>   <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:]</span>
                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support_kept</span><span class="p">,</span> <span class="n">X_query_part</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># if any query label was excluded, skip this episode (avoids OOB gathers)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">yq_m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>

                <span class="c1"># forward with episodic labels (contiguous, â¤ C_out)</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_episode</span><span class="p">,</span> <span class="n">ys_m</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># [1, Q, &lt;=C_out]</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># [Q, &lt;=C_out]</span>
                 <span class="c1"># ensure mapping fits the actual head width (in case adapters changed it mid-run)</span>
                <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">yq_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">continue</span>  <span class="c1"># skip this episode if it exceeds head capacity</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">yq_m</span><span class="p">)</span>



                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Fine-tuning complete"</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabicl_pure_sft</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="p">(</span><span class="n">TabICLClassifier</span><span class="p">,</span> <span class="n">OrionMSPClassifier</span><span class="p">,</span> <span class="n">OrionBixClassifier</span><span class="p">)</span> <span class="p">,</span> <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        PURE SFT FINE-TUNING (Not Recommended for TabICL)</span>

<span class="sd">        Standard supervised fine-tuning on full batches WITHOUT episodic structure.</span>

<span class="sd">        WARNING: This ignores TabICL's meta-learning design and may:</span>
<span class="sd">        - Reduce generalization to new tasks</span>
<span class="sd">        - Increase catastrophic forgetting</span>
<span class="sd">        - Overfit to the specific target task</span>

<span class="sd">        Use ONLY for:</span>
<span class="sd">        - Benchmarking against traditional fine-tuning</span>
<span class="sd">        - Comparison studies</span>
<span class="sd">        - Tasks where you explicitly want to sacrifice generalization for accuracy</span>
<span class="sd">        """</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] WARNING: Pure SFT on TabICL breaks its meta-learning design"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] This approach may reduce generalization to new tasks"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] RECOMMENDATION: Use episodic or SFT-hybrid instead"</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] PROCEED: Using pure SFT (use only for comparisons)"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
            <span class="s2">"warmup_epochs"</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">_load_model</span><span class="p">()</span>

        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="n">C_out</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># make one tiny 1-class episode from the first few rows</span>
            <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">y_np</span> <span class="o">=</span> <span class="n">y_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">y_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

            <span class="c1"># pick a class that has &gt;= (support_size + query_size) examples; fall back to any class</span>
            <span class="n">s_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"support_size"</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span>
            <span class="n">q_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"query_size"</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
            <span class="n">need</span> <span class="o">=</span> <span class="n">s_sz</span> <span class="o">+</span> <span class="n">q_sz</span>

            <span class="bp">cls</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_np</span><span class="p">):</span>
                <span class="n">cand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">y_np</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">cand</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;=</span> <span class="n">need</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">cand</span><span class="p">[:</span><span class="n">need</span><span class="p">]</span>
                    <span class="bp">cls</span> <span class="o">=</span> <span class="n">c</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">need</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_np</span><span class="p">)))</span>
                <span class="bp">cls</span> <span class="o">=</span> <span class="n">y_np</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">X_ep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_np</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># [1, S+Q, F]</span>
            <span class="n">ys</span>   <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">s_sz</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>       <span class="c1"># all support -&gt; class 0</span>
            <span class="c1"># pack as your forward expects: first S as support, rest as query</span>
            <span class="n">logits_probe</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_ep</span><span class="p">,</span> <span class="n">ys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>                   <span class="c1"># [1, Q, C_eff] typically</span>
            <span class="n">C_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">logits_probe</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># safety</span>
        <span class="k">if</span> <span class="n">C_out</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Could not infer logits width (C_out)."</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model_</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="s2">"TabICL"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Applied LoRA adapters to TabICL (pure SFT)"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] LoRA failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Proceeding with base pure SFT fine-tuning"</span><span class="p">)</span>

    <span class="c1"># Create standard supervised dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">],</span>
                                <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="c1"># Optional: Learning rate scheduler</span>
        <span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"warmup_epochs"</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span><span class="p">)))</span>

        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>

        <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">dataloader</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Pure SFT Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># split batch into a small pseudo-episode: half support, half query</span>
                <span class="n">mid</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="n">X_support</span><span class="p">,</span> <span class="n">y_support</span> <span class="o">=</span> <span class="n">X_batch</span><span class="p">[:</span><span class="n">mid</span><span class="p">],</span> <span class="n">y_batch</span><span class="p">[:</span><span class="n">mid</span><span class="p">]</span>
                <span class="n">X_query</span><span class="p">,</span>   <span class="n">y_query</span>   <span class="o">=</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">mid</span><span class="p">:],</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">mid</span><span class="p">:]</span>
                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

                <span class="n">ys</span> <span class="o">=</span> <span class="n">y_support</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">yq</span> <span class="o">=</span> <span class="n">y_query</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

                <span class="n">supp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
                <span class="c1"># keep at most C_out classes so the head can represent them</span>
                <span class="n">keep</span> <span class="o">=</span> <span class="n">supp</span><span class="p">[:</span><span class="n">C_out</span><span class="p">]</span>

                <span class="c1"># build map only for kept classes; others -&gt; -1 (excluded)</span>
                <span class="n">yq_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">yq</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">keep</span><span class="p">):</span>
                    <span class="n">ys_m</span><span class="p">[</span><span class="n">ys</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">yq_m</span><span class="p">[</span><span class="n">yq</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

                <span class="c1"># prune support rows that were dropped</span>
                <span class="n">keep_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">ys_m</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">ys_m</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
                <span class="n">X_support_kept</span> <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="p">:</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:][:,</span> <span class="n">keep_mask</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">X_query_part</span>   <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:]</span>
                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support_kept</span><span class="p">,</span> <span class="n">X_query_part</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># if any query label was excluded, skip this episode (avoids OOB gathers)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">yq_m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>

                <span class="c1"># forward with episodic labels (contiguous, â¤ C_out)</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_episode</span><span class="p">,</span> <span class="n">ys_m</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># [1, Q, &lt;=C_out]</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                           <span class="c1"># [Q, &lt;=C_out]</span>
                 <span class="c1"># ensure mapping fits the actual head width (in case adapters changed it mid-run)</span>
                <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">yq_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">continue</span>  <span class="c1"># skip this episode if it exceeds head capacity</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">yq_m</span><span class="p">)</span>


                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Avg Loss = </span><span class="si">{</span><span class="n">epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
                   <span class="sa">f</span><span class="s2">"LR = </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s2">"[TuningManager] Pure SFT training complete (remember: not recommended for TabICL)"</span><span class="p">)</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_mitra</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Performs episodic fine-tuning for in-context models like Mitra (Tab2D).</span>
<span class="sd">        """</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Starting episodic fine-tuning for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s2">"support_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
            <span class="s2">"query_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
            <span class="s2">"steps_per_epoch"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using fine-tuning config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="s2">"Mitra"</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] PEFT SUCCESS: Applied LoRA adapters to Mitra (Tab2D) model"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] PEFT FAILED: Mitra (Tab2D) incompatible with PEFT: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] FALLBACK: Proceeding with base fine-tuning (fully supported)"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">episode_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'support_size'</span><span class="p">]</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s1">'query_size'</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'steps_per_epoch'</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Finetuning Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">X_episodes</span><span class="p">,</span> <span class="n">y_episodes</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]):</span>
                    <span class="c1"># episode size does not exceed available samples</span>
                    <span class="k">if</span> <span class="n">episode_size</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
                        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Warning: Episode size (</span><span class="si">{</span><span class="n">episode_size</span><span class="si">}</span><span class="s2">) is larger than the dataset size (</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">). Using all samples"</span><span class="p">)</span>
                        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">episode_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

                    <span class="n">X_episodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>
                    <span class="n">y_episodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span>

                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">X_episodes</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">y_episodes</span><span class="p">))</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="n">s_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'support_size'</span><span class="p">]</span>
                <span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span> <span class="o">=</span> <span class="n">X_batch</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s_size</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X_batch</span><span class="p">[:,</span> <span class="n">s_size</span><span class="p">:,</span> <span class="p">:]</span>
                <span class="n">y_support</span><span class="p">,</span> <span class="n">y_query</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">[:,</span> <span class="p">:</span><span class="n">s_size</span><span class="p">],</span> <span class="n">y_batch</span><span class="p">[:,</span> <span class="n">s_size</span><span class="p">:]</span>

                <span class="n">b</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">X_support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">padding_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="n">padding_obs_support</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_support</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="n">padding_obs_query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">X_query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
                    <span class="n">x_support</span><span class="o">=</span><span class="n">X_support</span><span class="p">,</span> <span class="n">y_support</span><span class="o">=</span><span class="n">y_support</span><span class="p">,</span> <span class="n">x_query</span><span class="o">=</span><span class="n">X_query</span><span class="p">,</span>
                    <span class="n">padding_features</span><span class="o">=</span><span class="n">padding_features</span><span class="p">,</span> <span class="n">padding_obs_support</span><span class="o">=</span><span class="n">padding_obs_support</span><span class="p">,</span>
                    <span class="n">padding_obs_query__</span><span class="o">=</span><span class="n">padding_obs_query</span>
                <span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">y_query</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Episodic fine-tuning complete"</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabdpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">TabDPTClassifier</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Performs episodic fine-tuning for the TabDPT model.</span>
<span class="sd">        """</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Starting episodic fine-tuning for </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Determine number of classes from training data</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">))</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Detected </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2"> classes in training data"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span> 
            <span class="s2">"support_size"</span><span class="p">:</span> <span class="mi">512</span><span class="p">,</span>
            <span class="s2">"query_size"</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
            <span class="s2">"steps_per_epoch"</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using fine-tuning config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="s2">"TabDPT"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] PEFT SUCCESS: Applied LoRA to TabDPT model"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] PEFT not compatible with TabDPT: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Proceeding with base fine-tuning"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Also ensure the model's device attribute is updated</span>
        <span class="n">model</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># TabDPT now handles projection internally, so only use model parameters</span>
        <span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">trainable_params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1">#episode_size = config['support_size'] + config['query_size']</span>

        <span class="c1"># Compute PCA basis on GPU once, no autograd</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"feature_reduction"</span><span class="p">,</span> <span class="s2">"pca"</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"pca"</span> <span class="ow">and</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"V"</span><span class="p">):</span>
                    <span class="n">x_dev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                    <span class="n">q</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x_dev</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pca_lowrank</span><span class="p">(</span><span class="n">x_dev</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">V</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">V</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>


        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'steps_per_epoch'</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">iterable</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Finetuning Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">episode_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'support_size'</span><span class="p">]</span> <span class="o">+</span> <span class="n">config</span><span class="p">[</span><span class="s1">'query_size'</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">episode_size</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
                    <span class="n">scale</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">episode_size</span><span class="p">)</span>
                    <span class="n">s</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'support_size'</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale</span><span class="p">))</span>
                    <span class="n">q</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'query_size'</span><span class="p">]</span> <span class="o">*</span> <span class="n">scale</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">s</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'support_size'</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s1">'query_size'</span><span class="p">]</span>

                <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">s</span> <span class="o">+</span> <span class="n">q</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">[</span><span class="n">indices</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                 <span class="c1"># JIT PCA projection on GPU without affecting gradients</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"feature_reduction"</span><span class="p">,</span> <span class="s2">"pca"</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"pca"</span> <span class="ow">and</span> <span class="n">X_episode</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"V"</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">X_episode</span> <span class="o">=</span> <span class="n">X_episode</span> <span class="o">@</span> <span class="n">model</span><span class="o">.</span><span class="n">V</span>


                <span class="n">X_support</span> <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">y_support</span> <span class="o">=</span> <span class="n">y_episode</span><span class="p">[:</span><span class="n">s</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">X_query</span>   <span class="o">=</span> <span class="n">X_episode</span><span class="p">[</span><span class="n">s</span><span class="p">:]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">y_query</span>   <span class="o">=</span> <span class="n">y_episode</span><span class="p">[</span><span class="n">s</span><span class="p">:]</span>

                <span class="c1"># Apply padding to match model's expected feature count</span>
                <span class="n">X_support</span> <span class="o">=</span> <span class="n">pad_x</span><span class="p">(</span><span class="n">X_support</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">pad_x</span><span class="p">(</span><span class="n">X_query</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>

                <span class="n">x_src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">ys</span> <span class="o">=</span> <span class="n">y_support</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">yq</span> <span class="o">=</span> <span class="n">y_query</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

                <span class="n">supp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
                <span class="n">max_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">max</span><span class="p">()),</span> <span class="nb">int</span><span class="p">(</span><span class="n">yq</span><span class="o">.</span><span class="n">max</span><span class="p">())))</span>
                <span class="n">emap</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">max_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,),</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">supp</span><span class="p">):</span>
                    <span class="n">emap</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">i</span>

                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">emap</span><span class="p">[</span><span class="n">ys</span><span class="p">]</span>
                <span class="n">yq_m</span> <span class="o">=</span> <span class="n">emap</span><span class="p">[</span><span class="n">yq</span><span class="p">]</span>

                <span class="c1"># Skip episode if query label isn't in support (avoids OOB inside model/CE)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">yq_m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x_src</span><span class="o">=</span><span class="n">x_src</span><span class="p">,</span> <span class="n">y_src</span><span class="o">=</span><span class="n">ys_m</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">task</span><span class="o">=</span><span class="s1">'cls'</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="k">elif</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">Q</span> <span class="o">=</span> <span class="n">yq_m</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                        <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">-</span><span class="n">Q</span><span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
                <span class="k">elif</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">pass</span>
                <span class="k">elif</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unexpected logits shape </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">; expected 2D or 3D."</span><span class="p">)</span>

                <span class="c1"># --- Guard CE range and compute loss with EPISODIC targets ---</span>
                <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">yq_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="o">&gt;=</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
                    <span class="k">continue</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">yq_m</span><span class="p">)</span>

                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="c1"># Clean up: ensure model is in eval mode and on correct device after finetuning</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Ensure all parameters and buffers are on the correct device</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Episodic fine-tuning complete"</span><span class="p">)</span>



    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_mitra_pure_sft</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        PURE SFT FOR MITRA</span>

<span class="sd">        Unlike TabICL, pure SFT works naturally for Mitra because:</span>
<span class="sd">        1. Forward method is flexible with sequence dimensions</span>
<span class="sd">        2. Padding masks handle variable-length sequences</span>
<span class="sd">        3. Better for task-specific optimization</span>

<span class="sd">        This is suitable when you want to fully optimize for target task accuracy.</span>
<span class="sd">        """</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Starting Mitra Pure SFT Fine-tuning"</span><span class="p">)</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
            <span class="s2">"warmup_epochs"</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>
        <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="s2">"Mitra"</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Applied LoRA adapters to Mitra (pure SFT)"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] LoRA failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

    <span class="c1"># Create dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                                <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">],</span>
                                <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="c1"># LR scheduler</span>
        <span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"warmup_epochs"</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span><span class="p">)))</span>

        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">dataloader</span>
            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Pure SFT Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Convert to episodic format for Mitra</span>
            <span class="c1"># [B, F] -&gt; [B, 1, F] (treat entire batch as query with no support)</span>
                <span class="n">X_support</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">y_support</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">b</span><span class="p">,</span> <span class="n">f</span> <span class="o">=</span> <span class="n">X_support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X_support</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="n">padding_features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="n">padding_obs_support</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y_support</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
                <span class="n">padding_obs_query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">X_query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
                    <span class="n">x_support</span><span class="o">=</span><span class="n">X_support</span><span class="p">,</span> <span class="n">y_support</span><span class="o">=</span><span class="n">y_support</span><span class="p">,</span> <span class="n">x_query</span><span class="o">=</span><span class="n">X_query</span><span class="p">,</span>
                    <span class="n">padding_features</span><span class="o">=</span><span class="n">padding_features</span><span class="p">,</span>
                    <span class="n">padding_obs_support</span><span class="o">=</span><span class="n">padding_obs_support</span><span class="p">,</span>
                    <span class="n">padding_obs_query__</span><span class="o">=</span><span class="n">padding_obs_query</span>
                <span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">y_batch</span><span class="p">)</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Avg Loss = </span><span class="si">{</span><span class="n">epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Pure SFT fine-tuning complete"</span><span class="p">)</span>


    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabdpt_pure_sft</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">processor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        PURE SUPERVISED FINE-TUNING FOR TabDPT</span>

<span class="sd">        Standard batch-wise supervised training without episodic sampling.</span>
<span class="sd">        Works similarly to Mitra's pure SFT approach.</span>

<span class="sd">        Args:</span>
<span class="sd">            model: TabDPTClassifier instance</span>
<span class="sd">            X_train_processed: Preprocessed features (numpy array)</span>
<span class="sd">            y_train_processed: Target labels (numpy array)</span>
<span class="sd">            params: Fine-tuning hyperparameters</span>
<span class="sd">            processor: TabDPT processor with projector</span>
<span class="sd">            peft_config: PEFT configuration (optional)</span>
<span class="sd">        """</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Starting TabDPT Pure Supervised Fine-Tuning"</span><span class="p">)</span>

        <span class="c1"># Normalize labels to contiguous 0..C-1 IDs (prevents CE out-of-range)</span>
        <span class="n">classes</span><span class="p">,</span> <span class="n">y_train_processed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y_train_processed</span> <span class="o">=</span> <span class="n">y_train_processed</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">num_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Detected </span><span class="si">{</span><span class="n">num_classes</span><span class="si">}</span><span class="s2"> classes in training data (contiguous remap)"</span><span class="p">)</span>
        <span class="c1"># (Optional) keep mapping if you need to inverse-transform later</span>
        <span class="n">model</span><span class="o">.</span><span class="n">classes_</span> <span class="o">=</span> <span class="n">classes</span>


        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"device"</span><span class="p">:</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="p">,</span>
            <span class="s2">"epochs"</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s2">"learning_rate"</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
            <span class="s2">"batch_size"</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span>
            <span class="s2">"show_progress"</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
            <span class="s2">"weight_decay"</span><span class="p">:</span> <span class="mf">1e-4</span><span class="p">,</span>
            <span class="s2">"warmup_epochs"</span><span class="p">:</span> <span class="mi">1</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Using config: </span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">"device"</span><span class="p">])</span>

        <span class="k">if</span> <span class="n">peft_config</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">apply_tabular_lora</span><span class="p">(</span><span class="s2">"TabDPT"</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Applied LoRA adapters to TabDPT (Pure SFT)"</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] PEFT failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Proceeding with base fine-tuning"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">buffer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
            <span class="n">buffer</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">buffer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Compute PCA basis on GPU once, no autograd (only if needed)</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"feature_reduction"</span><span class="p">,</span> <span class="s2">"pca"</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"pca"</span> <span class="ow">and</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"V"</span><span class="p">):</span>
                    <span class="n">x_dev</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
                    <span class="n">q</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">x_dev</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pca_lowrank</span><span class="p">(</span><span class="n">x_dev</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">q</span><span class="p">)</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">V</span> <span class="o">=</span> <span class="n">V</span>
                    <span class="n">model</span><span class="o">.</span><span class="n">V</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>


        <span class="n">trainable_params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">processor</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">processor</span><span class="p">,</span> <span class="s1">'custom_preprocessor_'</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">custom_preprocessor_</span><span class="p">,</span> <span class="s1">'projector_'</span><span class="p">):</span>
            <span class="n">trainable_params</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">custom_preprocessor_</span><span class="o">.</span><span class="n">projector_</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] Including projector parameters in optimizer"</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span>
            <span class="n">trainable_params</span><span class="p">,</span>
            <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"learning_rate"</span><span class="p">],</span>
            <span class="n">weight_decay</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"weight_decay"</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">"batch_size"</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">total_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span>
        <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">config</span><span class="p">[</span><span class="s2">"warmup_epochs"</span><span class="p">]</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">lr_lambda</span><span class="p">(</span><span class="n">current_step</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">current_step</span> <span class="o">&lt;</span> <span class="n">warmup_steps</span><span class="p">:</span>
                <span class="k">return</span> <span class="nb">float</span><span class="p">(</span><span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">warmup_steps</span><span class="p">))</span>
            <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">total_steps</span> <span class="o">-</span> <span class="n">current_step</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_steps</span> <span class="o">-</span> <span class="n">warmup_steps</span><span class="p">)))</span>

        <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">LambdaLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">lr_lambda</span><span class="p">)</span>

        <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s2">"epochs"</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">dataloader</span>

            <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"Pure SFT Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># JIT PCA projection on GPU without affecting gradients</span>
                <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"feature_reduction"</span><span class="p">,</span> <span class="s2">"pca"</span><span class="p">)</span> <span class="o">==</span> <span class="s2">"pca"</span> <span class="ow">and</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">"V"</span><span class="p">):</span>
                    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                        <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span> <span class="o">@</span> <span class="n">model</span><span class="o">.</span><span class="n">V</span>

                <span class="n">X_support</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">y_support</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">X_support</span> <span class="o">=</span> <span class="n">pad_x</span><span class="p">(</span><span class="n">X_support</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">pad_x</span><span class="p">(</span><span class="n">X_query</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">max_features</span><span class="p">)</span>

                <span class="n">x_src</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">(</span>
                    <span class="n">x_src</span><span class="o">=</span><span class="n">x_src</span><span class="p">,</span>
                    <span class="n">y_src</span><span class="o">=</span><span class="n">y_support</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
                    <span class="n">task</span><span class="o">=</span><span class="s1">'cls'</span>
                <span class="p">)</span>

                <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="n">num_classes</span><span class="p">]</span>            <span class="c1"># trim to observed classes cap</span>
                <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>                <span class="c1"># normalize to [B, C]</span>
                <span class="k">elif</span> <span class="n">logits</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Unexpected logits shape: </span><span class="si">{</span><span class="nb">tuple</span><span class="p">(</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

                <span class="c1"># CE requires targets in [0, C-1]; if head width &lt; num_classes, drop OOR rows</span>
                <span class="n">C_eff</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

                <span class="n">valid</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y_batch</span> <span class="o">&lt;</span> <span class="n">C_eff</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">valid</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                    <span class="c1"># skip this minibatch if nothing valid remains</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">valid</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                        <span class="k">continue</span>
                    <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span>
                    <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">valid</span><span class="p">]</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>


                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s2">"show_progress"</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
                        <span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
                        <span class="n">lr</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">"</span>
                    <span class="p">)</span>

            <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">epoch_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"[TuningManager] Epoch [</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span><span class="si">}</span><span class="s2">]: "</span>
                <span class="sa">f</span><span class="s2">"Avg Loss = </span><span class="si">{</span><span class="n">avg_loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, "</span>
                <span class="sa">f</span><span class="s2">"LR = </span><span class="si">{</span><span class="n">scheduler</span><span class="o">.</span><span class="n">get_last_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2e</span><span class="si">}</span><span class="s2">"</span>
            <span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">"[TuningManager] TabDPT Pure Supervised Fine-Tuning Complete"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_finetune_tabicl_simple_sft</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">peft_config</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        TabICL : Convert supervised batches to episodic format</span>
<span class="sd">        """</span>

        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">'device'</span><span class="p">:</span> <span class="s1">'cuda'</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">'cpu'</span><span class="p">,</span>
            <span class="s1">'epochs'</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
            <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">1e-5</span><span class="p">,</span>
            <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
            <span class="s1">'show_progress'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
            <span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'device'</span><span class="p">])</span>

    <span class="c1"># Initialize</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">y_train_processed</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">_load_model</span><span class="p">()</span>
        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="n">C_out</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="c1"># make one tiny 1-class episode from the first few rows</span>
            <span class="n">X_np</span> <span class="o">=</span> <span class="n">X_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">X_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
            <span class="n">y_np</span> <span class="o">=</span> <span class="n">y_train_processed</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">else</span> <span class="n">y_train_processed</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

            <span class="c1"># pick a class that has &gt;= (support_size + query_size) examples; fall back to any class</span>
            <span class="n">s_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"support_size"</span><span class="p">,</span> <span class="mi">48</span><span class="p">))</span>
            <span class="n">q_sz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"query_size"</span><span class="p">,</span> <span class="mi">32</span><span class="p">))</span>
            <span class="n">need</span> <span class="o">=</span> <span class="n">s_sz</span> <span class="o">+</span> <span class="n">q_sz</span>

            <span class="bp">cls</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
            <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_np</span><span class="p">):</span>
                <span class="n">cand</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nonzero</span><span class="p">(</span><span class="n">y_np</span> <span class="o">==</span> <span class="n">c</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">cand</span><span class="o">.</span><span class="n">size</span> <span class="o">&gt;=</span> <span class="n">need</span><span class="p">:</span>
                    <span class="n">idx</span> <span class="o">=</span> <span class="n">cand</span><span class="p">[:</span><span class="n">need</span><span class="p">]</span>
                    <span class="bp">cls</span> <span class="o">=</span> <span class="n">c</span>
                    <span class="k">break</span>
            <span class="k">if</span> <span class="n">idx</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">need</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_np</span><span class="p">)))</span>
                <span class="bp">cls</span> <span class="o">=</span> <span class="n">y_np</span><span class="p">[</span><span class="n">idx</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>

            <span class="n">X_ep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_np</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>   <span class="c1"># [1, S+Q, F]</span>
            <span class="n">ys</span>   <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">s_sz</span><span class="p">,),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>       <span class="c1"># all support -&gt; class 0</span>
            <span class="c1"># pack as your forward expects: first S as support, rest as query</span>
            <span class="n">logits_probe</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_ep</span><span class="p">,</span> <span class="n">ys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>                   <span class="c1"># [1, Q, C_eff] typically</span>
            <span class="n">C_out</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">logits_probe</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># safety</span>
        <span class="k">if</span> <span class="n">C_out</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">"Could not infer logits width (C_out)."</span><span class="p">)</span>




    <span class="c1"># Standard dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train_processed</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="n">dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">],</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate'</span><span class="p">])</span>
        <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">config</span><span class="p">[</span><span class="s1">'epochs'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">iterable</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">"SFT Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span> <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s1">'show_progress'</span><span class="p">]</span> <span class="k">else</span> <span class="n">dataloader</span>
            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">for</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
                <span class="n">batch_size</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">X_batch</span> <span class="o">=</span> <span class="n">X_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">y_batch</span> <span class="o">=</span> <span class="n">y_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

            <span class="c1"># Split batch in half: first half = support, second half = query</span>
                <span class="n">mid</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="mi">2</span>
                <span class="k">if</span> <span class="n">mid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Skip if batch too small</span>
                    <span class="k">continue</span>
                <span class="n">X_support</span> <span class="o">=</span> <span class="n">X_batch</span><span class="p">[:</span><span class="n">mid</span><span class="p">]</span>
                <span class="n">y_support</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">[:</span><span class="n">mid</span><span class="p">]</span>
                <span class="n">X_query</span> <span class="o">=</span> <span class="n">X_batch</span><span class="p">[</span><span class="n">mid</span><span class="p">:]</span>
                <span class="n">y_query</span> <span class="o">=</span> <span class="n">y_batch</span><span class="p">[</span><span class="n">mid</span><span class="p">:]</span>

                <span class="c1"># Ensure X_support and X_query are 2D [samples, features] before concatenation</span>
                <span class="k">if</span> <span class="n">X_support</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">X_support</span> <span class="o">=</span> <span class="n">X_support</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">mid</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Flatten extra dimensions</span>
                <span class="k">if</span> <span class="n">X_query</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">X_query</span> <span class="o">=</span> <span class="n">X_query</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X_query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># Flatten extra dimensions</span>

                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support</span><span class="p">,</span> <span class="n">X_query</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># [1, batch_size, features]</span>

                <span class="n">ys</span> <span class="o">=</span> <span class="n">y_support</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span> <span class="k">if</span> <span class="n">y_support</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y_support</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
                <span class="n">yq</span> <span class="o">=</span> <span class="n">y_query</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span> <span class="k">if</span> <span class="n">y_query</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y_query</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

                <span class="n">supp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">ys</span><span class="p">)</span>
                <span class="c1"># keep at most C_out classes so the head can represent them</span>
                <span class="n">keep</span> <span class="o">=</span> <span class="n">supp</span><span class="p">[:</span><span class="n">C_out</span><span class="p">]</span>

                <span class="c1"># build map only for kept classes; others -&gt; -1 (excluded)</span>
                <span class="n">yq_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">yq</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full_like</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">keep</span><span class="p">):</span>
                    <span class="n">ys_m</span><span class="p">[</span><span class="n">ys</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
                    <span class="n">yq_m</span><span class="p">[</span><span class="n">yq</span> <span class="o">==</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>

                <span class="c1"># prune support rows that were dropped</span>
                <span class="n">keep_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">ys_m</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">keep_mask</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>
                <span class="n">ys_m</span> <span class="o">=</span> <span class="n">ys_m</span><span class="p">[</span><span class="n">keep_mask</span><span class="p">]</span>
                <span class="c1"># Use mid directly for support size (before filtering) and apply keep_mask correctly</span>
                <span class="c1"># X_episode shape: [1, batch_size, features], mid is the original support size</span>
                <span class="c1"># Index support samples first, then apply keep_mask to avoid dimension issues</span>
                <span class="n">X_support_all</span> <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="p">:</span><span class="n">mid</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># [1, mid, F]</span>
                <span class="n">X_support_kept</span> <span class="o">=</span> <span class="n">X_support_all</span><span class="p">[:,</span> <span class="n">keep_mask</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># [1, kept_support, F]</span>
                <span class="n">X_query_part</span> <span class="o">=</span> <span class="n">X_episode</span><span class="p">[:,</span> <span class="n">mid</span><span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># [1, query_size, F]</span>
                <span class="c1"># Ensure both tensors have same number of dimensions (both should be 3D)</span>
                <span class="n">X_episode</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">X_support_kept</span><span class="p">,</span> <span class="n">X_query_part</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># if any query label was excluded, skip this episode (avoids OOB gathers)</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">yq_m</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                    <span class="k">continue</span>

                <span class="c1"># forward with episodic labels (contiguous, â¤ C_out)</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="p">(</span><span class="n">X_episode</span><span class="p">,</span> <span class="n">ys_m</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>  <span class="c1"># [1, Q, &lt;=C_out]</span>
                <span class="n">logits</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>        <span class="c1"># [Q, &lt;=C_out]</span>
                <span class="c1"># ensure mapping fits the actual head width (in case adapters changed it mid-run)</span>
                <span class="k">if</span> <span class="n">logits</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">yq_m</span><span class="o">.</span><span class="n">max</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">continue</span>  <span class="c1"># skip this episode if it exceeds head capacity</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">yq_m</span><span class="p">)</span>


                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="n">epoch_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">config</span><span class="p">[</span><span class="s1">'show_progress'</span><span class="p">]:</span>
                    <span class="n">iterable</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">epoch_loss</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

        <span class="n">model</span><span class="o">.</span><span class="n">model_</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
</details>
<div class="doc doc-children">
<div class="doc doc-object doc-function">
<h2 class="doc doc-heading" id="tabtune.TuningManager.tuning.TuningManager.load_checkpoint">
<code class="highlight language-python"><span class="n">load_checkpoint</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">)</span></code>
<a class="headerlink" href="#tabtune.TuningManager.tuning.TuningManager.load_checkpoint" title="Permanent link">Â¶</a></h2>
<div class="doc doc-contents">
<p>Loads a checkpoint automatically to correct submodule.</p>
<details class="quote">
<summary>Source code in <code>tabtune/TuningManager/tuning.py</code></summary>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">load_checkpoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Loads a checkpoint automatically to correct submodule."""</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Checkpoint path </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2"> not found"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">model</span>

    <span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">map_location</span><span class="p">)</span>
    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">state</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">'model_state_dict'</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
    <span class="n">candidates</span> <span class="o">=</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model_'</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s1">'model'</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="n">model</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">candidate</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">candidate</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">candidate</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Loaded checkpoint weights into </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
                <span class="k">return</span> <span class="n">model</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TuningManager] Could not load into </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">candidate</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">"[TuningManager] Failed to load weights into model"</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></td></tr></table></div>
</details>
</div>
</div>
</div>
</div>
</div></div>
</div>
<footer class="col-md-12 text-center">
<hr/>
<p>
<small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
</p>
</footer>
<script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="../../js/bootstrap-3.0.3.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/highlight.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/python.min.js"></script>
<script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@9.18.0/build/languages/yaml.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script>var base_url = "../.."</script>
<script src="../../js/base.js"></script>
<script src="../../search/main.js"></script>
<script>
        // Initialize Mermaid v9.x after DOM loads
        // The mermaid2 plugin loads the library and sets window.mermaidConfig
        (function() {
            function initMermaid() {
                if (typeof mermaid !== 'undefined') {
                    // Get configuration from plugin or use defaults
                    const config = window.mermaidConfig || {
                        securityLevel: 'loose',
                        startOnLoad: false
                    };
                    
                    // Initialize mermaid with config
                    mermaid.initialize(config);
                    
                    // Render all mermaid diagrams - mermaid.run() automatically finds .mermaid elements
                    if (typeof mermaid.run === 'function') {
                        mermaid.run();
                    } else {
                        // Fallback for older API - manually initialize elements
                        const mermaidElements = document.querySelectorAll('.mermaid');
                        if (mermaidElements.length > 0) {
                            mermaid.init(undefined, mermaidElements);
                        }
                    }
                } else {
                    // Retry if mermaid library hasn't loaded yet
                    setTimeout(initMermaid, 100);
                }
            }
            
            // Wait for DOM and scripts to be ready
            if (document.readyState === 'loading') {
                document.addEventListener('DOMContentLoaded', initMermaid);
            } else {
                // DOM already loaded, but scripts might not be
                setTimeout(initMermaid, 100);
            }
        })();
    </script>
<div aria-hidden="true" aria-labelledby="searchModalLabel" class="modal" id="mkdocs_search_modal" role="dialog" tabindex="-1">
<div class="modal-dialog modal-lg">
<div class="modal-content">
<div class="modal-header">
<button class="close" data-dismiss="modal" type="button">
<span aria-hidden="true">Ã</span>
<span class="sr-only">Close</span>
</button>
<h4 class="modal-title" id="searchModalLabel">Search</h4>
</div>
<div class="modal-body">
<p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
<form>
<div class="form-group">
<input class="form-control" id="mkdocs-search-query" placeholder="Search..." title="Type search term here" type="text"/>
</div>
</form>
<div id="mkdocs-search-results"></div>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div><div aria-hidden="true" aria-labelledby="keyboardModalLabel" class="modal" id="mkdocs_keyboard_modal" role="dialog" tabindex="-1">
<div class="modal-dialog">
<div class="modal-content">
<div class="modal-header">
<h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
<button class="close" data-dismiss="modal" type="button"><span aria-hidden="true">Ã</span><span class="sr-only">Close</span></button>
</div>
<div class="modal-body">
<table class="table">
<thead>
<tr>
<th style="width: 20%;">Keys</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td class="help shortcut"><kbd>?</kbd></td>
<td>Open this help</td>
</tr>
<tr>
<td class="next shortcut"><kbd>n</kbd></td>
<td>Next page</td>
</tr>
<tr>
<td class="prev shortcut"><kbd>p</kbd></td>
<td>Previous page</td>
</tr>
<tr>
<td class="search shortcut"><kbd>s</kbd></td>
<td>Search</td>
</tr>
</tbody>
</table>
</div>
<div class="modal-footer">
</div>
</div>
</div>
</div>
</body>
</html>
